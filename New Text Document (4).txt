





m@DESKTOP-MUB16F8:~$ sudo docker run -it --privileged --rm --pull=always \
>   -e LLM_API_KEY="ollama" \
>   -e LLM_BASE_URL="http://host.docker.internal:11434" \
>   -e LLM_OLLAMA_BASE_URL="http://host.docker.internal:11434" \
>   -e SANDBOX_RUNTIME_CONTAINER_IMAGE=docker.all-hands.dev/all-hands-ai/runtime:0.12-nikolaik \
>   -v /var/run/docker.sock:/var/run/docker.sock \
>   -p 3000:3000 \
>   --add-host host.docker.internal:host-gateway \
>   --name openhands-app \
>   docker.all-hands.dev/all-hands-ai/openhands:0.12
[sudo] password for m:
0.12: Pulling from all-hands-ai/openhands
Digest: sha256:2e7382f8ab4defa232071ddae3bc726a25373f4b08f68aee5a3eff5af412b597
Status: Image is up to date for docker.all-hands.dev/all-hands-ai/openhands:0.12
docker: Error response from daemon: Conflict. The container name "/openhands-app" is already in use by container "5b4f2fd3009e996acba778c59ec9ee317452899c54d2a7f455f8248ffb17af83". You have to remove (or rename) that container to be able to reuse that name.

Run 'docker run --help' for more information
m@DESKTOP-MUB16F8:~$ sudo docker logs openhands-app
Starting OpenHands...
Running OpenHands as root
INFO:     Started server process [10]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:3000 (Press CTRL+C to quit)
m@DESKTOP-MUB16F8:~$ ip addr show eth0
2: eth0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc mq state UP group default qlen 1000
    link/ether 00:15:5d:4b:03:e1 brd ff:ff:ff:ff:ff:ff
    inet 172.21.151.42/20 brd 172.21.159.255 scope global eth0
       valid_lft forever preferred_lft forever
    inet6 fe80::215:5dff:fe4b:3e1/64 scope link
       valid_lft forever preferred_lft forever
m@DESKTOP-MUB16F8:~$ hostname -I
172.21.151.42
m@DESKTOP-MUB16F8:~$
cker runm@DESKTOP-MUB16F8:~$ sudo docker run -it --privileged --rm --pull=always \
>   -e LLM_API_KEY="ollama" \
>   -e LLM_BASE_URL="http://172.21.151.42:11434" \
>   -e LLM_OLLAMA_BASE_URL="http://172.21.151.42:11434" \
  -e SA>   -e SANDBOX_RUNTIME_CONTAINER_IMAGE=docker.all-hands.dev/all-hands-ai/runtime:0.12-nikolaik \
>   -v /var/run/docker.sock:/var/run/docker.sock \
>   -p 3000:3000 \
>   --add-host host.docker.internal:host-gateway \
>   --name openhands-app \
>   docker.all-hands.dev/all-hands-ai/openhands:0.12
0.12: Pulling from all-hands-ai/openhands
Digest: sha256:2e7382f8ab4defa232071ddae3bc726a25373f4b08f68aee5a3eff5af412b597
Status: Image is up to date for docker.all-hands.dev/all-hands-ai/openhands:0.12
docker: Error response from daemon: Conflict. The container name "/openhands-app" is already in use by container "5b4f2fd3009e996acba778c59ec9ee317452899c54d2a7f455f8248ffb17af83". You have to remove (or rename) that container to be able to reuse that name.

Run 'docker run --help' for more information
m@DESKTOP-MUB16F8:~$ sudo docker stop openhands-app
openhands-app
m@DESKTOP-MUB16F8:~$ sudo docker run -it --privileged --rm --pull=always \
>   -e LLM_API_KEY="ollama" \
>   -e LLM_BASE_URL="http://172.21.151.42:11434" \
  -e LL>   -e LLM_OLLAMA_BASE_URL="http://172.21.151.42:11434" \
>   -e SANDBOX_RUNTIME_CONTAINER_IMAGE=docker.all-hands.dev/all-hands-ai/runtime:0.12-nikolaik \
>   -v /var/run/docker.sock:/var/run/docker.sock \
>   -p 3000:3000 \
>   --add-host host.docker.internal:host-gateway \
>   --name openhands-app \
>   docker.all-hands.dev/all-hands-ai/openhands:0.12
0.12: Pulling from all-hands-ai/openhands
Digest: sha256:2e7382f8ab4defa232071ddae3bc726a25373f4b08f68aee5a3eff5af412b597
Status: Image is up to date for docker.all-hands.dev/all-hands-ai/openhands:0.12
Starting OpenHands...
Running OpenHands as root
INFO:     Started server process [11]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:3000 (Press CTRL+C to quit)
INFO:     172.17.0.1:48658 - "GET / HTTP/1.1" 200 OK
INFO:     172.17.0.1:48658 - "GET /assets/root-C13iIuce.css HTTP/1.1" 200 OK
INFO:     172.17.0.1:48674 - "GET /assets/manifest-4225960c.js HTTP/1.1" 200 OK
INFO:     172.17.0.1:48682 - "GET /assets/entry.client-1n4ZPLSW.js HTTP/1.1" 200 OK
INFO:     172.17.0.1:48698 - "GET /assets/jsx-runtime-zhgTtAea.js HTTP/1.1" 200 OK
INFO:     172.17.0.1:48700 - "GET /assets/components-Bd8d2nMd.js HTTP/1.1" 200 OK
INFO:     172.17.0.1:48674 - "GET /assets/index-CB_aKBva.js HTTP/1.1" 200 OK
INFO:     172.17.0.1:48708 - "GET /assets/react-redux-DzUTqGNF.js HTTP/1.1" 200 OK
INFO:     172.17.0.1:48658 - "GET /assets/socket-B39-LSlI.js HTTP/1.1" 200 OK
INFO:     172.17.0.1:48682 - "GET /assets/store-CT-MXBfU.js HTTP/1.1" 200 OK
INFO:     172.17.0.1:48698 - "GET /assets/router-CQIzOUUf.js HTTP/1.1" 200 OK
INFO:     172.17.0.1:48708 - "GET /assets/index-DvhLSMS6.js HTTP/1.1" 200 OK
INFO:     172.17.0.1:48700 - "GET /assets/i18nInstance-DCxlOlkw.js HTTP/1.1" 200 OK
INFO:     172.17.0.1:48658 - "GET /assets/AgentState-DCyv5jZT.js HTTP/1.1" 200 OK
INFO:     172.17.0.1:48674 - "GET /assets/index-BgBamcox.js HTTP/1.1" 200 OK
INFO:     172.17.0.1:48698 - "GET /assets/codeSlice-IFyzp_hl.js HTTP/1.1" 200 OK
INFO:     172.17.0.1:48682 - "GET /assets/agentSlice-0xeL04tr.js HTTP/1.1" 200 OK
INFO:     172.17.0.1:48708 - "GET /assets/root-CjnzvPFH.js HTTP/1.1" 200 OK
INFO:     172.17.0.1:48708 - "GET /locales/en/translation.json HTTP/1.1" 200 OK
INFO:     172.17.0.1:48708 - "GET /favicon.ico HTTP/1.1" 200 OK
INFO:     172.17.0.1:48708 - "GET /assets/_oh-CHAvq9bt.js HTTP/1.1" 200 OK
INFO:     172.17.0.1:48698 - "GET /assets/route-B0EamsJK.js HTTP/1.1" 200 OK
INFO:     172.17.0.1:48682 - "GET /assets/github-logo-BL5HJ9fI.js HTTP/1.1" 200 OK
INFO:     172.17.0.1:48708 - "GET /assets/connect-to-github-modal-B4f7Tfpz.js HTTP/1.1" 200 OK
INFO:     172.17.0.1:48658 - "GET /assets/modal-backdrop-si9s5Ywp.js HTTP/1.1" 200 OK
INFO:     172.17.0.1:48674 - "GET /assets/open-hands-BOkBFOmY.js HTTP/1.1" 200 OK
INFO:     172.17.0.1:48700 - "GET /assets/responses-iq082X3z.js HTTP/1.1" 200 OK
INFO:     172.17.0.1:48674 - "GET /assets/user-is-authenticated-BwDnPXVy.js HTTP/1.1" 200 OK
INFO:     172.17.0.1:48682 - "GET /assets/extends-CEetKkoc.js HTTP/1.1" 200 OK
INFO:     172.17.0.1:48698 - "GET /assets/utils-p7Tk_-vA.js HTTP/1.1" 200 OK
INFO:     172.17.0.1:48708 - "GET /assets/settings-DawUpo-u.js HTTP/1.1" 200 OK
INFO:     172.17.0.1:48708 - "GET /config.json HTTP/1.1" 200 OK
INFO:     172.17.0.1:48698 - "GET /config.json HTTP/1.1" 200 OK
20:13:02 - openhands:ERROR: listen.py:413 - Error getting OLLAMA models: HTTPConnectionPool(host='172.21.151.42', port=11434): Max retries exceeded with url: /api/tags (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f32fb2ee3c0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Traceback (most recent call last):
  File "/app/.venv/lib/python3.12/site-packages/urllib3/connection.py", line 199, in _new_conn
    sock = connection.create_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/urllib3/util/connection.py", line 85, in create_connection
    raise err
  File "/app/.venv/lib/python3.12/site-packages/urllib3/util/connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/app/.venv/lib/python3.12/site-packages/urllib3/connectionpool.py", line 789, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/urllib3/connectionpool.py", line 495, in _make_request
    conn.request(
  File "/app/.venv/lib/python3.12/site-packages/urllib3/connection.py", line 441, in request
    self.endheaders()
  File "/usr/local/lib/python3.12/http/client.py", line 1331, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/usr/local/lib/python3.12/http/client.py", line 1091, in _send_output
    self.send(msg)
  File "/usr/local/lib/python3.12/http/client.py", line 1035, in send
    self.connect()
  File "/app/.venv/lib/python3.12/site-packages/urllib3/connection.py", line 279, in connect
    self.sock = self._new_conn()
                ^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/urllib3/connection.py", line 214, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7f32fb2ee3c0>: Failed to establish a new connection: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/app/.venv/lib/python3.12/site-packages/requests/adapters.py", line 667, in send
    resp = conn.urlopen(
           ^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/urllib3/connectionpool.py", line 843, in urlopen
    retries = retries.increment(
              ^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/urllib3/util/retry.py", line 519, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='172.21.151.42', port=11434): Max retries exceeded with url: /api/tags (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f32fb2ee3c0>: Failed to establish a new connection: [Errno 111] Connection refused'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/app/openhands/server/listen.py", line 406, in get_litellm_models
    ollama_models_list = requests.get(ollama_url, timeout=3).json()[
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/requests/api.py", line 73, in get
    return request("get", url, params=params, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/requests/api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/requests/adapters.py", line 700, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='172.21.151.42', port=11434): Max retries exceeded with url: /api/tags (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f32fb2ee3c0>: Failed to establish a new connection: [Errno 111] Connection refused'))
INFO:     172.17.0.1:48682 - "GET /api/options/security-analyzers HTTP/1.1" 200 OK
INFO:     172.17.0.1:48698 - "GET /api/options/models HTTP/1.1" 200 OK
INFO:     172.17.0.1:48708 - "GET /api/options/agents HTTP/1.1" 200 OK
INFO:     172.17.0.1:57196 - "GET /assets/set-consent-DWbcphLP.js HTTP/1.1" 200 OK
INFO:     172.17.0.1:57196 - "GET /config.json HTTP/1.1" 200 OK
INFO:     172.17.0.1:57200 - "GET /config.json HTTP/1.1" 200 OK
INFO:     172.17.0.1:50108 - "GET /assets/settings-B80uBrgv.js HTTP/1.1" 200 OK
INFO:     172.17.0.1:50108 - "GET /config.json HTTP/1.1" 200 OK
INFO:     172.17.0.1:50124 - "GET /config.json HTTP/1.1" 200 OK
INFO:     172.17.0.1:50124 - "GET /config.json HTTP/1.1" 200 OK
INFO:     172.17.0.1:50108 - "GET /config.json HTTP/1.1" 200 OK
INFO:     172.17.0.1:50108 - "GET /config.json HTTP/1.1" 200 OK
INFO:     172.17.0.1:50124 - "GET /config.json HTTP/1.1" 200 OK
INFO:     172.17.0.1:50124 - "GET /config.json HTTP/1.1" 200 OK
INFO:     172.17.0.1:50108 - "GET /config.json HTTP/1.1" 200 OK
INFO:     172.17.0.1:57472 - "GET /config.json HTTP/1.1" 200 OK
INFO:     172.17.0.1:57482 - "GET /config.json HTTP/1.1" 200 OK
INFO:     172.17.0.1:57472 - "GET /assets/route-CCYv0vF5.js HTTP/1.1" 200 OK
INFO:     172.17.0.1:57494 - "GET /config.json HTTP/1.1" 200 OK
INFO:     172.17.0.1:57482 - "GET /assets/_oh.app-BbuKviuw.js HTTP/1.1" 200 OK
INFO:     172.17.0.1:57494 - "GET /assets/index-BXT04Q8N.js HTTP/1.1" 200 OK
INFO:     172.17.0.1:57482 - "GET /assets/index-C4MRHScb.js HTTP/1.1" 200 OK
INFO:     172.17.0.1:57472 - "GET /assets/declaration-DdUOQw3g.js HTTP/1.1" 200 OK
INFO:     172.17.0.1:57512 - "GET /assets/_oh.app-o9tOh4U3.js HTTP/1.1" 200 OK
INFO:     172.17.0.1:57502 - "GET /assets/index-wBZoZNP4.js HTTP/1.1" 200 OK
INFO:     172.17.0.1:57516 - "GET /assets/useScrollToBottom-B8_iP14x.js HTTP/1.1" 200 OK
INFO:     172.17.0.1:57494 - "GET /assets/clear-session-Bbh6tTiy.js HTTP/1.1" 200 OK
INFO:     172.17.0.1:57494 - "GET /assets/Terminal-CGrrDQr5.css HTTP/1.1" 200 OK
INFO:     172.17.0.1:57512 - "GET /assets/Terminal-DIsziyk5.js HTTP/1.1" 200 OK
20:23:04 - openhands:INFO: github.py:14 - Initializing UserVerifier
20:23:04 - openhands:INFO: github.py:27 - GITHUB_USER_LIST_FILE not configured
20:23:04 - openhands:INFO: github.py:48 - GITHUB_USERS_SHEET_ID not configured
20:23:04 - openhands:INFO: github.py:85 - No user verification sources configured - allowing all users
INFO:     ('172.17.0.1', 57520) - "WebSocket /ws" [accepted]
20:23:04 - openhands:INFO: listen.py:336 - New session: 44c59aee-a753-4ac7-82fb-ea64dfa287a8
INFO:     connection open
20:23:04 - openhands:WARNING: codeact_agent.py:101 - Function calling not supported for model ollama/llama3.2:1b. Disabling function calling.
INFO:     172.17.0.1:57512 - "GET /config.json HTTP/1.1" 200 OK
20:23:04 - openhands:INFO: base.py:98 - [runtime 44c59aee-a753-4ac7-82fb-ea64dfa287a8] Starting runtime with image: docker.all-hands.dev/all-hands-ai/runtime:0.12-nikolaik
20:23:05 - openhands:INFO: base.py:98 - [runtime 44c59aee-a753-4ac7-82fb-ea64dfa287a8] Container started: openhands-runtime-44c59aee-a753-4ac7-82fb-ea64dfa287a8
20:23:05 - openhands:INFO: base.py:98 - [runtime 44c59aee-a753-4ac7-82fb-ea64dfa287a8] Waiting for client to become ready at http://host.docker.internal:31331...
20:24:00 - openhands:INFO: base.py:98 - [runtime 44c59aee-a753-4ac7-82fb-ea64dfa287a8] Runtime is ready.
20:24:00 - openhands:WARNING: state.py:118 - Failed to restore state from session: sessions/44c59aee-a753-4ac7-82fb-ea64dfa287a8/agent_state.pkl
20:24:00 - openhands:INFO: agent_controller.py:135 - [Agent Controller 44c59aee-a753-4ac7-82fb-ea64dfa287a8] Starting step loop...
20:24:00 - openhands:INFO: agent_controller.py:135 - [Agent Controller 44c59aee-a753-4ac7-82fb-ea64dfa287a8] Setting agent(CodeActAgent) state from AgentState.LOADING to AgentState.INIT
20:24:00 - openhands:INFO: agent_controller.py:135 - [Agent Controller 44c59aee-a753-4ac7-82fb-ea64dfa287a8] Setting agent(CodeActAgent) state from AgentState.INIT to AgentState.RUNNING
20:24:00 - openhands:INFO: github.py:14 - Initializing UserVerifier
20:24:00 - openhands:INFO: github.py:27 - GITHUB_USER_LIST_FILE not configured
20:24:00 - openhands:INFO: github.py:48 - GITHUB_USERS_SHEET_ID not configured
20:24:00 - openhands:INFO: github.py:85 - No user verification sources configured - allowing all users
INFO:     172.17.0.1:53100 - "GET /config.json HTTP/1.1" 200 OK
INFO:     172.17.0.1:53110 - "GET /config.json HTTP/1.1" 200 OK
INFO:     172.17.0.1:53084 - "GET /api/list-files HTTP/1.1" 200 OK
20:24:00 - openhands:INFO: github.py:14 - Initializing UserVerifier
20:24:00 - openhands:INFO: github.py:27 - GITHUB_USER_LIST_FILE not configured
20:24:00 - openhands:INFO: github.py:48 - GITHUB_USERS_SHEET_ID not configured
20:24:00 - openhands:INFO: github.py:85 - No user verification sources configured - allowing all users
INFO:     172.17.0.1:53110 - "GET /api/list-files HTTP/1.1" 200 OK
20:24:00 - openhands:INFO: github.py:14 - Initializing UserVerifier
20:24:00 - openhands:INFO: github.py:27 - GITHUB_USER_LIST_FILE not configured
20:24:00 - openhands:INFO: github.py:48 - GITHUB_USERS_SHEET_ID not configured
20:24:00 - openhands:INFO: github.py:85 - No user verification sources configured - allowing all users
INFO:     172.17.0.1:53084 - "GET /api/list-files HTTP/1.1" 200 OK


==============
[Agent Controller 44c59aee-a753-4ac7-82fb-ea64dfa287a8] LEVEL 0 LOCAL STEP 0 GLOBAL STEP 0


Provider List: https://docs.litellm.ai/docs/providers


Provider List: https://docs.litellm.ai/docs/providers


Give Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new
LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.


Provider List: https://docs.litellm.ai/docs/providers

20:24:01 - openhands:ERROR: retry_mixin.py:47 - litellm.ServiceUnavailableError: OllamaException: HTTPConnectionPool(host='127.0.0.1', port=11434): Max retries exceeded with url: /v1/api/generate (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f32fa8984d0>: Failed to establish a new connection: [Errno 111] Connection refused')). Attempt #1 | You can customize retry values in the configuration.

Give Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new
LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.


Provider List: https://docs.litellm.ai/docs/providers

20:24:16 - openhands:ERROR: retry_mixin.py:47 - litellm.ServiceUnavailableError: OllamaException: HTTPConnectionPool(host='127.0.0.1', port=11434): Max retries exceeded with url: /v1/api/generate (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f32fa9ae810>: Failed to establish a new connection: [Errno 111] Connection refused')). Attempt #2 | You can customize retry values in the configuration.

Give Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new
LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.


Provider List: https://docs.litellm.ai/docs/providers

20:24:33 - openhands:ERROR: retry_mixin.py:47 - litellm.ServiceUnavailableError: OllamaException: HTTPConnectionPool(host='127.0.0.1', port=11434): Max re























m@DESKTOP-MUB16F8:~$ sudo docker run -it --privileged --rm --pull=always \
>   -e LLM_API_KEY="ollama" \
>   -e LLM_BASE_URL="http://127.0.0.1:11434" \
>   -e LLM_OLLAMA_BASE_URL="http://127.0.0.1:11434" \
>   -e SANDBOX_RUNTIME_CONTAINER_IMAGE=docker.all-hands.dev/all-hands-ai/runtime:0.12-nikolaik \
>   -v /var/run/docker.sock:/var/run/docker.sock \
>   -p 3000:3000 \
>   --name openhands-app \
>   docker.all-hands.dev/all-hands-ai/openhands:0.12
[sudo] password for m:
0.12: Pulling from all-hands-ai/openhands
Digest: sha256:2e7382f8ab4defa232071ddae3bc726a25373f4b08f68aee5a3eff5af412b597
Status: Image is up to date for docker.all-hands.dev/all-hands-ai/openhands:0.12
Starting OpenHands...
Running OpenHands as root
INFO:     Started server process [10]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:3000 (Press CTRL+C to quit)
INFO:     172.17.0.1:34672 - "GET / HTTP/1.1" 200 OK
INFO:     172.17.0.1:34672 - "GET /locales/en/translation.json HTTP/1.1" 200 OK
INFO:     172.17.0.1:34672 - "GET /config.json HTTP/1.1" 200 OK
INFO:     172.17.0.1:34678 - "GET /config.json HTTP/1.1" 200 OK
INFO:     172.17.0.1:34678 - "GET /config.json HTTP/1.1" 200 OK
20:32:44 - openhands:INFO: github.py:14 - Initializing UserVerifier
20:32:44 - openhands:INFO: github.py:27 - GITHUB_USER_LIST_FILE not configured
20:32:44 - openhands:INFO: github.py:48 - GITHUB_USERS_SHEET_ID not configured
20:32:44 - openhands:INFO: github.py:85 - No user verification sources configured - allowing all users
INFO:     ('172.17.0.1', 34694) - "WebSocket /ws" [accepted]
20:32:44 - openhands:ERROR: auth.py:27 - Invalid token
INFO:     connection open
20:32:44 - openhands:ERROR: listen.py:413 - Error getting OLLAMA models: HTTPConnectionPool(host='127.0.0.1', port=11434): Max retries exceeded with url: /api/tags (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f9b142f1100>: Failed to establish a new connection: [Errno 111] Connection refused'))
Traceback (most recent call last):
  File "/app/.venv/lib/python3.12/site-packages/urllib3/connection.py", line 199, in _new_conn
    sock = connection.create_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/urllib3/util/connection.py", line 85, in create_connection
    raise err
  File "/app/.venv/lib/python3.12/site-packages/urllib3/util/connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/app/.venv/lib/python3.12/site-packages/urllib3/connectionpool.py", line 789, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/urllib3/connectionpool.py", line 495, in _make_request
    conn.request(
  File "/app/.venv/lib/python3.12/site-packages/urllib3/connection.py", line 441, in request
    self.endheaders()
  File "/usr/local/lib/python3.12/http/client.py", line 1331, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/usr/local/lib/python3.12/http/client.py", line 1091, in _send_output
    self.send(msg)
  File "/usr/local/lib/python3.12/http/client.py", line 1035, in send
    self.connect()
  File "/app/.venv/lib/python3.12/site-packages/urllib3/connection.py", line 279, in connect
    self.sock = self._new_conn()
                ^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/urllib3/connection.py", line 214, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7f9b142f1100>: Failed to establish a new connection: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/app/.venv/lib/python3.12/site-packages/requests/adapters.py", line 667, in send
    resp = conn.urlopen(
           ^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/urllib3/connectionpool.py", line 843, in urlopen
    retries = retries.increment(
              ^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/urllib3/util/retry.py", line 519, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=11434): Max retries exceeded with url: /api/tags (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f9b142f1100>: Failed to establish a new connection: [Errno 111] Connection refused'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/app/openhands/server/listen.py", line 406, in get_litellm_models
    ollama_models_list = requests.get(ollama_url, timeout=3).json()[
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/requests/api.py", line 73, in get
    return request("get", url, params=params, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/requests/api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/requests/adapters.py", line 700, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=11434): Max retries exceeded with url: /api/tags (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f9b142f1100>: Failed to establish a new connection: [Errno 111] Connection refused'))
INFO:     172.17.0.1:34672 - "GET /api/options/agents HTTP/1.1" 200 OK
INFO:     172.17.0.1:34678 - "GET /api/options/models HTTP/1.1" 200 OK
INFO:     172.17.0.1:34696 - "GET /api/options/security-analyzers HTTP/1.1" 200 OK
INFO:     connection closed
INFO:     172.17.0.1:34710 - "GET /assets/end-session-CpBsKLW_.js HTTP/1.1" 200 OK
INFO:     172.17.0.1:34710 - "GET /config.json HTTP/1.1" 200 OK
INFO:     172.17.0.1:34696 - "GET /config.json HTTP/1.1" 200 OK
INFO:     172.17.0.1:45428 - "GET /config.json HTTP/1.1" 200 OK
INFO:     172.17.0.1:45442 - "GET /config.json HTTP/1.1" 200 OK
INFO:     172.17.0.1:45428 - "GET /config.json HTTP/1.1" 200 OK
INFO:     172.17.0.1:45442 - "GET /config.json HTTP/1.1" 200 OK
INFO:     172.17.0.1:32878 - "GET /config.json HTTP/1.1" 200 OK
20:33:48 - openhands:INFO: github.py:14 - Initializing UserVerifier
20:33:48 - openhands:INFO: github.py:27 - GITHUB_USER_LIST_FILE not configured
20:33:48 - openhands:INFO: github.py:48 - GITHUB_USERS_SHEET_ID not configured
20:33:48 - openhands:INFO: github.py:85 - No user verification sources configured - allowing all users
INFO:     ('172.17.0.1', 32884) - "WebSocket /ws" [accepted]
20:33:48 - openhands:INFO: listen.py:336 - New session: 9b610e06-50ea-4c66-91de-a2b323d94780
INFO:     connection open
20:33:48 - openhands:WARNING: codeact_agent.py:101 - Function calling not supported for model ollama/llama3.2:1b. Disabling function calling.
INFO:     172.17.0.1:32878 - "GET /config.json HTTP/1.1" 200 OK
20:33:48 - openhands:INFO: base.py:98 - [runtime 9b610e06-50ea-4c66-91de-a2b323d94780] Starting runtime with image: docker.all-hands.dev/all-hands-ai/runtime:0.12-nikolaik
20:33:49 - openhands:INFO: base.py:98 - [runtime 9b610e06-50ea-4c66-91de-a2b323d94780] Container started: openhands-runtime-9b610e06-50ea-4c66-91de-a2b323d94780
20:33:49 - openhands:INFO: base.py:98 - [runtime 9b610e06-50ea-4c66-91de-a2b323d94780] Waiting for client to become ready at http://host.docker.internal:30268...
20:34:43 - openhands:INFO: base.py:98 - [runtime 9b610e06-50ea-4c66-91de-a2b323d94780] Runtime is ready.
20:34:43 - openhands:WARNING: state.py:118 - Failed to restore state from session: sessions/9b610e06-50ea-4c66-91de-a2b323d94780/agent_state.pkl
20:34:43 - openhands:INFO: agent_controller.py:135 - [Agent Controller 9b610e06-50ea-4c66-91de-a2b323d94780] Starting step loop...
20:34:43 - openhands:INFO: agent_controller.py:135 - [Agent Controller 9b610e06-50ea-4c66-91de-a2b323d94780] Setting agent(CodeActAgent) state from AgentState.LOADING to AgentState.INIT
20:34:43 - openhands:INFO: agent_controller.py:135 - [Agent Controller 9b610e06-50ea-4c66-91de-a2b323d94780] Setting agent(CodeActAgent) state from AgentState.INIT to AgentState.RUNNING
20:34:43 - openhands:INFO: github.py:14 - Initializing UserVerifier
20:34:43 - openhands:INFO: github.py:27 - GITHUB_USER_LIST_FILE not configured
20:34:43 - openhands:INFO: github.py:48 - GITHUB_USERS_SHEET_ID not configured
20:34:43 - openhands:INFO: github.py:85 - No user verification sources configured - allowing all users
INFO:     172.17.0.1:39866 - "GET /config.json HTTP/1.1" 200 OK
INFO:     172.17.0.1:39870 - "GET /config.json HTTP/1.1" 200 OK
INFO:     172.17.0.1:39860 - "GET /api/list-files HTTP/1.1" 200 OK
20:34:44 - openhands:INFO: github.py:14 - Initializing UserVerifier
20:34:44 - openhands:INFO: github.py:27 - GITHUB_USER_LIST_FILE not configured
20:34:44 - openhands:INFO: github.py:48 - GITHUB_USERS_SHEET_ID not configured
20:34:44 - openhands:INFO: github.py:85 - No user verification sources configured - allowing all users
INFO:     172.17.0.1:39870 - "GET /api/list-files HTTP/1.1" 200 OK
20:34:44 - openhands:INFO: github.py:14 - Initializing UserVerifier
20:34:44 - openhands:INFO: github.py:27 - GITHUB_USER_LIST_FILE not configured
20:34:44 - openhands:INFO: github.py:48 - GITHUB_USERS_SHEET_ID not configured
20:34:44 - openhands:INFO: github.py:85 - No user verification sources configured - allowing all users
INFO:     172.17.0.1:39860 - "GET /api/list-files HTTP/1.1" 200 OK


==============
[Agent Controller 9b610e06-50ea-4c66-91de-a2b323d94780] LEVEL 0 LOCAL STEP 0 GLOBAL STEP 0


Provider List: https://docs.litellm.ai/docs/providers


Provider List: https://docs.litellm.ai/docs/providers


Give Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new
LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.


Provider List: https://docs.litellm.ai/docs/providers

20:34:44 - openhands:ERROR: retry_mixin.py:47 - litellm.ServiceUnavailableError: OllamaException: HTTPConnectionPool(host='127.0.0.1', port=11434): Max retries exceeded with url: /v1/api/generate (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f9b13dcfa70>: Failed to establish a new connection: [Errno 111] Connection refused')). Attempt #1 | You can customize retry values in the configuration.

Give Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new
LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.


Provider List: https://docs.litellm.ai/docs/providers

20:35:00 - openhands:ERROR: retry_mixin.py:47 - litellm.ServiceUnavailableError: OllamaException: HTTPConnectionPool(host='127.0.0.1', port=11434): Max retries exceeded with url: /v1/api/generate (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f9b13c5ba10>: Failed to establish a new connection: [Errno 111] Connection refused')). Attempt #2 | You can customize retry values in the configuration.

Give Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new
LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.


Provider List: https://docs.litellm.ai/docs/providers

20:35:16 - openhands:ERROR: retry_mixin.py:47 - litellm.ServiceUnavailableError: OllamaException: HTTPConnectionPool(host='127.0.0.1', port=11434): Max retries exceeded with url: /v1/api/generate (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f9b13c6c1d0>: Failed to establish a new connection: [Errno 111] Connection refused')). Attempt #3 | You can customize retry values in the configuration.

Give Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new
LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.


Provider List: https://docs.litellm.ai/docs/providers

20:35:31 - openhands:ERROR: retry_mixin.py:47 - litellm.ServiceUnavailableError: OllamaException: HTTPConnectionPool(host='127.0.0.1', port=11434): Max retries exceeded with url: /v1/api/generate (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f9b13c6da30>: Failed to establish a new connection: [Errno 111] Connection refused')). Attempt #4 | You can customize retry values in the configuration.

Give Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new
LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.


Provider List: https://docs.litellm.ai/docs/providers

20:35:49 - openhands:ERROR: retry_mixin.py:47 - litellm.ServiceUnavailableError: OllamaException: HTTPConnectionPool(host='127.0.0.1', port=11434): Max retries exceeded with url: /v1/api/generate (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f9b13c5b530>: Failed to establish a new connection: [Errno 111] Connection refused')). Attempt #5 | You can customize retry values in the configuration.

Give Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new
LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.


Provider List: https://docs.litellm.ai/docs/providers

20:36:23 - openhands:ERROR: retry_mixin.py:47 - litellm.ServiceUnavailableError: OllamaException: HTTPConnectionPool(host='127.0.0.1', port=11434): Max retries exceeded with url: /v1/api/generate (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f9b13c6ed80>: Failed to establish a new connection: [Errno 111] Connection refused')). Attempt #6 | You can customize retry values in the configuration.

Give Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new
LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.


Provider List: https://docs.litellm.ai/docs/providers

20:37:31 - openhands:ERROR: retry_mixin.py:47 - litellm.ServiceUnavailableError: OllamaException: HTTPConnectionPool(host='127.0.0.1', port=11434): Max retries exceeded with url: /v1/api/generate (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f9b13c6c230>: Failed to establish a new connection: [Errno 111] Connection refused')). Attempt #7 | You can customize retry values in the configuration.
^CINFO:     Shutting down
20:38:06 - openhands:INFO: session.py:66 - WebSocket disconnected, sid: 9b610e06-50ea-4c66-91de-a2b323d94780
INFO:     connection closed
INFO:     Waiting for application shutdown.
INFO:     Application shutdown complete.
INFO:     Finished server process [10]
^C





















































Skip to content
Navigation Menu
Copilot

Type / to search
Copilot navigation
Copilot Chat
New conversation
All-Hands-AI/OpenHands
You said: m@DESKTOP-MUB16F8:~$ sudo docker run -it --privileged --rm
m@DESKTOP-MUB16F8:~$ sudo docker run -it --privileged --rm --pull=always \
network > --network host \
> -e LLM_API_KEY="ollama" \
> -e LLM_BASE_URL="http://127.0.0.1:11434" \
> -e LLM_OLLAMA_BASE_URL="http://127.0.0.1:11434" \
> -e SANDBOX_RUNTIME_CONTAINER_IMAGE=docker.all-hands.dev/all-hands-ai/runtime:0.12-nikolaik \
> -v /var/run/docker.sock:/var/run/docker.sock \
> -p 3000:3000 \
> --add-host host.docker.internal:host-gateway \
> --name openhands-app \
> docker.all-hands.dev/all-hands-ai/openhands:0.12
[sudo] password for m:
0.12: Pulling from all-hands-ai/openhands
4f4fb700ef54: Pull complete
e6a8d31cf2eb: Pull complete
72b58a0f18ab: Pull complete
3b16ae67f677: Pull complete
c4d658f4c72d: Pull complete
5c6d5919c6f9: Pull complete
9fdf4515d3e8: Pull complete
407847212ec3: Pull complete
4e292ba32c88: Pull complete
aae4996ed7fe: Pull complete
3585541f64d3: Pull complete
f971246883c3: Pull complete
ef24faa9cd89: Pull complete
1563bd99caaa: Pull complete
Digest: sha256:2e7382f8ab4defa232071ddae3bc726a25373f4b08f68aee5a3eff5af412b597
Status: Downloaded newer image for docker.all-hands.dev/all-hands-ai/openhands:0.12
WARNING: Published ports are discarded when using host network mode
Starting OpenHands...
Running OpenHands as root
INFO:     Started server process [10]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:3000 (Press CTRL+C to quit)




http://localhost:3000/
لا يفتح فى المتصفح
Copilot said: يبدو أنك قمت بتشغيل حاوية Docker بنجاح
يبدو أنك قمت بتشغيل حاوية Docker بنجاح لتطبيق OpenHands، وظهر في سجل التشغيل أن السيرفر يعمل على http://0.0.0.0:3000، لكن عند محاولة فتح http://localhost:3000/ في المتصفح، لا يعمل الموقع.

أسباب محتملة وحلول:

استخدام host network مع -p

ظهرت رسالة:
WARNING: Published ports are discarded when using host network mode
هذا معناه أنك استخدمت --network host مع -p 3000:3000. عند استخدام --network host، خيار الـ -p يتم تجاهله لأن الحاوية تشارك الشبكة مباشرة مع الجهاز المضيف (host)، أي أنه يجب أن يكون التطبيق متاحًا مباشرة على منفذ الجهاز.
التأكد من المنفذ

تأكد أن المنفذ 3000 ليس محجوزاً من برنامج آخر على جهازك.
يمكنك فحص ذلك بالأمر:
bash
sudo netstat -tulpn | grep 3000
إذا كان التطبيق ظاهرًا على المنفذ 3000، فهذا جيد.
التجربة من جهاز آخر أو متصفح آخر

إذا كنت تستخدم جهاز افتراضي (مثلاً WSL أو Docker Desktop)، أحيانًا يكون هناك مشاكل في الشبكة بين النظام المضيف والحاوية.
جرب فتح http://127.0.0.1:3000/ أو http://[IP الجهاز]:3000/.
جدار الحماية/Firewall

تأكد أن جدار الحماية لا يمنع الاتصال بالمنفذ 3000.
تشغيل بدون --network host

جرب إزالة --network host من الأمر واستخدم فقط -p 3000:3000:
bash
sudo docker run -it --privileged --rm --pull=always \
-e ... \
-v ... \
-p 3000:3000 \
--add-host host.docker.internal:host-gateway \
--name openhands-app \
docker.all-hands.dev/all-hands-ai/openhands:0.12
هذا سيجعل التطبيق متاحًا على localhost:3000.
تلخيص سريع:

إذا استخدمت --network host، لا تستخدم -p.
جرب الوصول إلى http://127.0.0.1:3000/ بدلاً من localhost.
جرب إزالة --network host واستخدم فقط -p 3000:3000.
إذا لم تنجح أي من هذه الطرق، أعطني نتيجة الأمر:

bash
sudo netstat -tulpn | grep 3000
وكذلك تأكد من نظام التشغيل الذي تستخدمه (Linux أم Windows مع WSL أم Docker Desktop) لنعطيك حل أدق.

You said: m@DESKTOP-MUB16F8:~$ sudo netstat -tulpn | grep 3000 [sudo]
m@DESKTOP-MUB16F8:~$ sudo netstat -tulpn | grep 3000
[sudo] password for m:
sudo: netstat: command not found
m@DESKTOP-MUB16F8:~$
Copilot said: الأمر netstat غير متوفر على جهازك. يمكنك
الأمر netstat غير متوفر على جهازك. يمكنك استخدام أحد البدائل التالية حسب نظام التشغيل الخاص بك:

إذا كنت تستخدم Ubuntu أو توزيعة Debian:
يمكنك تثبيت net-tools (التي تحتوي على netstat) بالأمر:

bash
sudo apt update
sudo apt install net-tools
بعدها أعد تشغيل الأمر:

bash
sudo netstat -tulpn | grep 3000
بديل حديث: استخدم الأمر ss (موجود بشكل افتراضي في أغلب الأنظمة الحديثة):
bash
sudo ss -tulpn | grep 3000
سيظهر لك إذا كان هناك أي برنامج يستمع على المنفذ 3000، ومن بينها التطبيق الذي شغلته في Docker.

ملخص الخطوات:

جرب الأمر:
bash
sudo ss -tulpn | grep 3000
أخبرني بالنتيجة ليتم التشخيص بشكل أدق.
هل ترغب في معرفة كيفية تثبيت netstat أو الاكتفاء باستخدام ss؟

You said: اشتغل ولكن لا يوجد النماذج الموجودة ف اولاما
اشتغل
ولكن لا يوجد النماذج الموجودة ف اولاما ف شاشة
AI Provider Configuration
Copilot said: شكرًا للتوضيح! معنى كلامك أن شاشة
شكرًا للتوضيح!
معنى كلامك أن شاشة "AI Provider Configuration" في OpenHands لا تعرض نماذج (Models) Ollama المتوفرة لديك، رغم أن التطبيق يعمل.

هذه مشكلة شائعة غالبًا مع تكامل Ollama والتطبيقات الطرف الثالث (مثل OpenHands)، وغالبًا تكون الأسباب واحدة من التالي:

الأسباب الشائعة والحلول
1. مشكلة الاتصال بين OpenHands و Ollama
تأكد أن Ollama يعمل فعليًا على http://127.0.0.1:11434.
جرب هذا الأمر في الطرفية:
bash
curl http://127.0.0.1:11434/api/tags
إذا ظهرت لك قائمة النماذج، فهذا يعني أن Ollama يعمل بشكل صحيح.
2. متغيرات البيئة في Docker
تأكد أنك مررت المتغيرات بشكل صحيح:
LLM_API_KEY="ollama"
LLM_BASE_URL="http://127.0.0.1:11434"
LLM_OLLAMA_BASE_URL="http://127.0.0.1:11434"
أحيانًا تحتاج تغير 127.0.0.1 إلى host.docker.internal في متغيرات البيئة داخل أمر Docker:
bash
-e LLM_BASE_URL="http://host.docker.internal:11434"
-e LLM_OLLAMA_BASE_URL="http://host.docker.internal:11434"
السبب: عندما يعمل التطبيق داخل Docker، أحيانًا لا يرى localhost الخاص بالنظام المضيف، بل يرى نفسه فقط.
3. تأكد من أن النماذج محمّلة في Ollama
شغل هذا الأمر:
bash
ollama list
يجب أن ترى قائمة بالنماذج مثل: llama3, mistral, phi3, وغيرها.
إذا لم يوجد أي نموذج، حمّل نموذج مثل:
bash
ollama pull llama3
4. أعد تشغيل الحاوية بعد تعديل المتغيرات
أي تغيير في متغيرات البيئة يتطلب إعادة تشغيل الحاوية.
5. تحقق من سجل الأخطاء في OpenHands
أحيانًا تظهر رسالة خطأ في الطرفية أو في متصفح المطور (F12 > Console أو Network).
ملخص سريع للحل:
جرب تغيير LLM_BASE_URL و LLM_OLLAMA_BASE_URL إلى
Code
http://host.docker.internal:11434
بدلًا من 127.0.0.1
تأكد أن Ollama يعمل والنماذج محمّلة بالفعل (ollama list)
جرّب الاتصال بـ Ollama من داخل الحاوية:
bash
docker exec -it openhands-app curl http://host.docker.internal:11434/api/tags
إذا ظهرت النماذج، فالاتصال سليم.
أعد تشغيل الحاوية بعد أي تعديل.
هل تريد أمثلة أوامر جاهزة لتشغيل الحاوية بالصيغة الصحيحة؟ أرسل لي نتيجة

bash
curl http://127.0.0.1:11434/api/tags
وخبرني إذا عدلت متغيرات البيئة وجربت.

You said: m@DESKTOP-MUB16F8:~$ curl http://127.0.0.1:11434/api/tags {"models":[{"name":"orca-mini:latest","model":"orca-mini:latest","modified_at":"2025-05-25T20:54:12.622513707-07:00","size":1979947443,"digest":"2dbd9f439647093cf773c325b0b3081a11f1b1426d61dee8b946f8f6555a1755","details":{"parent_model":"","format":"gguf","family":"llama","families":null,"parameter_size":"3B","quantization_level":"Q4_0"}},{"name":"llama3.2:1b","model":"llama3.2:1b","modified_at":"2025-05-25T16:05:31.90019971-07:00","size":1321098329,"digest":"baf6a787fdffd633537aa2eb51cfd54cb93ff08e28040095462bb63daf552878","details":{"parent_model":"","format":"gguf","family":"llama","families":["llama"],"parameter_size":"1.2B","quantization_level":"Q8_0"}}]}m@DESKTOP-MUB16F8:~$
m@DESKTOP-MUB16F8:~$ curl http://127.0.0.1:11434/api/tags
{"models":[{"name":"orca-mini:latest","model":"orca-mini:latest","modified_at":"2025-05-25T20:54:12.622513707-07:00","size":1979947443,"digest":"2dbd9f439647093cf773c325b0b3081a11f1b1426d61dee8b946f8f6555a1755","details":{"parent_model":"","format":"gguf","family":"llama","families":null,"parameter_size":"3B","quantization_level":"Q4_0"}},{"name":"llama3.2:1b","model":"llama3.2:1b","modified_at":"2025-05-25T16:05:31.90019971-07:00","size":1321098329,"digest":"baf6a787fdffd633537aa2eb51cfd54cb93ff08e28040095462bb63daf552878","details":{"parent_model":"","format":"gguf","family":"llama","families":["llama"],"parameter_size":"1.2B","quantization_level":"Q8_0"}}]}m@DESKTOP-MUB16F8:~$
Copilot said: النتيجة التي ظهرت من أمر curl ممتازة
النتيجة التي ظهرت من أمر curl ممتازة وتؤكد أن:

خدمة Ollama تعمل بنجاح على جهازك المحلي.
لديك نموذجين متوفرين: orca-mini:latest و llama3.2:1b.
لكن المشكلة الآن أن OpenHands لا يعرض هذه النماذج في شاشة AI Provider Configuration.

الحل الأقوى لمشكلتك (خاص ببيئة Docker على Windows/WSL):
1. استخدم host.docker.internal بدل 127.0.0.1 داخل متغيرات البيئة في أمر docker
عندما تعمل الحاوية (container) مع Docker على Windows أو WSL، لا يمكنها غالبًا رؤية خدمة Ollama على 127.0.0.1 مباشرة من داخل الحاوية.
الحل هو تغيير متغيرات البيئة إلى:

LLM_BASE_URL="http://host.docker.internal:11434"
LLM_OLLAMA_BASE_URL="http://host.docker.internal:11434"
2. مثال لأمر تشغيل صحيح:
bash
sudo docker run -it --privileged --rm --pull=always \
  --network host \
  -e LLM_API_KEY="ollama" \
  -e LLM_BASE_URL="http://host.docker.internal:11434" \
  -e LLM_OLLAMA_BASE_URL="http://host.docker.internal:11434" \
  -e SANDBOX_RUNTIME_CONTAINER_IMAGE=docker.all-hands.dev/all-hands-ai/runtime:0.12-nikolaik \
  -v /var/run/docker.sock:/var/run/docker.sock \
  -p 3000:3000 \
  --add-host host.docker.internal:host-gateway \
  --name openhands-app \
  docker.all-hands.dev/all-hands-ai/openhands:0.12
قد لا تحتاج --network host على Windows، ويمكنك إزالتها إذا ظهرت مشاكل أو جرّب بدونها.

3. بعد تشغيل الأمر أعلاه:
أعد فتح المتصفح على http://localhost:3000
اذهب إلى AI Provider Configuration
يجب أن تظهر النماذج الآن (orca-mini:latest و llama3.2:1b)
4. إذا لم تظهر النماذج:
أعد تشغيل Ollama و OpenHands (أغلق الحاوية وأعد تشغيلها)
جرب الدخول للحاوية بهذه الطريقة:
bash
sudo docker exec -it openhands-app bash
ثم داخل الحاوية:
bash
curl http://host.docker.internal:11434/api/tags
إذا ظهرت نفس نتيجة النماذج فهذا يعني الاتصال سليم.
5. إذا ظهرت رسالة خطأ أو لم تظهر النماذج:
أرسل لي أي رسائل خطأ تظهر في الـ Terminal أو في واجهة OpenHands.
أخبرني بنتيجة الأمر داخل الحاوية.
باختصار:
المفتاح هو استخدام host.docker.internal بدل 127.0.0.1 في متغيرات البيئة عند تشغيل Docker.
جرب ذلك وأخبرني بالنتيجة!

You said: sudo docker run -it --privileged --rm --pull=always
sudo docker run -it --privileged --rm --pull=always \
  --network host \
  -e LLM_API_KEY="ollama" \
  -e LLM_BASE_URL="http://host.docker.internal:11434" \
  -e LLM_OLLAMA_BASE_URL="http://host.docker.internal:11434" \
  -e SANDBOX_RUNTIME_CONTAINER_IMAGE=docker.all-hands.dev/all-hands-ai/runtime:0.12-nikolaik \
  -v /var/run/docker.sock:/var/run/docker.sock \
  -p 3000:3000 \
  --add-host host.docker.internal:host-gateway \
  --name openhands-app \
  docker.all-hands.dev/all-hands-ai/openhands:0.12

hالرابط http://localhost:3000 لا يفتح
Copilot said: إليك خطوات التشخيص والحل بشكل منظم، بناءً
إليك خطوات التشخيص والحل بشكل منظم، بناءً على أوامرك وبيئتك (غالباً Windows أو WSL):

1. استخدام --network host مع Docker على Windows/WSL
ملحوظة هامة:
خيار --network host لا يعمل كما هو متوقع على Windows/WSL!
هو يعمل فقط على Linux native، أما على Windows/WSL/Docker Desktop فهو غالبًا يُتجاهل أو يسبب مشاكل في الشبكة.
2. الحل الأفضل: إزالة --network host
فقط استخدم:
bash
sudo docker run -it --privileged --rm --pull=always \
  -e LLM_API_KEY="ollama" \
  -e LLM_BASE_URL="http://host.docker.internal:11434" \
  -e LLM_OLLAMA_BASE_URL="http://host.docker.internal:11434" \
  -e SANDBOX_RUNTIME_CONTAINER_IMAGE=docker.all-hands.dev/all-hands-ai/runtime:0.12-nikolaik \
  -v /var/run/docker.sock:/var/run/docker.sock \
  -p 3000:3000 \
  --add-host host.docker.internal:host-gateway \
  --name openhands-app \
  docker.all-hands.dev/all-hands-ai/openhands:0.12
لا تستعمل --network host نهائيًا على Windows أو WSL.
3. بعد تشغيل الحاوية
افتح المتصفح على
Code
http://localhost:3000
إذا لم يفتح، جرب:
تحقق أن الحاوية تعمل:
bash
sudo docker ps
هل يوجد سطر باسم openhands-app؟
إذا لم يكن موجودًا أو توقفت الحاوية فجأة، أعطني نتيجة:
bash
sudo docker logs openhands-app
إذا ظهرت رسالة أن المنفذ 3000 مشغول، أوقف أي برنامج آخر يستخدمه أو غيّر المنفذ في الأمر (مثلاً: -p 3001:3000).
4. فحص المنفذ من جهازك (وليس من داخل الحاوية)
جرب:
bash
curl http://localhost:3000
أو
bash
curl http://127.0.0.1:3000
يجب أن ترى رد من التطبيق (HTML أو JSON أو رسالة ترحيب).
5. إذا ما زال لا يفتح
أعطني نتيجة:
bash
sudo docker ps
sudo docker logs openhands-app
6. ملخص سريع
لا تستخدم --network host على Windows أو WSL.
استخدم -p 3000:3000 مع host.docker.internal في المتغيرات.
تحقق أن الحاوية تعمل، وأن المنفذ غير محجوز من برنامج آخر.
تحقق من سجل الحاوية إذا لم يفتح الرابط.
إذا طبقت الخطوات وما زال لا يعمل، أرسل لي:

نتيجة sudo docker ps
نتيجة sudo docker logs openhands-app
نظام التشغيل لديك (Windows/WSL أم Linux؟)
وسأعطيك التشخيص النهائي.

You said: m@DESKTOP-MUB16F8:~$ sudo docker exec -it openhands-app bash [sudo]
m@DESKTOP-MUB16F8:~$ sudo docker exec -it openhands-app bash
[sudo] password for m:
Sorry, try again.
[sudo] password for m:
root@docker-desktop:/app# curl http://host.docker.internal:11434/api/tags
curl: (7) Failed to connect to host.docker.internal port 11434 after 6 ms: Couldn't connect to server
root@docker-desktop:/app#
Copilot said: النتيجة هنا واضحة: من داخل الحاوية
النتيجة هنا واضحة:
من داخل الحاوية (container)، لا يمكن الاتصال بـ host.docker.internal:11434.
هذا هو السبب الرئيسي لعدم ظهور نماذج Ollama داخل تطبيق OpenHands.

لماذا حدث ذلك؟
على بعض بيئات Docker (خصوصًا على WSL أو Docker Desktop)، أحيانًا لا يعمل عنوان host.docker.internal كما هو متوقع، أو قد يتطلب إعدادات إضافية.
إذا كنت تستخدم WSL2 أو Docker Desktop على Windows، أحيانًا تحتاج إلى تشغيل Ollama على كل من Windows وداخل WSL، أو تحتاج إلى ضبط إعدادات الشبكة.
خطوات الحل حسب حالتك
1. هل Ollama يعمل في نفس النظام الذي شغلت فيه Docker؟
إذا كنت تستخدم WSL2:
هل شغلت Ollama داخل WSL2 أم على Windows مباشرة؟
إذا شغلت Ollama على Windows، قد لا يكون متاحًا من داخل WSL2 إلا بعد إعدادات خاصة.
الحل الأسرع: شغل Ollama داخل نفس بيئة WSL2 التي تستخدمها مع Docker!
افتح Terminal جديد في نفس WSL2
شغل Ollama هناك (مثلاً: ollama serve أو حسب طريقة التشغيل لديك)
جرب بعدها تشغيل OpenHands بنفس الطريقة السابقة
2. جرب استخدام عنوان الـ IP مباشرة بدل host.docker.internal
احصل على عنوان الـ IP لنظامك (المضيف/host):
في WSL2:
bash
ip addr show eth0
أو
bash
hostname -I
ستجد عنوان IP مثل: 172.20.123.45
ثم شغل الحاوية بهذا الشكل:
bash
sudo docker run -it --privileged --rm --pull=always \
  -e LLM_API_KEY="ollama" \
  -e LLM_BASE_URL="http://<IP_ADDRESS>:11434" \
  -e LLM_OLLAMA_BASE_URL="http://<IP_ADDRESS>:11434" \
  ... باقي الأوامر ...
ضع مكان <IP_ADDRESS> العنوان الذي ظهر لك.
3. هل Ollama يعمل داخل Docker أيضا؟
إذا شغلت Ollama في Docker، لازم تربط الشبكة بشكل صحيح بين الحاويتين (بـ docker network).
لكن أبسط حل: شغل Ollama على نفس النظام (WSL2 أو Windows) الذي تشغل فيه OpenHands.
4. جرب من داخل الحاوية:
بعد تنفيذ الخطوات أعلاه، جرب من داخل الحاوية:
bash
curl http://<IP_ADDRESS>:11434/api/tags
يجب أن تظهر نفس النماذج.
ملخص سريع للحل:
شغل Ollama وOpenHands على نفس النظام (يفضّل داخل WSL2 إذا كنت تستخدمها).
استخدم عنوان الـ IP بدل host.docker.internal في متغيرات البيئة.
أعد تشغيل الحاوية.
جرب الاتصال من داخل الحاوية بالأمر curl كما في الخطوة 4.
إذا واجهت مشكلة في معرفة عنوان الـ IP أو في الخطوات، أعطني ناتج:

bash
hostname -I
أو

bash
ip addr show eth0
وسأعطيك الأمر المناسب بشكل مباشر بناءً على النتيجة.

You said: m@DESKTOP-MUB16F8:~$ sudo docker run -it --privileged --rm
m@DESKTOP-MUB16F8:~$ sudo docker run -it --privileged --rm --pull=always \
>   -e LLM_API_KEY="ollama" \
>   -e LLM_BASE_URL="http://host.docker.internal:11434" \
>   -e LLM_OLLAMA_BASE_URL="http://host.docker.internal:11434" \
>   -e SANDBOX_RUNTIME_CONTAINER_IMAGE=docker.all-hands.dev/all-hands-ai/runtime:0.12-nikolaik \
>   -v /var/run/docker.sock:/var/run/docker.sock \
>   -p 3000:3000 \
>   --add-host host.docker.internal:host-gateway \
>   --name openhands-app \
>   docker.all-hands.dev/all-hands-ai/openhands:0.12
[sudo] password for m:
0.12: Pulling from all-hands-ai/openhands
Digest: sha256:2e7382f8ab4defa232071ddae3bc726a25373f4b08f68aee5a3eff5af412b597
Status: Image is up to date for docker.all-hands.dev/all-hands-ai/openhands:0.12
docker: Error response from daemon: Conflict. The container name "/openhands-app" is already in use by container "5b4f2fd3009e996acba778c59ec9ee317452899c54d2a7f455f8248ffb17af83". You have to remove (or rename) that container to be able to reuse that name.

Run 'docker run --help' for more information
m@DESKTOP-MUB16F8:~$ sudo docker logs openhands-app
Starting OpenHands...
Running OpenHands as root
INFO:     Started server process [10]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:3000 (Press CTRL+C to quit)
m@DESKTOP-MUB16F8:~$
Copilot said: الرسالة تعني أن الحاوية باسم openhands-app تعمل
الرسالة تعني أن الحاوية باسم openhands-app تعمل بالفعل، لذلك لا يمكنك تشغيل واحدة أخرى بنفس الاسم.

ماذا تفعل الآن؟
الحاوية الحالية تعمل

أكّد ذلك بالأمر:
bash
sudo docker ps
ستجد الحاوية باسم openhands-app، تحقق من الأعمدة "STATUS" و "PORTS".
للوصول للتطبيق:

افتح المتصفح على:
Code
http://localhost:3000
إذا لم يعمل، جرب:
Code
curl http://localhost:3000
إذا أردت إعادة تشغيل الحاوية:

أوقف الحاوية أولاً:
bash
sudo docker stop openhands-app
ثم شغل الأمر docker run من جديد.
إذا أردت حذف الحاوية نهائياً (بعد الإيقاف):

bash
sudo docker rm openhands-app
ملخص سريع
لا يمكنك تشغيل حاويتين بنفس الاسم.
أوقف الحاوية القديمة قبل تشغيل واحدة جديدة.
الحاوية الحالية تعمل، جرّب زيارة التطبيق أو أعد تشغيل الحاوية كما بالأعلى.
إذا واجهت أي مشكلة في الوصول بعد هذه الخطوات، أرسل لي نتيجة:

bash
sudo docker ps
sudo docker logs openhands-app
curl http://localhost:3000
وسأساعدك خطوة بخطوة.

You said: ESKTOP-MUB16F8:~$ sudo docker run -it --privileged --rm
ESKTOP-MUB16F8:~$ sudo docker run -it --privileged --rm --pull=always \
>   -e LLM_API_KEY="ollama" \
>   -e LLM_BASE_URL="http://host.docker.internal:11434" \
>   -e LLM_OLLAMA_BASE_URL="http://host.docker.internal:11434" \
>   -e SANDBOX_RUNTIME_CONTAINER_IMAGE=docker.all-hands.dev/all-hands-ai/runtime:0.12-nikolaik \
>   -v /var/run/docker.sock:/var/run/docker.sock \
>   -p 3000:3000 \
>   --add-host host.docker.internal:host-gateway \
>   --name openhands-app \
>   docker.all-hands.dev/all-hands-ai/openhands:0.12
[sudo] password for m:
0.12: Pulling from all-hands-ai/openhands
Digest: sha256:2e7382f8ab4defa232071ddae3bc726a25373f4b08f68aee5a3eff5af412b597
Status: Image is up to date for docker.all-hands.dev/all-hands-ai/openhands:0.12
docker: Error response from daemon: Conflict. The container name "/openhands-app" is already in use by container "5b4f2fd3009e996acba778c59ec9ee317452899c54d2a7f455f8248ffb17af83". You have to remove (or rename) that container to be able to reuse that name.

Run 'docker run --help' for more information
m@DESKTOP-MUB16F8:~$ sudo docker logs openhands-app
Starting OpenHands...
Running OpenHands as root
INFO:     Started server process [10]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:3000 (Press CTRL+C to quit)
m@DESKTOP-MUB16F8:~$ ip addr show eth0
2: eth0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc mq state UP group default qlen 1000
    link/ether 00:15:5d:4b:03:e1 brd ff:ff:ff:ff:ff:ff
    inet 172.21.151.42/20 brd 172.21.159.255 scope global eth0
       valid_lft forever preferred_lft forever
    inet6 fe80::215:5dff:fe4b:3e1/64 scope link
       valid_lft forever preferred_lft forever
m@DESKTOP-MUB16F8:~$ hostname -I
172.21.151.42
m@DESKTOP-MUB16F8:~$
cker runm@DESKTOP-MUB16F8:~$ sudo docker run -it --privileged --rm --pull=always \
>   -e LLM_API_KEY="ollama" \
>   -e LLM_BASE_URL="http://172.21.151.42:11434" \
>   -e LLM_OLLAMA_BASE_URL="http://172.21.151.42:11434" \
  -e SA>   -e SANDBOX_RUNTIME_CONTAINER_IMAGE=docker.all-hands.dev/all-hands-ai/runtime:0.12-nikolaik \
>   -v /var/run/docker.sock:/var/run/docker.sock \
>   -p 3000:3000 \
>   --add-host host.docker.internal:host-gateway \
>   --name openhands-app \
>   docker.all-hands.dev/all-hands-ai/openhands:0.12
0.12: Pulling from all-hands-ai/openhands
Digest: sha256:2e7382f8ab4defa232071ddae3bc726a25373f4b08f68aee5a3eff5af412b597
Status: Image is up to date for docker.all-hands.dev/all-hands-ai/openhands:0.12
docker: Error response from daemon: Conflict. The container name "/openhands-app" is already in use by container "5b4f2fd3009e996acba778c59ec9ee317452899c54d2a7f455f8248ffb17af83". You have to remove (or rename) that container to be able to reuse that name.

Run 'docker run --help' for more information
m@DESKTOP-MUB16F8:~$
Copilot said: المشكلة واضحة: الحاوية (container) باسم `openhands-app`
المشكلة واضحة:
الحاوية (container) باسم openhands-app تعمل بالفعل، لذلك لا يمكنك تشغيل واحدة جديدة بنفس الاسم.
أيضًا، في كل مرة تشغل docker run بنفس الاسم، تظهر لك رسالة:

Code
docker: Error response from daemon: Conflict. The container name "/openhands-app" is already in use by container "<container_id>". You have to remove (or rename) that container to be able to reuse that name.
الحل خطوة بخطوة:
أوقف الحاوية القديمة:

bash
sudo docker stop openhands-app
(اختياري) احذف الحاوية نهائيًا إذا كانت متوقفة:

bash
sudo docker rm openhands-app
الآن أعد تشغيل الأمر مع عنوان الـ IP الجديد:

bash
sudo docker run -it --privileged --rm --pull=always \
  -e LLM_API_KEY="ollama" \
  -e LLM_BASE_URL="http://172.21.151.42:11434" \
  -e LLM_OLLAMA_BASE_URL="http://172.21.151.42:11434" \
  -e SANDBOX_RUNTIME_CONTAINER_IMAGE=docker.all-hands.dev/all-hands-ai/runtime:0.12-nikolaik \
  -v /var/run/docker.sock:/var/run/docker.sock \
  -p 3000:3000 \
  --add-host host.docker.internal:host-gateway \
  --name openhands-app \
  docker.all-hands.dev/all-hands-ai/openhands:0.12
ملاحظات مهمة:
إذا لم ترد حذف الحاوية كل مرة، يمكنك تغيير الاسم في أمر التشغيل، مثلاً:
--name openhands-app2
لو أردت التأكد من الحاويات الفعالة:
bash
sudo docker ps
إذا أردت رؤية كل الحاويات (حتى المتوقفة):
bash
sudo docker ps -a
بعد التشغيل بنجاح:
جرب الدخول على
Code
http://localhost:3000
من متصفح جهازك.
إذا لم يعمل، جرب:
Code
curl http://localhost:3000
إذا ظهرت أي رسالة خطأ أخرى أو لم يعمل التطبيق، أرسل لي ناتج هذه الأوامر:

bash
sudo docker ps
sudo docker logs openhands-app
وسأتابع معك خطوة بخطوة حتى يعمل كل شيء بإذن الله.

You said: m@DESKTOP-MUB16F8:~$ sudo docker run -it --privileged --rm
m@DESKTOP-MUB16F8:~$ sudo docker run -it --privileged --rm --pull=always \
>   -e LLM_API_KEY="ollama" \
>   -e LLM_BASE_URL="http://host.docker.internal:11434" \
>   -e LLM_OLLAMA_BASE_URL="http://host.docker.internal:11434" \
>   -e SANDBOX_RUNTIME_CONTAINER_IMAGE=docker.all-hands.dev/all-hands-ai/runtime:0.12-nikolaik \
>   -v /var/run/docker.sock:/var/run/docker.sock \
>   -p 3000:3000 \
>   --add-host host.docker.internal:host-gateway \
>   --name openhands-app \
>   docker.all-hands.dev/all-hands-ai/openhands:0.12
[sudo] password for m:
0.12: Pulling from all-hands-ai/openhands
Digest: sha256:2e7382f8ab4defa232071ddae3bc726a25373f4b08f68aee5a3eff5af412b597
Status: Image is up to date for docker.all-hands.dev/all-hands-ai/openhands:0.12
docker: Error response from daemon: Conflict. The container name "/openhands-app" is already in use by container "5b4f2fd3009e996acba778c59ec9ee317452899c54d2a7f455f8248ffb17af83". You have to remove (or rename) that container to be able to reuse that name.

Run 'docker run --help' for more information
m@DESKTOP-MUB16F8:~$ sudo docker logs openhands-app
Starting OpenHands...
Running OpenHands as root
INFO:     Started server process [10]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:3000 (Press CTRL+C to quit)
m@DESKTOP-MUB16F8:~$ ip addr show eth0
2: eth0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc mq state UP group default qlen 1000
    link/ether 00:15:5d:4b:03:e1 brd ff:ff:ff:ff:ff:ff
    inet 172.21.151.42/20 brd 172.21.159.255 scope global eth0
       valid_lft forever preferred_lft forever
    inet6 fe80::215:5dff:fe4b:3e1/64 scope link
       valid_lft forever preferred_lft forever
m@DESKTOP-MUB16F8:~$ hostname -I
172.21.151.42
m@DESKTOP-MUB16F8:~$
cker runm@DESKTOP-MUB16F8:~$ sudo docker run -it --privileged --rm --pull=always \
>   -e LLM_API_KEY="ollama" \
>   -e LLM_BASE_URL="http://172.21.151.42:11434" \
>   -e LLM_OLLAMA_BASE_URL="http://172.21.151.42:11434" \
  -e SA>   -e SANDBOX_RUNTIME_CONTAINER_IMAGE=docker.all-hands.dev/all-hands-ai/runtime:0.12-nikolaik \
>   -v /var/run/docker.sock:/var/run/docker.sock \
>   -p 3000:3000 \
>   --add-host host.docker.internal:host-gateway \
>   --name openhands-app \
>   docker.all-hands.dev/all-hands-ai/openhands:0.12
0.12: Pulling from all-hands-ai/openhands
Digest: sha256:2e7382f8ab4defa232071ddae3bc726a25373f4b08f68aee5a3eff5af412b597
Status: Image is up to date for docker.all-hands.dev/all-hands-ai/openhands:0.12
docker: Error response from daemon: Conflict. The container name "/openhands-app" is already in use by container "5b4f2fd3009e996acba778c59ec9ee317452899c54d2a7f455f8248ffb17af83". You have to remove (or rename) that container to be able to reuse that name.

Run 'docker run --help' for more information
m@DESKTOP-MUB16F8:~$ sudo docker stop openhands-app
openhands-app
m@DESKTOP-MUB16F8:~$ sudo docker run -it --privileged --rm --pull=always \
>   -e LLM_API_KEY="ollama" \
>   -e LLM_BASE_URL="http://172.21.151.42:11434" \
  -e LL>   -e LLM_OLLAMA_BASE_URL="http://172.21.151.42:11434" \
>   -e SANDBOX_RUNTIME_CONTAINER_IMAGE=docker.all-hands.dev/all-hands-ai/runtime:0.12-nikolaik \
>   -v /var/run/docker.sock:/var/run/docker.sock \
>   -p 3000:3000 \
>   --add-host host.docker.internal:host-gateway \
>   --name openhands-app \
>   docker.all-hands.dev/all-hands-ai/openhands:0.12
0.12: Pulling from all-hands-ai/openhands
Digest: sha256:2e7382f8ab4defa232071ddae3bc726a25373f4b08f68aee5a3eff5af412b597
Status: Image is up to date for docker.all-hands.dev/all-hands-ai/openhands:0.12
Starting OpenHands...
Running OpenHands as root
INFO:     Started server process [11]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:3000 (Press CTRL+C to quit)
INFO:     172.17.0.1:48658 - "GET / HTTP/1.1" 200 OK
INFO:     172.17.0.1:48658 - "GET /assets/root-C13iIuce.css HTTP/1.1" 200 OK
INFO:     172.17.0.1:48674 - "GET /assets/manifest-4225960c.js HTTP/1.1" 200 OK
INFO:     172.17.0.1:48682 - "GET /assets/entry.client-1n4ZPLSW.js HTTP/1.1" 200 OK
INFO:     172.17.0.1:48698 - "GET /assets/jsx-runtime-zhgTtAea.js HTTP/1.1" 200 OK
INFO:     172.17.0.1:48700 - "GET /assets/components-Bd8d2nMd.js HTTP/1.1" 200 OK
INFO:     172.17.0.1:48674 - "GET /assets/index-CB_aKBva.js HTTP/1.1" 200 OK
INFO:     172.17.0.1:48708 - "GET /assets/react-redux-DzUTqGNF.js HTTP/1.1" 200 OK
INFO:     172.17.0.1:48658 - "GET /assets/socket-B39-LSlI.js HTTP/1.1" 200 OK
INFO:     172.17.0.1:48682 - "GET /assets/store-CT-MXBfU.js HTTP/1.1" 200 OK
INFO:     172.17.0.1:48698 - "GET /assets/router-CQIzOUUf.js HTTP/1.1" 200 OK
INFO:     172.17.0.1:48708 - "GET /assets/index-DvhLSMS6.js HTTP/1.1" 200 OK
INFO:     172.17.0.1:48700 - "GET /assets/i18nInstance-DCxlOlkw.js HTTP/1.1" 200 OK
INFO:     172.17.0.1:48658 - "GET /assets/AgentState-DCyv5jZT.js HTTP/1.1" 200 OK
INFO:     172.17.0.1:48674 - "GET /assets/index-BgBamcox.js HTTP/1.1" 200 OK
INFO:     172.17.0.1:48698 - "GET /assets/codeSlice-IFyzp_hl.js HTTP/1.1" 200 OK
INFO:     172.17.0.1:48682 - "GET /assets/agentSlice-0xeL04tr.js HTTP/1.1" 200 OK
INFO:     172.17.0.1:48708 - "GET /assets/root-CjnzvPFH.js HTTP/1.1" 200 OK
INFO:     172.17.0.1:48708 - "GET /locales/en/translation.json HTTP/1.1" 200 OK
INFO:     172.17.0.1:48708 - "GET /favicon.ico HTTP/1.1" 200 OK
INFO:     172.17.0.1:48708 - "GET /assets/_oh-CHAvq9bt.js HTTP/1.1" 200 OK
INFO:     172.17.0.1:48698 - "GET /assets/route-B0EamsJK.js HTTP/1.1" 200 OK
INFO:     172.17.0.1:48682 - "GET /assets/github-logo-BL5HJ9fI.js HTTP/1.1" 200 OK
INFO:     172.17.0.1:48708 - "GET /assets/connect-to-github-modal-B4f7Tfpz.js HTTP/1.1" 200 OK
INFO:     172.17.0.1:48658 - "GET /assets/modal-backdrop-si9s5Ywp.js HTTP/1.1" 200 OK
INFO:     172.17.0.1:48674 - "GET /assets/open-hands-BOkBFOmY.js HTTP/1.1" 200 OK
INFO:     172.17.0.1:48700 - "GET /assets/responses-iq082X3z.js HTTP/1.1" 200 OK
INFO:     172.17.0.1:48674 - "GET /assets/user-is-authenticated-BwDnPXVy.js HTTP/1.1" 200 OK
INFO:     172.17.0.1:48682 - "GET /assets/extends-CEetKkoc.js HTTP/1.1" 200 OK
INFO:     172.17.0.1:48698 - "GET /assets/utils-p7Tk_-vA.js HTTP/1.1" 200 OK
INFO:     172.17.0.1:48708 - "GET /assets/settings-DawUpo-u.js HTTP/1.1" 200 OK
INFO:     172.17.0.1:48708 - "GET /config.json HTTP/1.1" 200 OK
INFO:     172.17.0.1:48698 - "GET /config.json HTTP/1.1" 200 OK
20:13:02 - openhands:ERROR: listen.py:413 - Error getting OLLAMA models: HTTPConnectionPool(host='172.21.151.42', port=11434): Max retries exceeded with url: /api/tags (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f32fb2ee3c0>: Failed to establish a new connection: [Errno 111] Connection refused'))
Traceback (most recent call last):
  File "/app/.venv/lib/python3.12/site-packages/urllib3/connection.py", line 199, in _new_conn
    sock = connection.create_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/urllib3/util/connection.py", line 85, in create_connection
    raise err
  File "/app/.venv/lib/python3.12/site-packages/urllib3/util/connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/app/.venv/lib/python3.12/site-packages/urllib3/connectionpool.py", line 789, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/urllib3/connectionpool.py", line 495, in _make_request
    conn.request(
  File "/app/.venv/lib/python3.12/site-packages/urllib3/connection.py", line 441, in request
    self.endheaders()
  File "/usr/local/lib/python3.12/http/client.py", line 1331, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/usr/local/lib/python3.12/http/client.py", line 1091, in _send_output
    self.send(msg)
  File "/usr/local/lib/python3.12/http/client.py", line 1035, in send
    self.connect()
  File "/app/.venv/lib/python3.12/site-packages/urllib3/connection.py", line 279, in connect
    self.sock = self._new_conn()
                ^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/urllib3/connection.py", line 214, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7f32fb2ee3c0>: Failed to establish a new connection: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/app/.venv/lib/python3.12/site-packages/requests/adapters.py", line 667, in send
    resp = conn.urlopen(
           ^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/urllib3/connectionpool.py", line 843, in urlopen
    retries = retries.increment(
              ^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/urllib3/util/retry.py", line 519, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='172.21.151.42', port=11434): Max retries exceeded with url: /api/tags (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f32fb2ee3c0>: Failed to establish a new connection: [Errno 111] Connection refused'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/app/openhands/server/listen.py", line 406, in get_litellm_models
    ollama_models_list = requests.get(ollama_url, timeout=3).json()[
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/requests/api.py", line 73, in get
    return request("get", url, params=params, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/requests/api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/requests/adapters.py", line 700, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='172.21.151.42', port=11434): Max retries exceeded with url: /api/tags (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f32fb2ee3c0>: Failed to establish a new connection: [Errno 111] Connection refused'))
INFO:     172.17.0.1:48682 - "GET /api/options/security-analyzers HTTP/1.1" 200 OK
INFO:     172.17.0.1:48698 - "GET /api/options/models HTTP/1.1" 200 OK
INFO:     172.17.0.1:48708 - "GET /api/options/agents HTTP/1.1" 200 OK
INFO:     172.17.0.1:57196 - "GET /assets/set-consent-DWbcphLP.js HTTP/1.1" 200 OK
INFO:     172.17.0.1:57196 - "GET /config.json HTTP/1.1" 200 OK
INFO:     172.17.0.1:57200 - "GET /config.json HTTP/1.1" 200 OK
INFO:     172.17.0.1:50108 - "GET /assets/settings-B80uBrgv.js HTTP/1.1" 200 OK
INFO:     172.17.0.1:50108 - "GET /config.json HTTP/1.1" 200 OK
INFO:     172.17.0.1:50124 - "GET /config.json HTTP/1.1" 200 OK
INFO:     172.17.0.1:50124 - "GET /config.json HTTP/1.1" 200 OK
INFO:     172.17.0.1:50108 - "GET /config.json HTTP/1.1" 200 OK
INFO:     172.17.0.1:50108 - "GET /config.json HTTP/1.1" 200 OK
INFO:     172.17.0.1:50124 - "GET /config.json HTTP/1.1" 200 OK
INFO:     172.17.0.1:50124 - "GET /config.json HTTP/1.1" 200 OK
INFO:     172.17.0.1:50108 - "GET /config.json HTTP/1.1" 200 OK
INFO:     172.17.0.1:57472 - "GET /config.json HTTP/1.1" 200 OK
INFO:     172.17.0.1:57482 - "GET /config.json HTTP/1.1" 200 OK
INFO:     172.17.0.1:57472 - "GET /assets/route-CCYv0vF5.js HTTP/1.1" 200 OK
INFO:     172.17.0.1:57494 - "GET /config.json HTTP/1.1" 200 OK
INFO:     172.17.0.1:57482 - "GET /assets/_oh.app-BbuKviuw.js HTTP/1.1" 200 OK
INFO:     172.17.0.1:57494 - "GET /assets/index-BXT04Q8N.js HTTP/1.1" 200 OK
INFO:     172.17.0.1:57482 - "GET /assets/index-C4MRHScb.js HTTP/1.1" 200 OK
INFO:     172.17.0.1:57472 - "GET /assets/declaration-DdUOQw3g.js HTTP/1.1" 200 OK
INFO:     172.17.0.1:57512 - "GET /assets/_oh.app-o9tOh4U3.js HTTP/1.1" 200 OK
INFO:     172.17.0.1:57502 - "GET /assets/index-wBZoZNP4.js HTTP/1.1" 200 OK
INFO:     172.17.0.1:57516 - "GET /assets/useScrollToBottom-B8_iP14x.js HTTP/1.1" 200 OK
INFO:     172.17.0.1:57494 - "GET /assets/clear-session-Bbh6tTiy.js HTTP/1.1" 200 OK
INFO:     172.17.0.1:57494 - "GET /assets/Terminal-CGrrDQr5.css HTTP/1.1" 200 OK
INFO:     172.17.0.1:57512 - "GET /assets/Terminal-DIsziyk5.js HTTP/1.1" 200 OK
20:23:04 - openhands:INFO: github.py:14 - Initializing UserVerifier
20:23:04 - openhands:INFO: github.py:27 - GITHUB_USER_LIST_FILE not configured
20:23:04 - openhands:INFO: github.py:48 - GITHUB_USERS_SHEET_ID not configured
20:23:04 - openhands:INFO: github.py:85 - No user verification sources configured - allowing all users
INFO:     ('172.17.0.1', 57520) - "WebSocket /ws" [accepted]
20:23:04 - openhands:INFO: listen.py:336 - New session: 44c59aee-a753-4ac7-82fb-ea64dfa287a8
INFO:     connection open
20:23:04 - openhands:WARNING: codeact_agent.py:101 - Function calling not supported for model ollama/llama3.2:1b. Disabling function calling.
INFO:     172.17.0.1:57512 - "GET /config.json HTTP/1.1" 200 OK
20:23:04 - openhands:INFO: base.py:98 - [runtime 44c59aee-a753-4ac7-82fb-ea64dfa287a8] Starting runtime with image: docker.all-hands.dev/all-hands-ai/runtime:0.12-nikolaik
20:23:05 - openhands:INFO: base.py:98 - [runtime 44c59aee-a753-4ac7-82fb-ea64dfa287a8] Container started: openhands-runtime-44c59aee-a753-4ac7-82fb-ea64dfa287a8
20:23:05 - openhands:INFO: base.py:98 - [runtime 44c59aee-a753-4ac7-82fb-ea64dfa287a8] Waiting for client to become ready at http://host.docker.internal:31331...
20:24:00 - openhands:INFO: base.py:98 - [runtime 44c59aee-a753-4ac7-82fb-ea64dfa287a8] Runtime is ready.
20:24:00 - openhands:WARNING: state.py:118 - Failed to restore state from session: sessions/44c59aee-a753-4ac7-82fb-ea64dfa287a8/agent_state.pkl
20:24:00 - openhands:INFO: agent_controller.py:135 - [Agent Controller 44c59aee-a753-4ac7-82fb-ea64dfa287a8] Starting step loop...
20:24:00 - openhands:INFO: agent_controller.py:135 - [Agent Controller 44c59aee-a753-4ac7-82fb-ea64dfa287a8] Setting agent(CodeActAgent) state from AgentState.LOADING to AgentState.INIT
20:24:00 - openhands:INFO: agent_controller.py:135 - [Agent Controller 44c59aee-a753-4ac7-82fb-ea64dfa287a8] Setting agent(CodeActAgent) state from AgentState.INIT to AgentState.RUNNING
20:24:00 - openhands:INFO: github.py:14 - Initializing UserVerifier
20:24:00 - openhands:INFO: github.py:27 - GITHUB_USER_LIST_FILE not configured
20:24:00 - openhands:INFO: github.py:48 - GITHUB_USERS_SHEET_ID not configured
20:24:00 - openhands:INFO: github.py:85 - No user verification sources configured - allowing all users
INFO:     172.17.0.1:53100 - "GET /config.json HTTP/1.1" 200 OK
INFO:     172.17.0.1:53110 - "GET /config.json HTTP/1.1" 200 OK
INFO:     172.17.0.1:53084 - "GET /api/list-files HTTP/1.1" 200 OK
20:24:00 - openhands:INFO: github.py:14 - Initializing UserVerifier
20:24:00 - openhands:INFO: github.py:27 - GITHUB_USER_LIST_FILE not configured
20:24:00 - openhands:INFO: github.py:48 - GITHUB_USERS_SHEET_ID not configured
20:24:00 - openhands:INFO: github.py:85 - No user verification sources configured - allowing all users
INFO:     172.17.0.1:53110 - "GET /api/list-files HTTP/1.1" 200 OK
20:24:00 - openhands:INFO: github.py:14 - Initializing UserVerifier
20:24:00 - openhands:INFO: github.py:27 - GITHUB_USER_LIST_FILE not configured
20:24:00 - openhands:INFO: github.py:48 - GITHUB_USERS_SHEET_ID not configured
20:24:00 - openhands:INFO: github.py:85 - No user verification sources configured - allowing all users
INFO:     172.17.0.1:53084 - "GET /api/list-files HTTP/1.1" 200 OK


==============
[Agent Controller 44c59aee-a753-4ac7-82fb-ea64dfa287a8] LEVEL 0 LOCAL STEP 0 GLOBAL STEP 0


Provider List: https://docs.litellm.ai/docs/providers


Provider List: https://docs.litellm.ai/docs/providers


Give Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new
LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.


Provider List: https://docs.litellm.ai/docs/providers

20:24:01 - openhands:ERROR: retry_mixin.py:47 - litellm.ServiceUnavailableError: OllamaException: HTTPConnectionPool(host='127.0.0.1', port=11434): Max retries exceeded with url: /v1/api/generate (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f32fa8984d0>: Failed to establish a new connection: [Errno 111] Connection refused')). Attempt #1 | You can customize retry values in the configuration.

Give Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new
LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.


Provider List: https://docs.litellm.ai/docs/providers

20:24:16 - openhands:ERROR: retry_mixin.py:47 - litellm.ServiceUnavailableError: OllamaException: HTTPConnectionPool(host='127.0.0.1', port=11434): Max retries exceeded with url: /v1/api/generate (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f32fa9ae810>: Failed to establish a new connection: [Errno 111] Connection refused')). Attempt #2 | You can customize retry values in the configuration.

Give Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new
LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.


Provider List: https://docs.litellm.ai/docs/providers

20:24:33 - openhands:ERROR: retry_mixin.py:47 - litellm.ServiceUnavailableError: OllamaException: HTTPConnectionPool(host='127.0.0.1', port=11434): Max retries exceeded with url: /v1/api/generate (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f32fa7fecf0>: Failed to establish a new connection: [Errno 111] Connection refused')). Attempt #3 | You can customize retry values in the configuration.

Give Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new
LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.


Provider List: https://docs.litellm.ai/docs/providers

20:24:48 - openhands:ERROR: retry_mixin.py:47 - litellm.ServiceUnavailableError: OllamaException: HTTPConnectionPool(host='127.0.0.1', port=11434): Max retries exceeded with url: /v1/api/generate (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f32fa9ef2c0>: Failed to establish a new connection: [Errno 111] Connection refused')). Attempt #4 | You can customize retry values in the configuration.

Give Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new
LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.


Provider List: https://docs.litellm.ai/docs/providers

20:25:06 - openhands:ERROR: retry_mixin.py:47 - litellm.ServiceUnavailableError: OllamaException: HTTPConnectionPool(host='127.0.0.1', port=11434): Max retries exceeded with url: /v1/api/generate (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f32fa7ffda0>: Failed to establish a new connection: [Errno 111] Connection refused')). Attempt #5 | You can customize retry values in the configuration.
Copilot said: المشكلة الآن واضحة جدًا من سجلات التطبيق: ###
المشكلة الآن واضحة جدًا من سجلات التطبيق:

ملخص الرسالة:
التطبيق OpenHands يعمل بشكل سليم على المنفذ 3000، وتستطيع الدخول عليه من المتصفح.
لكن: التطبيق غير قادر على الاتصال بخدمة Ollama على العنوان 172.21.151.42:11434 وأيضًا حاول الاتصال بـ 127.0.0.1:11434 وفشل.
تظهر رسائل مثل:
Code
Failed to establish a new connection: [Errno 111] Connection refused
الأسباب الأكثر شيوعًا:
خدمة Ollama غير مشغلة حاليًا على جهازك أو داخل WSL2.
Ollama تعمل على ويندوز وليس داخل WSL2، أو العكس، ولا يوجد اتصال شبكة بين WSL2 وبيئة Ollama.
Ollama تعمل لكن على منفذ أو عنوان مختلف.
خطوات الحل (مجرّبة وفعّالة):
1. هل أنت تستخدم WSL2؟
إذا كنت تعمل داخل WSL2 (Ubuntu على ويندوز)، يجب أن تشغّل Ollama داخل نفس بيئة WSL2، وليس على ويندوز مباشرة.
2. شغّل Ollama داخل نفس التيرمنال/بيئة WSL2
افتح تيرمنال جديد في نفس Ubuntu/WSL2 واكتب:

bash
ollama serve
يجب أن يظهر لك رسالة أن الخدمة تعمل على 127.0.0.1:11434.
3. تأكد من أن Ollama تعمل
من نفس تيرمنال WSL2:

bash
curl http://127.0.0.1:11434/api/tags
إذا ظهرت قائمة النماذج، Ollama تعمل بشكل سليم.
4. شغّل OpenHands مجددًا (ولا تغيّر متغيرات البيئة، استعمل 127.0.0.1)
شغّل الحاوية بهذه المتغيرات (في نفس WSL2):

bash
sudo docker run -it --privileged --rm --pull=always \
  -e LLM_API_KEY="ollama" \
  -e LLM_BASE_URL="http://127.0.0.1:11434" \
  -e LLM_OLLAMA_BASE_URL="http://127.0.0.1:11434" \
  -e SANDBOX_RUNTIME_CONTAINER_IMAGE=docker.all-hands.dev/all-hands-ai/runtime:0.12-nikolaik \
  -v /var/run/docker.sock:/var/run/docker.sock \
  -p 3000:3000 \
  --name openhands-app \
  docker.all-hands.dev/all-hands-ai/openhands:0.12
لا تستخدم host.docker.internal ولا الـ IP.
المفتاح هو أن يكون Ollama وOpenHands في نفس البيئة (WSL2 أو ويندوز)، والأفضل أن يكونا في WSL2.
5. إذا كنت على ويندوز فقط (وليس WSL2)
إذا كنت على ويندوز فقط، استخدم:
في CMD أو PowerShell: شغّل Ollama
ثم شغّل OpenHands في CMD وليس في WSL2
استعمل host.docker.internal في متغيرات البيئة
ملخص سريع:
إذا كنت في WSL2: شغّل Ollama وOpenHands في WSL2 واستخدم 127.0.0.1
إذا كنت في ويندوز فقط: شغّل Ollama وOpenHands في ويندوز واستخدم host.docker.internal
كيف تتأكد أن Ollama متاحة من داخل الحاوية؟
من داخل الحاوية:

bash
curl http://127.0.0.1:11434/api/tags
إذا نجح، كل شيء تمام.

إذا اتبعت الخطوات السابقة ولم تظهر النماذج أو بقي الخطأ ظاهرًا:
أخبرني:
أين تشغّل Ollama بالضبط (ويندوز أم WSL2)؟
أين تشغّل Docker/OpenHands (ويندوز أم WSL2)؟
نتيجة:
bash
curl http://127.0.0.1:11434/api/tags
من داخل الحاوية.
وسأوجهك خطوة بخطوة حسب حالتك.

You said: 20:34:44 - openhands:INFO: github.py:85 - No user
20:34:44 - openhands:INFO: github.py:85 - No user verification sources configured - allowing all users
INFO:     172.17.0.1:39860 - "GET /api/list-files HTTP/1.1" 200 OK


==============
[Agent Controller 9b610e06-50ea-4c66-91de-a2b323d94780] LEVEL 0 LOCAL STEP 0 GLOBAL STEP 0


Provider List: https://docs.litellm.ai/docs/providers


Provider List: https://docs.litellm.ai/docs/providers


Give Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new
LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.


Provider List: https://docs.litellm.ai/docs/providers

20:34:44 - openhands:ERROR: retry_mixin.py:47 - litellm.ServiceUnavailableError: OllamaException: HTTPConnectionPool(host='127.0.0.1', port=11434): Max retries exceeded with url: /v1/api/generate (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f9b13dcfa70>: Failed to establish a new connection: [Errno 111] Connection refused')). Attempt #1 | You can customize retry values in the configuration.
Copilot said: الرسالة التي ظهرت لك: ``` litellm.ServiceUnavailableError: OllamaException: HTTPConnectionPool(host='127.0.0.1', port=11434):
الرسالة التي ظهرت لك:

Code
litellm.ServiceUnavailableError: OllamaException: HTTPConnectionPool(host='127.0.0.1', port=11434): Max retries exceeded with url: /v1/api/generate (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f9b13dcfa70>: Failed to establish a new connection: [Errno 111] Connection refused'))
تعني أن تطبيق OpenHands غير قادر على الاتصال بخدمة Ollama على العنوان 127.0.0.1:11434 (الاتصال مرفوض).

الأسباب الشائعة والحل النهائي
1. خدمة Ollama غير مفعّلة أو ليست في نفس البيئة
يجب أن تكون خدمة Ollama مفعّلة وتعمل في نفس البيئة (نفس WSL2 أو نفس نظام لينكس/ويندوز) التي تشغّل فيها OpenHands.
2. كيف تتأكد أن Ollama تعمل؟
في نفس التيرمنال (أو نافذة WSL2) التي تشغّل فيها OpenHands، نفّذ:

bash
ps aux | grep ollama
أو

bash
curl http://127.0.0.1:11434/api/tags
إذا لم يظهر أي رد أو ظهر "connection refused"، إذًا Ollama غير مفعّلة.
3. الحل خطوة بخطوة
أ) إذا كنت تعمل في WSL2 أو في لينكس:
شغّل Ollama في تيرمنال WSL2:

bash
ollama serve
يجب أن تظهر رسالة مثل:

Code
ollama: listening on 127.0.0.1:11434
في نافذة أخرى، شغّل OpenHands بنفس الإعدادات (متغيرات البيئة لـ 127.0.0.1).

ب) إذا كنت تعمل على ويندوز فقط:
شغّل Ollama من CMD أو PowerShell.
شغّل Docker/OpenHands من نفس ويندوز وليس WSL2.
استخدم host.docker.internal في متغيرات البيئة.
4. تحقق من الاتصال من داخل الحاوية
بعد تشغيل الحاوية:

bash
sudo docker exec -it openhands-app curl http://127.0.0.1:11434/api/tags
إذا لم تظهر قائمة النماذج، فهذا يعني أن الحاوية لا تستطيع رؤية Ollama على هذا العنوان.
ملخص سريع للحل:
شغّل Ollama في نفس بيئة OpenHands/Docker (يفضّل داخل WSL2 إن كنت تستخدم WSL2).
استخدم 127.0.0.1 في متغيرات البيئة إذا كنت في نفس النظام، أو host.docker.internal إذا كنت تستخدم Docker على ويندوز فقط.
تأكد أن Ollama تعمل وترد على المنفذ 11434 قبل تشغيل OpenHands.
جرب الاتصال من داخل الحاوية كما في الخطوة 4 بالأعلى.
إذا لم تنجح، أخبرني:

أين تشغّل Ollama؟ (داخل WSL2 أم على ويندوز أم في لينكس عادي؟)
أين تشغّل Docker/OpenHands؟
نتيجة:
bash
curl http://127.0.0.1:11434/api/tags
من داخل الحاوية ومن خارجها.
سأعطيك الحل النهائي بناءً على وضعك!

You said: انا شغال فى والس 2 جو ويندوز
انا شغال فى والس 2 جو ويندوز 10
تم تثبيت اولاما فى والس2 وتم تحميل النموذج فى اولاما داخل والس والنموذج مرئى ولكن الاتصال لا يعمل
Copilot said: شكرًا لتوضيح البيئة التي تعمل عليها!
شكرًا لتوضيح البيئة التي تعمل عليها!
الآن أصبح واضحًا أنك:

تستخدم WSL2 على ويندوز 10.
Ollama مُثبت ويعمل داخل WSL2 (وليس على ويندوز مباشرة).
النموذج في Ollama مرئي من داخل WSL2.
لكن OpenHands لا يستطيع الاتصال بـ Ollama (connection refused).
السبب الأساسي للمشكلة
عندما تشغل Docker داخل WSL2:

الحاوية (container) ترى نفسها كـ "جهاز مستقل" داخل نفس شبكة WSL2، لكنها لا تستطيع دائمًا الوصول إلى خدمات تعمل على 127.0.0.1 في الـ host (WSL2) مباشرة.
لذلك، الاتصال بـ 127.0.0.1:11434 من داخل الحاوية لن يصل غالبًا إلى Ollama الذي يعمل على WSL2، بل يحاول الاتصال بنفس الحاوية فقط.
الحل الأكـثر ذكاءً (مجرّب ومضمون):
1. اجعل Ollama تستمع على جميع الشبكات (0.0.0.0)
افتح تيرمنال WSL2 واوقف Ollama (إذا كان شغالًا):

bash
pkill ollama
ثم شغل Ollama ليعمل على جميع الشبكات:

bash
OLLAMA_HOST=0.0.0.0 ollama serve
أو (في بعض الإصدارات):

bash
export OLLAMA_HOST=0.0.0.0
ollama serve
الآن Ollama سيستمع على كل الشبكات داخل WSL2 وليس فقط على 127.0.0.1.

2. استخدم عنوان IP الخاص بـ WSL2 في متغيرات Docker
احصل على عنوان الـ IP الخاص بـ WSL2:

bash
hostname -I
(سيظهر لك مثل: 172.21.151.42)

شغل OpenHands بهذا الأمر (استبدل <WSL2_IP> بالعنوان الذي ظهر لك):

bash
sudo docker run -it --privileged --rm --pull=always \
  -e LLM_API_KEY="ollama" \
  -e LLM_BASE_URL="http://<WSL2_IP>:11434" \
  -e LLM_OLLAMA_BASE_URL="http://<WSL2_IP>:11434" \
  -e SANDBOX_RUNTIME_CONTAINER_IMAGE=docker.all-hands.dev/all-hands-ai/runtime:0.12-nikolaik \
  -v /var/run/docker.sock:/var/run/docker.sock \
  -p 3000:3000 \
  --name openhands-app \
  docker.all-hands.dev/all-hands-ai/openhands:0.12
3. اختبر الاتصال من داخل الحاوية
بعد تشغيل الحاوية:

bash
sudo docker exec -it openhands-app curl http://<WSL2_IP>:11434/api/tags
إذا ظهرت النماذج: تم الحل!
إذا لم تظهر: تأكد أن Ollama يعمل على 0.0.0.0 وليست هناك جدران نارية تمنع الاتصال.
ملخص سريع:
شغل Ollama على 0.0.0.0 (وليس 127.0.0.1)
استخدم IP الخاص بـ WSL2 في Docker
اختبر الاتصال من داخل الحاوية
إذا واجهت مشكلة في أي خطوة، أرسل لي نتيجة: 1.

bash
echo $OLLAMA_HOST
bash
hostname -I
من داخل الحاوية:
bash
curl http://<WSL2_IP>:11434/api/tags
وسأكمل معك الحل حتى يعمل كل شيء بإذن الله.

You said: m@DESKTOP-MUB16F8:~$ pkill ollama pkill: killing pid 215 failed:
m@DESKTOP-MUB16F8:~$ pkill ollama
pkill: killing pid 215 failed: Operation not permitted
m@DESKTOP-MUB16F8:~$ OLLAMA_HOST=0.0.0.0 ollama serve
Error: listen tcp 0.0.0.0:11434: bind: address already in use
m@DESKTOP-MUB16F8:~$





m@DESKTOP-MUB16F8:~$ hostname -I
172.21.151.42
m@DESKTOP-MUB16F8:~$
Copilot said: المشكلة واضحة الآن: - عندما تحاول تشغيل Ollama
المشكلة واضحة الآن:

عندما تحاول تشغيل Ollama على
Code
OLLAMA_HOST=0.0.0.0 ollama serve
تظهر الرسالة:
Code
Error: listen tcp 0.0.0.0:11434: bind: address already in use
وهذا يعني أن Ollama أو برنامج آخر ما زال يستخدم المنفذ 11434 بالفعل!
خطوات الحل
1. معرفة من يستخدم المنفذ 11434
نفّذ الأمر التالي في WSL2:

bash
sudo lsof -i :11434
أو

bash
sudo netstat -tulpn | grep 11434
سيظهر لك رقم الـ PID للعملية التي تحتل المنفذ.
2. إيقاف العملية التي تحتل المنفذ
إذا رأيت سطرًا مثل:

Code
ollama    215   ...   LISTEN
فهذا هو رقم الـ PID (هنا 215).

اقتل العملية (مع sudo):

bash
sudo kill -9 215
(استبدل 215 برقم الـ PID الذي يظهر لك)

3. تأكد أن المنفذ أصبح حرًّا
كرر:

bash
sudo lsof -i :11434
إذا لم يظهر شيء، أصبح المنفذ جاهز.
4. شغّل Ollama من جديد على كل الشبكات
bash
OLLAMA_HOST=0.0.0.0 ollama serve
5. جرّب الآن من الحاوية:
bash
curl http://172.21.151.42:11434/api/tags
إذا ظهرت النماذج: الحل نجح!
ملخص سريع:
اعرف من يحتل المنفذ 11434 (lsof أو netstat)
اقتل العملية بالـ PID مع sudo
أعد تشغيل ollama على 0.0.0.0
جرب curl من الحاوية أو حتى من جهازك
إذا واجهت أي مشكلة في أي خطوة، أرسل لي نتيجة:
bash
sudo lsof -i :11434
أو
bash
sudo netstat -tulpn | grep 11434
وسأرشدك تحديدًا.

You said: m@DESKTOP-MUB16F8:~$ pkill ollama pkill: killing pid 215 failed:
m@DESKTOP-MUB16F8:~$ pkill ollama
pkill: killing pid 215 failed: Operation not permitted
m@DESKTOP-MUB16F8:~$ OLLAMA_HOST=0.0.0.0 ollama serve
Error: listen tcp 0.0.0.0:11434: bind: address already in use
m@DESKTOP-MUB16F8:~$ export OLLAMA_HOST=0.0.0.0
llama sem@DESKTOP-MUB16F8:~$ ollama serve
Error: listen tcp 0.0.0.0:11434: bind: address already in use
m@DESKTOP-MUB16F8:~$ hostname -I
172.21.151.42
m@DESKTOP-MUB16F8:~$ curl http://172.21.151.42:11434/api/tags
curl: (7) Failed to connect to 172.21.151.42 port 11434 after 0 ms: Couldn't connect to server
m@DESKTOP-MUB16F8:~$
Copilot said: الرسائل تقول بوضوح: - **المنفذ 11434 مشغول بالفعل**
الرسائل تقول بوضوح:

المنفذ 11434 مشغول بالفعل (هناك Ollama أو برنامج آخر يستخدمه).
كل محاولة لتشغيل Ollama على هذا المنفذ تفشل.
لا يمكنك الاتصال على http://172.21.151.42:11434/api/tags لأن الخدمة ليست فعالة عليه.
الحل خطوة بخطوة (افعل بالترتيب):
1. معرفة العملية التي تحتل المنفذ 11434
نفذ:

bash
sudo lsof -i :11434
أو:

bash
sudo netstat -tulpn | grep 11434
2. اقتل العملية المسيطرة على المنفذ
إذا ظهر مثلاً:
Code
ollama   215    ...   LISTEN
نفذ:
bash
sudo kill -9 215
(استبدل 215 برقم الـ PID الفعلي الذي يظهر لك)
3. تأكد أن المنفذ أصبح فارغًا
كرر:

bash
sudo lsof -i :11434
إذا لم يظهر لك شيء، المنفذ أصبح متاحًا.
4. شغل Ollama ليستمع على كل الشبكات
bash
OLLAMA_HOST=0.0.0.0 ollama serve
يجب أن تظهر رسالة مثل:
listening on 0.0.0.0:11434
5. اختبر الوصول من WSL2
من ترمنال جديد:

bash
curl http://127.0.0.1:11434/api/tags
curl http://172.21.151.42:11434/api/tags
يجب أن تظهر النماذج المحمّلة.
6. اختبر الوصول من داخل الحاوية (Docker)
bash
sudo docker exec -it openhands-app curl http://172.21.151.42:11434/api/tags
يجب أن تظهر نفس النتيجة.
إذا ما زال لا يظهر شيء
أرسل لي نتيجة:
bash
sudo lsof -i :11434
أو
bash
sudo netstat -tulpn | grep 11434
وأيضًا:
bash
ps aux | grep ollama
بعد حل مشكلة المنفذ، ستعمل Ollama مع OpenHands بإذن الله.
أي مشكلة أو نتيجة للأوامر السابقة، انسخها هنا وسأتابع معك خطوة بخطوة حتى يتم الحل النهائي.

You said: m@DESKTOP-MUB16F8:~$ pkill ollama pkill: killing pid 215 failed:
m@DESKTOP-MUB16F8:~$ pkill ollama
pkill: killing pid 215 failed: Operation not permitted
m@DESKTOP-MUB16F8:~$ OLLAMA_HOST=0.0.0.0 ollama serve
Error: listen tcp 0.0.0.0:11434: bind: address already in use
m@DESKTOP-MUB16F8:~$ export OLLAMA_HOST=0.0.0.0
llama sem@DESKTOP-MUB16F8:~$ ollama serve
Error: listen tcp 0.0.0.0:11434: bind: address already in use
m@DESKTOP-MUB16F8:~$ hostname -I
172.21.151.42
m@DESKTOP-MUB16F8:~$ curl http://172.21.151.42:11434/api/tags
curl: (7) Failed to connect to 172.21.151.42 port 11434 after 0 ms: Couldn't connect to server
m@DESKTOP-MUB16F8:~$ curl http://172.21.151.42:11434/api/tags
curl: (7) Failed to connect to 172.21.151.42 port 11434 after 0 ms: Couldn't connect to server
m@DESKTOP-MUB16F8:~$ curl http://172.21.151.42:11434/api/tags
curl: (7) Failed to connect to 172.21.151.42 port 11434 after 0 ms: Couldn't connect to server
m@DESKTOP-MUB16F8:~$
Copilot said: أنت الآن في الخطوة الصحيحة، لكن هناك
أنت الآن في الخطوة الصحيحة، لكن هناك عملية شغالة بالفعل على المنفذ 11434 (غالبًا Ollama)، ولا تملك الصلاحية لإيقافها بأمر pkill ollama (لأنه يحتاج sudo).

الحل السريع خطوة بخطوة:
1. اكتشف العملية التي تحتل المنفذ 11434
نفذ الأمر التالي:

bash
sudo lsof -i :11434
أو:

bash
sudo netstat -tulpn | grep 11434
سيظهر لك سطر فيه رقم الـ PID (رقم العملية) مثل:

Code
ollama   215   ...   LISTEN
2. اقتل العملية بصلاحية sudo
نفذ:

bash
sudo kill -9 215
(استبدل 215 برقم الـ PID الذي ظهر لك من الخطوة السابقة)

3. تأكد أن المنفذ أصبح فارغ
كرر:

bash
sudo lsof -i :11434
لو لم يظهر شيء، المنفذ أصبح متاحًا.

4. شغل Ollama ليستمع على كل الشبكات
الآن:

bash
OLLAMA_HOST=0.0.0.0 ollama serve
يجب أن تظهر رسالة شبيهة بـ:

Code
listening on 0.0.0.0:11434
5. اختبر الاتصال من WSL2
bash
curl http://127.0.0.1:11434/api/tags
curl http://172.21.151.42:11434/api/tags
لو ظهر لك JSON فيه النماذج، كل شيء تمام.

6. اختبر الاتصال من داخل الحاوية (اختياري)
bash
sudo docker exec -it openhands-app curl http://172.21.151.42:11434/api/tags
لو ظهرت النماذج، كل شيء يعمل!

ملخص سريع:
استخدم sudo لقتل العملية التي تحتل المنفذ.
أعد تشغيل Ollama على 0.0.0.0.
اختبر الاتصال من WSL2 (وأيضًا من داخل الحاوية إذا أردت).
إذا واجهت أي مشكلة في الخطوات أعلاه، أرسل لي ناتج:

bash
sudo lsof -i :11434
ps aux | grep ollama
وسأرشدك بدقة للخطوة التالية!

You said: m@DESKTOP-MUB16F8:~$ pkill ollama pkill: killing pid 215 failed:
m@DESKTOP-MUB16F8:~$ pkill ollama
pkill: killing pid 215 failed: Operation not permitted
m@DESKTOP-MUB16F8:~$ OLLAMA_HOST=0.0.0.0 ollama serve
Error: listen tcp 0.0.0.0:11434: bind: address already in use
m@DESKTOP-MUB16F8:~$ export OLLAMA_HOST=0.0.0.0
llama sem@DESKTOP-MUB16F8:~$ ollama serve
Error: listen tcp 0.0.0.0:11434: bind: address already in use
m@DESKTOP-MUB16F8:~$ hostname -I
172.21.151.42
m@DESKTOP-MUB16F8:~$ curl http://172.21.151.42:11434/api/tags
curl: (7) Failed to connect to 172.21.151.42 port 11434 after 0 ms: Couldn't connect to server
m@DESKTOP-MUB16F8:~$ curl http://172.21.151.42:11434/api/tags
curl: (7) Failed to connect to 172.21.151.42 port 11434 after 0 ms: Couldn't connect to server
m@DESKTOP-MUB16F8:~$ curl http://172.21.151.42:11434/api/tags
curl: (7) Failed to connect to 172.21.151.42 port 11434 after 0 ms: Couldn't connect to server
m@DESKTOP-MUB16F8:~$ OLLAMA_HOST=0.0.0.0 ollama serve
Error: listen tcp 0.0.0.0:11434: bind: address already in use
m@DESKTOP-MUB16F8:~$ sudo docker exec -it openhands-app curl http://172.21.151.42:11434/api/tags
[sudo] password for m:
Sorry, try again.
[sudo] password for m:
Error response from daemon: No such container: openhands-app
m@DESKTOP-MUB16F8:~$


m@DESKTOP-MUB16F8:~$ curl http://127.0.0.1:11434/api/tags
rl http://172.21.151.42:11434/api/tags{"models":[{"name":"orca-mini:latest","model":"orca-mini:latest","modified_at":"2025-05-25T20:54:12.622513707-07:00","size":1979947443,"digest":"2dbd9f439647093cf773c325b0b3081a11f1b1426d61dee8b946f8f6555a1755","details":{"parent_model":"","format":"gguf","family":"llama","families":null,"parameter_size":"3B","quantization_level":"Q4_0"}},{"name":"llama3.2:1b","model":"llama3.2:1b","modified_at":"2025-05-25T16:05:31.90019971-07:00","size":1321098329,"digest":"baf6a787fdffd633537aa2eb51cfd54cb93ff08e28040095462bb63daf552878","details":{"parent_model":"","format":"gguf","family":"llama","families":["llama"],"parameter_size":"1.2B","quantization_level":"Q8_0"}}]}m@DESKTOP-MUB16F8:~$ curl http://172.21.151.42:11434/api/tags
curl: (7) Failed to connect to 172.21.151.42 port 11434 after 0 ms: Couldn't connect to server
m@DESKTOP-MUB16F8:~$ curl http://127.0.0.1:11434/api/tags
//172.21.151.42:11434/api/tags{"models":[{"name":"orca-mini:latest","model":"orca-mini:latest","modified_at":"2025-05-25T20:54:12.622513707-07:00","size":1979947443,"digest":"2dbd9f439647093cf773c325b0b3081a11f1b1426d61dee8b946f8f6555a1755","details":{"parent_model":"","format":"gguf","family":"llama","families":null,"parameter_size":"3B","quantization_level":"Q4_0"}},{"name":"llama3.2:1b","model":"llama3.2:1b","modified_at":"2025-05-25T16:05:31.90019971-07:00","size":1321098329,"digest":"baf6a787fdffd633537aa2eb51cfd54cb93ff08e28040095462bb63daf552878","details":{"parent_model":"","format":"gguf","family":"llama","families":["llama"],"parameter_size":"1.2B","quantization_level":"Q8_0"}}]}m@DESKTOP-MUB16F8:~$ curl http://172.21.151.42:11434/api/tags
Copilot said: رائع! لقد وضحت الصورة النهائية الآن: - **Ollama
رائع! لقد وضحت الصورة النهائية الآن:

Ollama تعمل بشكل سليم على 127.0.0.1:11434 داخل WSL2، ويمكنك رؤية النماذج باستخدام:
bash
curl http://127.0.0.1:11434/api/tags
لكن
لا يمكنك الوصول إلى Ollama عبر عنوان IP الخاص بـ WSL2 (172.21.151.42:11434)، وهذا طبيعي لأن Ollama افتراضيًا تستمع فقط على 127.0.0.1 (أي loopback interface فقط).
ماذا يعني هذا؟
من داخل WSL2: أي برنامج يستخدم 127.0.0.1:11434 سيصل إلى Ollama (ممتاز!).
من داخل حاوية Docker في WSL2: غالبًا لن يستطيع الوصول إلى 127.0.0.1 الخاص بك، لأنه يمثل الحاوية نفسها.
الحل النهائي (مجرب وفعّال):
1. أوقف كل عمليات Ollama (بحاجة sudo)
bash
sudo lsof -i :11434
خُذ الـ PID من العمود الثاني، ثم:

bash
sudo kill -9 <PID>
كرر حتى يصبح المنفذ فارغًا:

bash
sudo lsof -i :11434
(لا يجب أن يظهر أي شيء)

2. شغّل Ollama ليستمع على جميع الشبكات (0.0.0.0)
bash
OLLAMA_HOST=0.0.0.0 ollama serve
يجب أن تظهر رسالة مثل:

Code
listening on 0.0.0.0:11434
3. اختبر من داخل WSL2
bash
curl http://127.0.0.1:11434/api/tags
curl http://172.21.151.42:11434/api/tags
يجب أن يعملا معًا الآن.

4. شغّل الحاوية مع متغيرات البيئة الصحيحة:
bash
sudo docker run -it --privileged --rm --pull=always \
  -e LLM_API_KEY="ollama" \
  -e LLM_BASE_URL="http://172.21.151.42:11434" \
  -e LLM_OLLAMA_BASE_URL="http://172.21.151.42:11434" \
  -e SANDBOX_RUNTIME_CONTAINER_IMAGE=docker.all-hands.dev/all-hands-ai/runtime:0.12-nikolaik \
  -v /var/run/docker.sock:/var/run/docker.sock \
  -p 3000:3000 \
  --name openhands-app \
  docker.all-hands.dev/all-hands-ai/openhands:0.12
5. اختبر من داخل الحاوية:
bash
sudo docker exec -it openhands-app curl http://172.21.151.42:11434/api/tags
إذا ظهرت النماذج: كل شيء جاهز!

إذا لم تتمكن من قتل العملية بالـ sudo
أعد تشغيل WSL2 بالكامل (يمكنك تنفيذ: wsl --shutdown من ويندوز ثم أعد فتح Ubuntu).
فور الفتح، شغّل الأمر:
bash
OLLAMA_HOST=0.0.0.0 ollama serve
ملخص سريع:
أوقف كل عمليات Ollama (sudo).
شغّل Ollama على 0.0.0.0.
استخدم IP WSL2 في متغيرات البيئة لـ Docker.
اختبر من داخل الحاوية.
إذا ظهرت النماذج: تم الحل 100%!
إذا واجهت أي صعوبة في قتل العملية أو ظهرت رسالة رفض صلاحيات حتى مع sudo، أعد تشغيل WSL2 بالكامل من ويندوز.
أي سؤال أو نتيجة، شاركني بها وسأتابع معك خطوة بخطوة!

You said: Error response from daemon: No such container:
Error response from daemon: No such container: openhands-app
m@DESKTOP-MUB16F8:~$ sudo lsof -i :11434
aux | grep ollamaps aux | grep ollamaCOMMAND PID   USER   FD   TYPE DEVICE SIZE/OFF NODE NAME
ollama  215 ollama    3u  IPv4  28870      0t0  TCP localhost:11434 (LISTEN)
m@DESKTOP-MUB16F8:~$
Copilot said: ممتاز! الآن ظهرت العملية التي تحتل المنفذ
ممتاز! الآن ظهرت العملية التي تحتل المنفذ 11434:

Code
ollama  215 ollama    3u  IPv4  28870      0t0  TCP localhost:11434 (LISTEN)
الـ PID للعملية هو 215
تعمل باسم المستخدم ollama
تستمع فقط على localhost:11434 (أي 127.0.0.1 فقط، وليس 0.0.0.0)
المطلوب الآن:
1. أوقف العملية الحالية (بحاجة sudo)
نفّذ:

bash
sudo kill -9 215
(إذا ظهر Permission denied أو لم ينجح، جرب إضافة sudo أمام الأمر دائمًا)

2. تأكد أن العملية توقفت والمنفذ أصبح فارغًا
نفّذ:

bash
sudo lsof -i :11434
إذا لم يظهر شيء، انتقل للخطوة التالية.

3. شغّل Ollama ليستمع على جميع الشبكات
نفّذ:

bash
OLLAMA_HOST=0.0.0.0 ollama serve
يجب أن تظهر رسالة مثل:

Code
listening on 0.0.0.0:11434
4. اختبر الوصول من WSL2:
bash
curl http://127.0.0.1:11434/api/tags
curl http://172.21.151.42:11434/api/tags
يجب أن تظهر النماذج في كلا الحالتين.

5. بعدها شغّل الحاوية Docker واستخدم العنوان 172.21.151.42 في متغيرات البيئة كما شرحت لك سابقًا.
إذا واجهت أي مشكلة في تنفيذ sudo kill -9 215 (مثل "Permission denied")، أرسل لي رسالة الخطأ، وسأرشدك للحل البديل (إعادة تشغيل WSL2 بالكامل).

بانتظار نتيجتك بعد تنفيذ هذه الخطوات!

You said: -bash: syntax error near unexpected token `newline' m@DESKTOP-MUB16F8:~$
-bash: syntax error near unexpected token `newline'
m@DESKTOP-MUB16F8:~$ sudo lsof -i :11434
COMMAND PID   USER   FD   TYPE DEVICE SIZE/OFF NODE NAME
ollama  215 ollama    3u  IPv4  28870      0t0  TCP localhost:11434 (LISTEN)
m@DESKTOP-MUB16F8:~$ sudo lsof -i :11434
COMMAND PID   USER   FD   TYPE DEVICE SIZE/OFF NODE NAME
ollama  215 ollama    3u  IPv4  28870      0t0  TCP localhost:11434 (LISTEN)
m@DESKTOP-MUB16F8:~$ sudo lsof -i :11434
COMMAND PID   USER   FD   TYPE DEVICE SIZE/OFF NODE NAME
ollama  215 ollama    3u  IPv4  28870      0t0  TCP localhost:11434 (LISTEN)
m@DESKTOP-MUB16F8:~$ sudo lsof -i :11434
COMMAND PID   USER   FD   TYPE DEVICE SIZE/OFF NODE NAME
ollama  215 ollama    3u  IPv4  28870      0t0  TCP localhost:11434 (LISTEN)
m@DESKTOP-MUB16F8:~$ sudo lsof -i :11434
COMMAND PID   USER   FD   TYPE DEVICE SIZE/OFF NODE NAME
ollama  215 ollama    3u  IPv4  28870      0t0  TCP localhost:11434 (LISTEN)
m@DESKTOP-MUB16F8:~$ sudo lsof -i :11434
COMMAND PID   USER   FD   TYPE DEVICE SIZE/OFF NODE NAME
ollama  215 ollama    3u  IPv4  28870      0t0  TCP localhost:11434 (LISTEN)
m@DESKTOP-MUB16F8:~$ sudo lsof -i :11434
COMMAND PID   USER   FD   TYPE DEVICE SIZE/OFF NODE NAME
ollama  215 ollama    3u  IPv4  28870      0t0  TCP localhost:11434 (LISTEN)
m@DESKTOP-MUB16F8:~$



m@DESKTOP-MUB16F8:~$ sudo kill -9 <PID>
-bash: syntax error near unexpected token `newline'
m@DESKTOP-MUB16F8:~$ sudo kill -9 <PID>
-bash: syntax error near unexpected token `newline'
m@DESKTOP-MUB16F8:~$ sudo kill -9 <PID>
-bash: syntax error near unexpected token `newline'
m@DESKTOP-MUB16F8:~$



Copilot said: المشكلة في الأمر الذي تكتبه: ```bash sudo kill -9
المشكلة في الأمر الذي تكتبه:

bash
sudo kill -9 <PID>
علامة <PID> ليست أمرًا تكتبه حرفيًا، بل يجب أن تستبدلها برقم العملية الفعلي الذي ظهر لك في نتيجة lsof.

من نتائجك السابقة:

رقم الـ PID هو 215.
الحل:
نفّذ هذا الأمر بالضبط:

bash
sudo kill -9 215
بعدها:

أعد تنفيذ:

bash
sudo lsof -i :11434
يجب ألا يظهر أي شيء (المنفذ أصبح فارغًا).

ثم شغّل:

bash
OLLAMA_HOST=0.0.0.0 ollama serve
وتأكد:

bash
curl http://127.0.0.1:11434/api/tags
curl http://172.21.151.42:11434/api/tags
إذا واجهت أي رسالة خطأ أو لم تفهم خطوة، أرسل لي الرسالة كما هي وسأكمل معك!

You said: m@DESKTOP-MUB16F8:~$ sudo kill -9 * kill: invalid
m@DESKTOP-MUB16F8:~$  sudo kill -9 *
kill: invalid argument

Usage:
 kill [options] <pid> [...]

Options:
 <pid> [...]            send signal to every <pid> listed
 -<signal>, -s, --signal <signal>
                        specify the <signal> to be sent
 -q, --queue <value>    integer value to be sent with the signal
 -l, --list=[<signal>]  list all signal names, or convert one to a name
 -L, --table            list all signal names in a nice table

 -h, --help     display this help and exit
 -V, --version  output version information and exit

For more details see kill(1).
m@DESKTOP-MUB16F8:~$
Copilot said: الخطأ سببه أنك استخدمت `*` بدل رقم
الخطأ سببه أنك استخدمت * بدل رقم العملية (PID).
يجب أن تكتب رقم العملية فقط.

من نتائجك السابقة:

رقم الـ PID للعملية هو 215.
اكتب الأمر هكذا بالضبط:
bash
sudo kill -9 215
ملخص الخطوات:

نفذ الأمر أعلاه فقط.
بعد ذلك تأكد أن العملية توقفت:
bash
sudo lsof -i :11434
إذا لم يظهر لك أي شيء: المنفذ أصبح فارغًا.
شغّل Ollama ليستمع على كل الشبكات:
bash
OLLAMA_HOST=0.0.0.0 ollama serve
لو واجهت أي رسالة خطأ أو لم تفهم شيء، أرسل لي الرسالة كما هي وسأساعدك فورًا!

You said: m@DESKTOP-MUB16F8:~$ curl http://127.0.0.1:11434/api/tags url http://172.21.151.42:11434/api/tags{"models":[{"name":"orca-mini:latest","model":"orca-mini:latest","modified_at":"2025-05-25T20:54:12.622513707-07:00","size":1979947443,"digest":"2dbd9f439647093cf773c325b0b3081a11f1b1426d61dee8b946f8f6555a1755","details":{"parent_model":"","format":"gguf","family":"llama","families":null,"parameter_size":"3B","quantization_level":"Q4_0"}},{"name":"llama3.2:1b","model":"llama3.2:1b","modified_at":"2025-05-25T16:05:31.90019971-07:00","size":1321098329,"digest":"baf6a787fdffd633537aa2eb51cfd54cb93ff08e28040095462bb63daf552878","details":{"parent_model":"","format":"gguf","family":"llama","families":["llama"],"parameter_size":"1.2B","quantization_level":"Q8_0"}}]}m@DESKTOP-MUB16F8:~$ curl http://172.21.151.42:11434/api/tags curl: (7)
m@DESKTOP-MUB16F8:~$ curl http://127.0.0.1:11434/api/tags
url http://172.21.151.42:11434/api/tags{"models":[{"name":"orca-mini:latest","model":"orca-mini:latest","modified_at":"2025-05-25T20:54:12.622513707-07:00","size":1979947443,"digest":"2dbd9f439647093cf773c325b0b3081a11f1b1426d61dee8b946f8f6555a1755","details":{"parent_model":"","format":"gguf","family":"llama","families":null,"parameter_size":"3B","quantization_level":"Q4_0"}},{"name":"llama3.2:1b","model":"llama3.2:1b","modified_at":"2025-05-25T16:05:31.90019971-07:00","size":1321098329,"digest":"baf6a787fdffd633537aa2eb51cfd54cb93ff08e28040095462bb63daf552878","details":{"parent_model":"","format":"gguf","family":"llama","families":["llama"],"parameter_size":"1.2B","quantization_level":"Q8_0"}}]}m@DESKTOP-MUB16F8:~$ curl http://172.21.151.42:11434/api/tags
curl: (7) Failed to connect to 172.21.151.42 port 11434 after 0 ms: Couldn't connect to server
m@DESKTOP-MUB16F8:~$
Copilot said: الآن أصبح واضحاً تماماً: - **Ollama تعمل فقط
الآن أصبح واضحاً تماماً:

Ollama تعمل فقط على 127.0.0.1:11434 داخل WSL2.
لا تعمل ولا تستمع على 172.21.151.42:11434 (IP الخاص بـ WSL2)، ولهذا لا يمكن الوصول إليها من الحاويات (Docker containers) أو من خارج WSL2.
لماذا؟
لأن Ollama تعمل فقط على الـ loopback (العنوان المحلي) وليس على جميع الشبكات. يجب أن تجعلها تعمل على جميع الشبكات (0.0.0.0) حتى تصبح متاحة على عنوان الـ IP الخاص بـ WSL2.

الحل النهائي خطوة بخطوة (بتجربة ناجحة):
1. اقتل كل عمليات Ollama بصلاحية sudo
نفذ:

bash
sudo lsof -i :11434
سيظهر لك شيء مثل:

Code
ollama  215 ollama    3u  IPv4  28870      0t0  TCP localhost:11434 (LISTEN)
الرقم في العمود الثاني هو الـ PID (مثلاً: 215).
اقتله:

bash
sudo kill -9 215
كرر حتى يصبح:

bash
sudo lsof -i :11434
بدون أي نتيجة.

2. شغّل ollama ليستمع على جميع الشبكات
نفذ:

bash
OLLAMA_HOST=0.0.0.0 ollama serve
يجب أن تظهر رسالة مثل:

Code
listening on 0.0.0.0:11434
3. اختبر من داخل WSL2
نفذ:

bash
curl http://127.0.0.1:11434/api/tags
curl http://172.21.151.42:11434/api/tags
يجب أن تظهر نفس النتيجة في كلا الحالتين (قائمة النماذج).

4. الآن يمكنك ضبط متغيرات البيئة في Docker
استخدم:

http://172.21.151.42:11434 في متغيرات البيئة لـ OpenHands أو أي خدمة في Docker.
5. إذا لم تستطع قتل العملية أو ظهرت مشاكل صلاحيات
أعد تشغيل WSL2 بالكامل:

في ويندوز، أغلق كل ترمنالات Ubuntu.
في CMD (ويندوز)، اكتب:
Code
wsl --shutdown
أعد فتح Ubuntu، وابدأ من جديد:
bash
OLLAMA_HOST=0.0.0.0 ollama serve
ملخص:
يجب قتل كل عمليات Ollama ثم تشغيلها على 0.0.0.0.
بعدها ستعمل على كل الشبكات، وسيظهر النموذج على كل من 127.0.0.1 و IP الخاص بـ WSL2.
إذا واجهت "Permission denied" أو لم تستطع قتل العملية: أعد تشغيل WSL2 بالكامل.
إذا اتبعت هذه الخطوات بدقة ولم ينجح الأمر، أرسل لي نتيجة:

bash
sudo lsof -i :11434
مباشرة بعد محاولة قتل العملية.

سأبقى معك حتى تعمل! 🚦

You said: بدل التكرار الا يوجد عملية تقتل pid
بدل التكرار الا يوجد عملية تقتل pid مرة واحدة
Copilot said: نعم، يمكنك قتل العملية مباشرة مرة واحدة
نعم، يمكنك قتل العملية مباشرة مرة واحدة باستخدام أمر واحد فقط، بدون تكرار أو تكرار البحث عن الـPID.
إذا كنت تريد قتل جميع العمليات التي تخص ollama على المنفذ 11434 دفعة واحدة، استخدم أحد الأوامر التالية:

1. قتل كل عمليات ollama باسم البرنامج:
bash
sudo pkill -f ollama
أو:

bash
sudo killall ollama
2. قتل كل العمليات التي تستخدم المنفذ 11434 دفعة واحدة:
bash
sudo lsof -t -i :11434 | xargs sudo kill -9
هذا الأمر يجد كل الـPID التي تستخدم المنفذ 11434 ويقتلها كلها دفعة واحدة.
3. للتأكد أن المنفذ أصبح فارغًا:
bash
sudo lsof -i :11434
إذا لم يظهر أي شيء، فالمنفذ أصبح فارغًا وجاهز.

ملخص:
أفضل وأسرع أمر لقتل كل العمليات على المنفذ 11434 هو:

bash
sudo lsof -t -i :11434 | xargs sudo kill -9
هل تحتاج شرحًا لأي أمر؟

You said: m@DESKTOP-MUB16F8:~$ sudo pkill -f ollama m@DESKTOP-MUB16F8:~$ sudo killall
m@DESKTOP-MUB16F8:~$ sudo pkill -f ollama
m@DESKTOP-MUB16F8:~$ sudo killall ollama
m@DESKTOP-MUB16F8:~$ sudo lsof -t -i :11434 | xargs sudo kill -9
m@DESKTOP-MUB16F8:~$ sudo lsof -i :11434
COMMAND  PID   USER   FD   TYPE DEVICE SIZE/OFF NODE NAME
ollama  4720 ollama    3u  IPv4  77819      0t0  TCP localhost:11434 (LISTEN)
m@DESKTOP-MUB16F8:~$
Copilot said: الآن الوضع واضح: كل أوامر القتل
الآن الوضع واضح:
كل أوامر القتل تم تنفيذها، لكن العملية ollama لا تزال تعمل وتستمع على localhost:11434 باسم المستخدم ollama.

لماذا لم تُقتل العملية؟
لأن العملية تعمل باسم المستخدم ollama وليس باسمك (m)، وقد يكون هذا المستخدم محمي أو يعمل كخدمة (systemd service)، أو تم تشغيلها بطريقة تجعلها تُعاد تلقائيًا، أو تشتغل تلقائيًا في الخلفية عند إعادة تشغيل النظام.

جرب الخطوات التالية بالترتيب:
1. معرفة كيف تم تشغيل ollama:
نفذ:

bash
ps aux | grep ollama
وابحث عن السطر الذي فيه:

Code
ollama   4720  ...
هل هو مذكور كـ /usr/bin/ollama serve أم كـ service أو أي شيء آخر؟

2. أوقف خدمة ollama إن كانت تعمل كخدمة
نفذ:

bash
sudo systemctl stop ollama
ثم:

bash
sudo lsof -i :11434
إذا لم يظهر شيء، المنفذ أصبح متاح.

3. أعد تشغيل ollama بالطريقة الصحيحة
بعد التأكد أن المنفذ فارغ:

bash
OLLAMA_HOST=0.0.0.0 ollama serve
(أو حسب طريقة تشغيلك أنت في بيئة WSL2)

4. إذا استمرت المشكلة ولم تستطع قتل العملية:
الحل النهائي:
أعد تشغيل WSL2 بالكامل (سيقتل كل العمليات ويعيد الذاكرة نظيفة):

أغلق جميع نوافذ/تيرمنالات Ubuntu/WSL2.
في CMD أو PowerShell على ويندوز، نفّذ:
Code
wsl --shutdown
أعد فتح Ubuntu، ثم مباشرة:
bash
OLLAMA_HOST=0.0.0.0 ollama serve
ملخص:

جرب إيقاف الخدمة: sudo systemctl stop ollama
إذا لم تنجح: أعد تشغيل WSL2 بالكامل.
بعدها شغّل Ollama كما تريد (على 0.0.0.0).
إذا أرسلت لي نتيجة:

bash
ps aux | grep ollama
سأستطيع تحديد بالضبط كيف تعمل العملية وكيف نوقفها نهائيًا.
بانتظارك!

You said: m@DESKTOP-MUB16F8:~$ ps aux | grep ollama ollama
m@DESKTOP-MUB16F8:~$ ps aux | grep ollama
ollama    4769  6.0  0.0 2076656 30852 ?       Ssl  13:51   0:00 /usr/local/bin/ollama serve
m         4785  0.0  0.0   4092  1944 pts/4    S+   13:51   0:00 grep --color=auto ollama
m@DESKTOP-MUB16F8:~$
Copilot said: ممتاز، الآن الصورة واضحة جدًا: - العملية التي
ممتاز، الآن الصورة واضحة جدًا:

العملية التي تشغّل Ollama هي:
Code
ollama    4769  ...  /usr/local/bin/ollama serve
وهي تعمل باسم المستخدم ollama وليس باسمك (m).
كيف تقتل العملية بشكل مضمون؟
أنت تملك صلاحية الـsudo، إذًا نفذ الأمر التالي (لاحظ رقم الـPID هو 4769):

bash
sudo kill -9 4769
انتظر ثانية ثم تأكد أن العملية توقفت:

bash
ps aux | grep ollama
sudo lsof -i :11434
إذا لم يظهر شيء، العملية توقفت والمنفذ أصبح فارغًا.

الخطوة التالية:
بعد أن تتأكد أن العملية انتهت:

شغّل Ollama ليستمع على جميع الشبكات:
bash
OLLAMA_HOST=0.0.0.0 ollama serve
جرب:
bash
curl http://127.0.0.1:11434/api/tags
curl http://<IP الخاص بك>:11434/api/tags
(استبدل <IP الخاص بك> بـ 172.21.151.42 أو ما يظهر عندك من hostname -I)
ملخص:
استخدم الرقم الفعلي للعملية (4769) في أمر القتل.
بعد القتل، أعد تشغيل Ollama بالـ OLLAMA_HOST المناسب.
الآن يمكن أي برنامج في WSL2 أو Docker الوصول للمنفذ عبر عنوان IP.
إذا واجهت أي رسالة خطأ أو لم تجد العملية بعد القتل، أرسل لي النتيجة كما هي!

You said: m@DESKTOP-MUB16F8:~$ ps aux | grep ollama m
m@DESKTOP-MUB16F8:~$ ps aux | grep ollama
m         4835  0.0  0.0   4092  1952 pts/4    S+   13:53   0:00 grep --color=auto ollama
m@DESKTOP-MUB16F8:~$ sudo kill -9 4835
kill: (4835): No such process
m@DESKTOP-MUB16F8:~$ sudo kill -9 4769
kill: (4769): No such process
m@DESKTOP-MUB16F8:~$ ps aux | grep ollama
do lsof -i :11434m         4843  0.0  0.0   4092  1840 pts/4    S+   13:53   0:00 grep --color=auto ollama
m@DESKTOP-MUB16F8:~$ sudo lsof -i :11434
m@DESKTOP-MUB16F8:~$
Copilot said: ممتاز! كل شيء يعمل كما ينبغي
ممتاز!
كل شيء يعمل كما ينبغي الآن:

عملية ollama لم تعد تعمل (لا تظهر في ps aux).
المنفذ 11434 أصبح فارغًا (لا يظهر شيء في lsof).
الآن شغّل Ollama بالعنوان الصحيح
شغّل الأمر التالي:

bash
OLLAMA_HOST=0.0.0.0 ollama serve
يجب أن تظهر رسالة مثل:

Code
listening on 0.0.0.0:11434
اختبر من داخل WSL2
جرب:

bash
curl http://127.0.0.1:11434/api/tags
curl http://172.21.151.42:11434/api/tags
(استبدل 172.21.151.42 بالعنوان الذي يعطيك إياه hostname -I لو تغير)

إذا ظهرت قائمة النماذج في كلا الحالتين: أنت جاهز وستعمل مع Docker أيضًا.
إذا واجهت أي رسالة خطأ في التشغيل أو الاختبار، انسخها هنا وسأرشدك فورًا.
أنت على بُعد خطوة واحدة من النجاح! 🚦

You said: m@DESKTOP-MUB16F8:~$ curl http://127.0.0.1:11434/api/tags url http://<IP الخاص بك>:11434/api/tags{"models":[]}m@DESKTOP-MUB16F8:~$ curl
m@DESKTOP-MUB16F8:~$ curl http://127.0.0.1:11434/api/tags
url http://<IP الخاص بك>:11434/api/tags{"models":[]}m@DESKTOP-MUB16F8:~$ curl http://<IP الخاص بك>:11434/api/tags
-bash: IP: No such file or directory
m@DESKTOP-MUB16F8:~$ OLLAMA_HOST=0.0.0.0 ollama serve
Error: listen tcp 0.0.0.0:11434: bind: address already in use
m@DESKTOP-MUB16F8:~$ curl http://127.0.0.1:11434/api/tags
://172.21.151.42:11434/api/tags{"models":[]}m@DESKTOP-MUB16F8:~$ curl http://172.21.151.42:11434/api/tags
{"models":[]}m@DESKTOP-MUB16F8:~$ curl http://127.0.0.1:11434/api/tags
{"models":[]}m@DESKTOP-MUB16F8:~$
m@DESKTOP-MUB16F8:~$
m@DESKTOP-MUB16F8:~$
m@DESKTOP-MUB16F8:~$ curl http://127.0.0.1:11434/api/tags
{"models":[]}m@DESKTOP-MUB16F8:~$ curl http://172.21.151.42:11434/api/tags
{"models":[]}m@DESKTOP-MUB16F8:~$
m@DESKTOP-MUB16F8:~$
m@DESKTOP-MUB16F8:~$ curl http://172.21.151.42:11434/api/tags
{"models":[]}m@DESKTOP-MUB16F8:~$


Copilot said: ممتاز، الآن Ollama تعمل بشكل صحيح على
ممتاز، الآن Ollama تعمل بشكل صحيح على كل من:

127.0.0.1:11434
172.21.151.42:11434
ونتيجة الـ curl هي:

JSON
{"models":[]}
ماذا يعني هذا؟
السيرفر شغال بشكل صحيح ويستقبل الطلبات من كل العناوين، لكن لا يوجد أي نموذج (Model) مثبت حاليًا في Ollama.
لهذا السبب الـ API تُرجع {"models":[]} في كل الحالات.
ما الخطوة التالية؟
1. تثبيت نموذج (Model) في Ollama
مثلاً لتثبيت نموذج llama3:

bash
ollama pull llama3
أو نموذج orca-mini:

bash
ollama pull orca-mini
انتظر حتى ينتهي التحميل (قد يأخذ عدة دقائق حسب سرعة الإنترنت).

2. تحقق مجددًا من النماذج
بعد اكتمال التحميل، جرب:

bash
curl http://127.0.0.1:11434/api/tags
أو

bash
curl http://172.21.151.42:11434/api/tags
يجب أن تظهر قائمة بالنماذج التي قمت بتحميلها، مثل:

JSON
{"models":[{"name":"llama3:latest", ...}]}
3. الآن يمكنك استخدام Ollama من أي مكان (WSL2، Docker، إلخ).
ملخص:
كل شيء يعمل، فقط حمّل نموذجًا في Ollama ليظهر في القائمة وتبدأ بالاستفادة منه.

هل ترغب في معرفة كيفية تحميل نموذج معين أو استخدامه؟ اكتب لي اسم النموذج أو الغرض وسأعطيك الأمر المناسب!

You said: m@DESKTOP-MUB16F8:~$ OLLAMA_HOST=0.0.0.0 ollama serve Error: listen tcp 0.0.0.0:11434:
m@DESKTOP-MUB16F8:~$ OLLAMA_HOST=0.0.0.0 ollama serve
Error: listen tcp 0.0.0.0:11434: bind: address already in use
m@DESKTOP-MUB16F8:~$ sudo systemctl stop ollama
[sudo] password for m:
Sorry, try again.
[sudo] password for m:
m@DESKTOP-MUB16F8:~$ ps aux | grep ollama
m         4835  0.0  0.0   4092  1952 pts/4    S+   13:53   0:00 grep --color=auto ollama
m@DESKTOP-MUB16F8:~$ sudo kill -9 4835
kill: (4835): No such process
m@DESKTOP-MUB16F8:~$ sudo kill -9 4769
kill: (4769): No such process
m@DESKTOP-MUB16F8:~$ ps aux | grep ollama
do lsof -i :11434m         4843  0.0  0.0   4092  1840 pts/4    S+   13:53   0:00 grep --color=auto ollama
m@DESKTOP-MUB16F8:~$ sudo lsof -i :11434
m@DESKTOP-MUB16F8:~$ OLLAMA_HOST=0.0.0.0 ollama serve
time=2025-05-26T13:54:14.061-07:00 level=INFO source=routes.go:1205 msg="server config" env="map[CUDA_VISIBLE_DEVICES: GPU_DEVICE_ORDINAL: HIP_VISIBLE_DEVICES: HSA_OVERRIDE_GFX_VERSION: HTTPS_PROXY: HTTP_PROXY: NO_PROXY: OLLAMA_CONTEXT_LENGTH:4096 OLLAMA_DEBUG:INFO OLLAMA_FLASH_ATTENTION:false OLLAMA_GPU_OVERHEAD:0 OLLAMA_HOST:http://0.0.0.0:11434 OLLAMA_INTEL_GPU:false OLLAMA_KEEP_ALIVE:5m0s OLLAMA_KV_CACHE_TYPE: OLLAMA_LLM_LIBRARY: OLLAMA_LOAD_TIMEOUT:5m0s OLLAMA_MAX_LOADED_MODELS:0 OLLAMA_MAX_QUEUE:512 OLLAMA_MODELS:/home/m/.ollama/models OLLAMA_MULTIUSER_CACHE:false OLLAMA_NEW_ENGINE:false OLLAMA_NOHISTORY:false OLLAMA_NOPRUNE:false OLLAMA_NUM_PARALLEL:0 OLLAMA_ORIGINS:[http://localhost https://localhost http://localhost:* https://localhost:* http://127.0.0.1 https://127.0.0.1 http://127.0.0.1:* https://127.0.0.1:* http://0.0.0.0 https://0.0.0.0 http://0.0.0.0:* https://0.0.0.0:* app://* file://* tauri://* vscode-webview://* vscode-file://*] OLLAMA_SCHED_SPREAD:false ROCR_VISIBLE_DEVICES: http_proxy: https_proxy: no_proxy:]"
time=2025-05-26T13:54:14.066-07:00 level=INFO source=images.go:463 msg="total blobs: 0"
time=2025-05-26T13:54:14.066-07:00 level=INFO source=images.go:470 msg="total unused blobs removed: 0"
time=2025-05-26T13:54:14.067-07:00 level=INFO source=routes.go:1258 msg="Listening on [::]:11434 (version 0.7.1)"
time=2025-05-26T13:54:14.067-07:00 level=INFO source=gpu.go:217 msg="looking for compatible GPUs"
time=2025-05-26T13:54:19.453-07:00 level=INFO source=gpu.go:377 msg="no compatible GPUs were discovered"
time=2025-05-26T13:54:19.453-07:00 level=INFO source=types.go:130 msg="inference compute" id=0 library=cpu variant="" compute="" driver=0.0 name="" total="31.3 GiB" available="29.7 GiB"
[GIN] 2025/05/26 - 13:54:31 | 200 |    1.836124ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/26 - 13:55:04 | 200 |     186.208µs |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/26 - 13:55:05 | 200 |     117.219µs |   172.21.151.42 | GET      "/api/tags"
[GIN] 2025/05/26 - 13:55:19 | 200 |      101.48µs |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/26 - 13:55:22 | 200 |     133.932µs |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/05/26 - 13:55:31 | 200 |     125.854µs |   172.21.151.42 | GET      "/api/tags"
[GIN] 2025/05/26 - 13:55:34 | 200 |     100.679µs |   172.21.151.42 | GET      "/api/tags"



Copilot said: ممتاز! كل شيء يعمل كما يجب
ممتاز!
كل شيء يعمل كما يجب الآن:

Ollama تعمل على جميع الشبكات (0.0.0.0:11434)
تظهر في السجلات ([GIN] ... GET "/api/tags") أن السيرفر يستقبل الطلبات بنجاح من كلا:
127.0.0.1
172.21.151.42
ماذا يعني هذا؟
بإمكانك الآن الوصول إلى Ollama من داخل WSL2، ومن الحاويات (Docker)، أو حتى من برامج أخرى على نفس الجهاز.
السيرفر جاهز تمامًا للعمل.
ملاحظة مهمة:
إذا واجهت في المستقبل مشكلة "address already in use"، استخدم هذه الخطوات:

اعرف رقم العملية:
bash
sudo lsof -i :11434
اقتل العملية:
bash
sudo lsof -t -i :11434 | xargs sudo kill -9
ماذا بعد؟
إذا أردت تثبيت نموذج:
bash
ollama pull llama3
أو أي نموذج آخر مثل:
bash
ollama pull orca-mini
بعد التحميل، جرب:
bash
curl http://127.0.0.1:11434/api/tags
يجب أن ترى النماذج ضمن قائمة models.
إذا احتجت أي أمر إضافي أو شرح عن كيفية ربط Ollama مع Docker أو تطبيق آخر، أخبرني بما تريد بالتحديد وسأدلك على الخطوات المناسبة! 🎯

You said: الان سيعمل اوبن هاندس مع النموذج الجدد
الان سيعمل اوبن هاندس مع النموذج الجدد ؟
Copilot said: نعم، الآن سيعمل OpenHands مع Ollama بشكل
نعم، الآن سيعمل OpenHands مع Ollama بشكل صحيح بعد تنفيذ الخطوات التالية، بشرط أن:

Ollama يعمل على 0.0.0.0:
(وقد تحقق ذلك بنجاح من السجلات الأخيرة لديك.)

يمكن الوصول إلى Ollama من عنوان الشبكة الخاص بـ WSL2
(وقد تحقق ذلك عندما أعطاك curl نتيجة صحيحة من
curl http://172.21.151.42:11434/api/tags
أو أي عنوان IP آخر خاص بـ WSL2.)

تقوم بتحميل النموذج الذي تريده في Ollama
(حتى الآن قائمة النماذج لديك فارغة. يجب تنفيذ أمر مثل:

bash
ollama pull llama3
أو أي نموذج آخر تحتاجه.)

تضبط OpenHands ليستخدم عنوان Ollama الصحيح
في إعدادات OpenHands أو متغيرات البيئة الخاصة به (مثلاً عند تشغيل الحاوية Docker)، يجب أن يكون متغير الاتصال بـ Ollama هو:

Code
http://172.21.151.42:11434
أو حسب عنوان IP الخاص بك.

ملخص الخطوات التي يجب التأكد منها:
شغّل Ollama على 0.0.0.0 (تم ✅)

حمّل النموذج الذي تحتاجه (مثلاً llama3 أو orca-mini)

bash
ollama pull llama3
تأكد أن النموذج ظهر في:

bash
curl http://127.0.0.1:11434/api/tags
يجب أن تظهر قائمة فيها اسم النموذج.

شغّل OpenHands واجعل عنوان Ollama هو
http://172.21.151.42:11434
أو حسب عنوان الشبكة الذي ظهر عندك.

إذا اتبعت هذا بالترتيب:
سيعمل OpenHands مع Ollama والنموذج الجديد فوراً بإذن الله.

إذا واجهت أي رسالة خطأ، انسخها هنا وسأحلها معك خطوة بخطوة!

How can I help you?

Copilot said: نعم، الآن سيعمل OpenHands مع Ollama بشكل نعم، الآن سيعمل OpenHands مع Ollama بشكل صحيح بعد تنفيذ الخطوات التالية، بشرط أن: Ollama يعمل على 0.0.0.0: (وقد تحقق ذلك بنجاح من السجلات الأخيرة لديك.) يمكن الوصول إلى Ollama من عنوان الشبكة الخاص بـ WSL2 (وقد تحقق ذلك عندما أعطاك curl نتيجة صحيحة من curl http://172.21.151.42:11434/api/tags أو أي عنوان IP آخر خاص بـ WSL2.) تقوم بتحميل النموذج الذي تريده في Ollama (حتى الآن قائمة النماذج لديك فارغة. يجب تنفيذ أمر مثل: bash ollama pull llama3 أو أي نموذج آخر تحتاجه.) تضبط OpenHands ليستخدم عنوان Ollama الصحيح في إعدادات OpenHands أو متغيرات البيئة الخاصة به (مثلاً عند تشغيل الحاوية Docker)، يجب أن يكون متغير الاتصال بـ Ollama هو: Code http://172.21.151.42:11434 أو حسب عنوان IP الخاص بك. ملخص الخطوات التي يجب التأكد منها: شغّل Ollama على 0.0.0.0 (تم ✅) حمّل النموذج الذي تحتاجه (مثلاً llama3 أو orca-mini) bash ollama pull llama3 تأكد أن النموذج ظهر في: bash curl http://127.0.0.1:11434/api/tags يجب أن تظهر قائمة فيها اسم النموذج. شغّل OpenHands واجعل عنوان Ollama هو http://172.21.151.42:11434 أو حسب عنوان الشبكة الذي ظهر عندك. إذا اتبعت هذا بالترتيب: سيعمل OpenHands مع Ollama والنموذج الجديد فوراً بإذن الله. إذا واجهت أي رسالة خطأ، انسخها هنا وسأحلها معك خطوة بخطوة!























































m@DESKTOP-MUB16F8:~$ curl http://127.0.0.1:11434/api/tags
url http://<IP الخاص بك>:11434/api/tags{"models":[]}m@DESKTOP-MUB16F8:~$ curl http://<IP الخاص بك>:11434/api/tags
-bash: IP: No such file or directory
m@DESKTOP-MUB16F8:~$ OLLAMA_HOST=0.0.0.0 ollama serve
Error: listen tcp 0.0.0.0:11434: bind: address already in use
m@DESKTOP-MUB16F8:~$ curl http://127.0.0.1:11434/api/tags
://172.21.151.42:11434/api/tags{"models":[]}m@DESKTOP-MUB16F8:~$ curl http://172.21.151.42:11434/api/tags
{"models":[]}m@DESKTOP-MUB16F8:~$ curl http://127.0.0.1:11434/api/tags
{"models":[]}m@DESKTOP-MUB16F8:~$
m@DESKTOP-MUB16F8:~$
m@DESKTOP-MUB16F8:~$
m@DESKTOP-MUB16F8:~$ curl http://127.0.0.1:11434/api/tags
{"models":[]}m@DESKTOP-MUB16F8:~$ curl http://172.21.151.42:11434/api/tags
{"models":[]}m@DESKTOP-MUB16F8:~$
m@DESKTOP-MUB16F8:~$
m@DESKTOP-MUB16F8:~$ curl http://172.21.151.42:11434/api/tags
{"models":[]}m@DESKTOP-MUB16F8:~$ ollama list
NAME    ID    SIZE    MODIFIED
m@DESKTOP-MUB16F8:~$ ollama pull llama3
pulling manifest
pulling 6a0746a1ec1a: 100% ▕██████████████████████████████████████████████████████████▏ 4.7 GB
pulling 4fa551d4f938: 100% ▕██████████████████████████████████████████████████████████▏  12 KB
pulling 8ab4849b038c: 100% ▕██████████████████████████████████████████████████████████▏  254 B
pulling 577073ffcc6c: 100% ▕██████████████████████████████████████████████████████████▏  110 B
pulling 3f8eb4da87fa: 100% ▕██████████████████████████████████████████████████████████▏  485 B
verifying sha256 digest
writing manifest
success
m@DESKTOP-MUB16F8:~$ ollama list
NAME             ID              SIZE      MODIFIED
llama3:latest    365c0bd3c000    4.7 GB    48 seconds ago
m@DESKTOP-MUB16F8:~$ docker run -it --rm \
-e OLLAM>   -e OLLAMA_HOST="http://172.21.151.42:11434" \
>   -e LLM_OLLAMA_BASE_URL="http://172.21.151.42:11434" \
>   -e SANDBOX_RUNTIME_CONTAINER_IMAGE=docker.all-hands.dev/all-hands-ai/runtime:0.12-nikolaik \
 /var/>   -v /var/run/docker.sock:/var/run/docker.sock \
>   -p 3000:3000 \
>   --add-host host.docker.internal:host-gateway \
>   --name openhands-app \
>   docker.all-hands.dev/all-hands-ai/openhands:0.12
Starting OpenHands...
Running OpenHands as root
INFO:     Started server process [10]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:3000 (Press CTRL+C to quit)
INFO:     172.17.0.1:38464 - "GET / HTTP/1.1" 200 OK
INFO:     172.17.0.1:38464 - "GET /locales/en/translation.json HTTP/1.1" 200 OK
INFO:     172.17.0.1:38464 - "GET /config.json HTTP/1.1" 200 OK
INFO:     172.17.0.1:38472 - "GET /config.json HTTP/1.1" 200 OK
INFO:     172.17.0.1:38472 - "GET /config.json HTTP/1.1" 200 OK
21:23:20 - openhands:INFO: github.py:14 - Initializing UserVerifier
21:23:20 - openhands:INFO: github.py:27 - GITHUB_USER_LIST_FILE not configured
21:23:20 - openhands:INFO: github.py:48 - GITHUB_USERS_SHEET_ID not configured
21:23:20 - openhands:INFO: github.py:85 - No user verification sources configured - allowing all users
INFO:     ('172.17.0.1', 38484) - "WebSocket /ws" [accepted]
21:23:20 - openhands:ERROR: auth.py:27 - Invalid token
INFO:     connection open
INFO:     172.17.0.1:38472 - "GET /api/options/models HTTP/1.1" 200 OK
INFO:     172.17.0.1:38464 - "GET /api/options/agents HTTP/1.1" 200 OK
INFO:     172.17.0.1:38488 - "GET /api/options/security-analyzers HTTP/1.1" 200 OK
INFO:     connection closed
INFO:     172.17.0.1:38488 - "GET /config.json HTTP/1.1" 200 OK
INFO:     172.17.0.1:38472 - "GET /config.json HTTP/1.1" 200 OK
INFO:     172.17.0.1:45728 - "GET / HTTP/1.1" 200 OK
INFO:     172.17.0.1:45728 - "GET /favicon.ico HTTP/1.1" 200 OK
INFO:     172.17.0.1:45728 - "GET /locales/en/translation.json HTTP/1.1" 200 OK
INFO:     172.17.0.1:45728 - "GET /config.json HTTP/1.1" 200 OK
INFO:     172.17.0.1:45732 - "GET /config.json HTTP/1.1" 200 OK
INFO:     172.17.0.1:45728 - "GET /api/options/agents HTTP/1.1" 200 OK
INFO:     172.17.0.1:45732 - "GET /api/options/models HTTP/1.1" 200 OK
INFO:     172.17.0.1:45748 - "GET /api/options/security-analyzers HTTP/1.1" 200 OK
INFO:     172.17.0.1:39856 - "GET /assets/settings-B80uBrgv.js HTTP/1.1" 200 OK
INFO:     172.17.0.1:39856 - "GET /config.json HTTP/1.1" 200 OK
INFO:     172.17.0.1:39856 - "GET /config.json HTTP/1.1" 200 OK
INFO:     172.17.0.1:39856 - "GET /config.json HTTP/1.1" 200 OK
INFO:     172.17.0.1:39862 - "GET /config.json HTTP/1.1" 200 OK
INFO:     172.17.0.1:39862 - "GET /config.json HTTP/1.1" 200 OK
INFO:     172.17.0.1:39856 - "GET /config.json HTTP/1.1" 200 OK
INFO:     172.17.0.1:59718 - "GET /assets/_oh.app-BbuKviuw.js HTTP/1.1" 200 OK
INFO:     172.17.0.1:59730 - "GET /config.json HTTP/1.1" 200 OK
INFO:     172.17.0.1:59722 - "GET /assets/route-CCYv0vF5.js HTTP/1.1" 200 OK
INFO:     172.17.0.1:59718 - "GET /assets/_oh.app-o9tOh4U3.js HTTP/1.1" 200 OK
INFO:     172.17.0.1:59730 - "GET /assets/index-BXT04Q8N.js HTTP/1.1" 200 OK
INFO:     172.17.0.1:59744 - "GET /assets/clear-session-Bbh6tTiy.js HTTP/1.1" 200 OK
INFO:     172.17.0.1:59734 - "GET /assets/declaration-DdUOQw3g.js HTTP/1.1" 200 OK
INFO:     172.17.0.1:59740 - "GET /assets/useScrollToBottom-B8_iP14x.js HTTP/1.1" 200 OK
INFO:     172.17.0.1:59722 - "GET /assets/index-C4MRHScb.js HTTP/1.1" 200 OK
INFO:     172.17.0.1:59730 - "GET /assets/index-wBZoZNP4.js HTTP/1.1" 200 OK
INFO:     172.17.0.1:59718 - "GET /assets/Terminal-DIsziyk5.js HTTP/1.1" 200 OK
INFO:     172.17.0.1:59730 - "GET /assets/Terminal-CGrrDQr5.css HTTP/1.1" 200 OK
21:24:36 - openhands:INFO: github.py:14 - Initializing UserVerifier
21:24:36 - openhands:INFO: github.py:27 - GITHUB_USER_LIST_FILE not configured
21:24:36 - openhands:INFO: github.py:48 - GITHUB_USERS_SHEET_ID not configured
21:24:36 - openhands:INFO: github.py:85 - No user verification sources configured - allowing all users
INFO:     ('172.17.0.1', 59758) - "WebSocket /ws" [accepted]
21:24:36 - openhands:INFO: listen.py:336 - New session: b2d909c7-e4d1-4858-9f41-e3be86a78fb6
INFO:     connection open
21:24:36 - openhands:WARNING: codeact_agent.py:101 - Function calling not supported for model ollama/llama3:latest. Disabling function calling.
INFO:     172.17.0.1:59718 - "GET /config.json HTTP/1.1" 200 OK
21:24:36 - openhands:INFO: base.py:98 - [runtime b2d909c7-e4d1-4858-9f41-e3be86a78fb6] Starting runtime with image: docker.all-hands.dev/all-hands-ai/runtime:0.12-nikolaik
21:24:37 - openhands:INFO: base.py:98 - [runtime b2d909c7-e4d1-4858-9f41-e3be86a78fb6] Container started: openhands-runtime-b2d909c7-e4d1-4858-9f41-e3be86a78fb6
21:24:37 - openhands:INFO: base.py:98 - [runtime b2d909c7-e4d1-4858-9f41-e3be86a78fb6] Waiting for client to become ready at http://host.docker.internal:36771...











































m@DESKTOP-MUB16F8:~$ curl http://127.0.0.1:11434/api/tags
url http://0.0.0.0:11434/api/tags
curl http://<IP-WSL2>:11434/api/tags
curl http://host.docker.internal:11434/api/tags{"models":[{"name":"llama3:latest","model":"llama3:latest","modified_at":"2025-05-26T14:20:43.158646446-07:00","size":4661224676,"digest":"365c0bd3c000a25d28ddbf732fe1c6add414de7275464c4e4d1c3b5fcb5d8ad1","details":{"parent_model":"","format":"gguf","family":"llama","families":["llama"],"parameter_size":"8.0B","quantization_level":"Q4_0"}}]}m@DESKTOP-MUB16F8:~$ curl http://0.0.0.0:11434/api/tags
{"models":[{"name":"llama3:latest","model":"llama3:latest","modified_at":"2025-05-26T14:20:43.158646446-07:00","size":4661224676,"digest":"365c0bd3c000a25d28ddbf732fe1c6add414de7275464c4e4d1c3b5fcb5d8ad1","details":{"parent_model":"","format":"gguf","family":"llama","families":["llama"],"parameter_size":"8.0B","quantization_level":"Q4_0"}}]}m@DESKTOP-MUB16F8:~$ curl http://<IP-WSL2>:11434/api/tags
-bash: IP-WSL2: No such file or directory
m@DESKTOP-MUB16F8:~$ curl http://host.docker.internal:11434/api/tags
curl: (7) Failed to connect to host.docker.internal port 11434 after 1 ms: Couldn't connect to server
m@DESKTOP-MUB16F8:~$ hostname -I
172.21.151.42
m@DESKTOP-MUB16F8:~$ docker run --rm -it ubuntu:24.04 bash
 ثم داخل الحاوية:
apt update && apt install -y curl
curl http://172.21.151.42:11434/api/tagsUnable to find image 'ubuntu:24.04' locally

24.04: Pulling from library/ubuntu
0622fac788ed: Pull complete
Digest: sha256:6015f66923d7afbc53558d7ccffd325d43b4e249f41a6e93eef074c9505d2233
Status: Downloaded newer image for ubuntu:24.04
# ثم داخل الحاوية:
apt update && apt install -y curl
curl http://172.21.151.42:11434/api/tags
root@c3bd2d28392c:/# # \330\253\331\205 \330\257\330\247\330\256\331\204
 \330\247\331\204\330\255\330\247\331\210\331\212\330\251:
root@c3bd2d28392c:/# apt update && apt install -y curl
Get:1 http://security.ubuntu.com/ubuntu noble-security InRelease [126 kB]
Get:2 http://archive.ubuntu.com/ubuntu noble InRelease [256 kB]
Get:3 http://security.ubuntu.com/ubuntu noble-security/restricted amd64 Packages [1434 kB]
Get:4 http://archive.ubuntu.com/ubuntu noble-updates InRelease [126 kB]
Get:5 http://archive.ubuntu.com/ubuntu noble-backports InRelease [126 kB]
Get:6 http://archive.ubuntu.com/ubuntu noble/universe amd64 Packages [19.3 MB]
Get:7 http://security.ubuntu.com/ubuntu noble-security/universe amd64 Packages [1088 kB]
Get:8 http://security.ubuntu.com/ubuntu noble-security/main amd64 Packages [1081 kB]
Get:9 http://security.ubuntu.com/ubuntu noble-security/multiverse amd64 Packages [22.1 kB]
Get:10 http://archive.ubuntu.com/ubuntu noble/restricted amd64 Packages [117 kB]
Get:11 http://archive.ubuntu.com/ubuntu noble/multiverse amd64 Packages [331 kB]
Get:12 http://archive.ubuntu.com/ubuntu noble/main amd64 Packages [1808 kB]
Get:13 http://archive.ubuntu.com/ubuntu noble-updates/universe amd64 Packages [1385 kB]
Get:14 http://archive.ubuntu.com/ubuntu noble-updates/multiverse amd64 Packages [26.7 kB]
Get:15 http://archive.ubuntu.com/ubuntu noble-updates/restricted amd64 Packages [1478 kB]
Get:16 http://archive.ubuntu.com/ubuntu noble-updates/main amd64 Packages [1399 kB]
Get:17 http://archive.ubuntu.com/ubuntu noble-backports/universe amd64 Packages [31.8 kB]
Get:18 http://archive.ubuntu.com/ubuntu noble-backports/main amd64 Packages [48.0 kB]
Fetched 30.2 MB in 9s (3189 kB/s)
Reading package lists... Done
Building dependency tree... Done
Reading state information... Done
All packages are up to date.
Reading package lists... Done
Building dependency tree... Done
Reading state information... Done
The following additional packages will be installed:
  ca-certificates krb5-locales libbrotli1 libcurl4t64 libgssapi-krb5-2 libk5crypto3 libkeyutils1 libkrb5-3
  libkrb5support0 libldap-common libldap2 libnghttp2-14 libpsl5t64 librtmp1 libsasl2-2 libsasl2-modules
  libsasl2-modules-db libssh-4 openssl publicsuffix
Suggested packages:
  krb5-doc krb5-user libsasl2-modules-gssapi-mit | libsasl2-modules-gssapi-heimdal libsasl2-modules-ldap
  libsasl2-modules-otp libsasl2-modules-sql
The following NEW packages will be installed:
  ca-certificates curl krb5-locales libbrotli1 libcurl4t64 libgssapi-krb5-2 libk5crypto3 libkeyutils1 libkrb5-3
  libkrb5support0 libldap-common libldap2 libnghttp2-14 libpsl5t64 librtmp1 libsasl2-2 libsasl2-modules
  libsasl2-modules-db libssh-4 openssl publicsuffix
0 upgraded, 21 newly installed, 0 to remove and 0 not upgraded.
Need to get 3566 kB of archives.
After this operation, 9211 kB of additional disk space will be used.
Get:1 http://archive.ubuntu.com/ubuntu noble-updates/main amd64 openssl amd64 3.0.13-0ubuntu3.5 [1002 kB]
Get:2 http://archive.ubuntu.com/ubuntu noble/main amd64 ca-certificates all 20240203 [159 kB]
Get:3 http://archive.ubuntu.com/ubuntu noble-updates/main amd64 krb5-locales all 1.20.1-6ubuntu2.5 [14.5 kB]
Get:4 http://archive.ubuntu.com/ubuntu noble-updates/main amd64 libkrb5support0 amd64 1.20.1-6ubuntu2.5 [34.1 kB]
Get:5 http://archive.ubuntu.com/ubuntu noble-updates/main amd64 libk5crypto3 amd64 1.20.1-6ubuntu2.5 [82.0 kB]
Get:6 http://archive.ubuntu.com/ubuntu noble/main amd64 libkeyutils1 amd64 1.6.3-3build1 [9490 B]
Get:7 http://archive.ubuntu.com/ubuntu noble-updates/main amd64 libkrb5-3 amd64 1.20.1-6ubuntu2.5 [347 kB]
Get:8 http://archive.ubuntu.com/ubuntu noble-updates/main amd64 libgssapi-krb5-2 amd64 1.20.1-6ubuntu2.5 [143 kB]
Get:9 http://archive.ubuntu.com/ubuntu noble-updates/main amd64 libnghttp2-14 amd64 1.59.0-1ubuntu0.2 [74.3 kB]
Get:10 http://archive.ubuntu.com/ubuntu noble/main amd64 libpsl5t64 amd64 0.21.2-1.1build1 [57.1 kB]
Get:11 http://archive.ubuntu.com/ubuntu noble/main amd64 publicsuffix all 20231001.0357-0.1 [129 kB]
Get:12 http://archive.ubuntu.com/ubuntu noble/main amd64 libbrotli1 amd64 1.1.0-2build2 [331 kB]
Get:13 http://archive.ubuntu.com/ubuntu noble-updates/main amd64 libsasl2-modules-db amd64 2.1.28+dfsg1-5ubuntu3.1 [20.4 kB]
Get:14 http://archive.ubuntu.com/ubuntu noble-updates/main amd64 libsasl2-2 amd64 2.1.28+dfsg1-5ubuntu3.1 [53.2 kB]
Get:15 http://archive.ubuntu.com/ubuntu noble-updates/main amd64 libldap2 amd64 2.6.7+dfsg-1~exp1ubuntu8.2 [196 kB]
Get:16 http://archive.ubuntu.com/ubuntu noble/main amd64 librtmp1 amd64 2.4+20151223.gitfa8646d.1-2build7 [56.3 kB]
Get:17 http://archive.ubuntu.com/ubuntu noble/main amd64 libssh-4 amd64 0.10.6-2build2 [188 kB]
Get:18 http://archive.ubuntu.com/ubuntu noble-updates/main amd64 libcurl4t64 amd64 8.5.0-2ubuntu10.6 [341 kB]
Get:19 http://archive.ubuntu.com/ubuntu noble-updates/main amd64 curl amd64 8.5.0-2ubuntu10.6 [226 kB]
Get:20 http://archive.ubuntu.com/ubuntu noble-updates/main amd64 libldap-common all 2.6.7+dfsg-1~exp1ubuntu8.2 [31.7 kB]Get:21 http://archive.ubuntu.com/ubuntu noble-updates/main amd64 libsasl2-modules amd64 2.1.28+dfsg1-5ubuntu3.1 [69.9 kB]
Fetched 3566 kB in 3s (1379 kB/s)
debconf: delaying package configuration, since apt-utils is not installed
Selecting previously unselected package openssl.
(Reading database ... 4381 files and directories currently installed.)
Preparing to unpack .../00-openssl_3.0.13-0ubuntu3.5_amd64.deb ...
Unpacking openssl (3.0.13-0ubuntu3.5) ...
Selecting previously unselected package ca-certificates.
Preparing to unpack .../01-ca-certificates_20240203_all.deb ...
Unpacking ca-certificates (20240203) ...
Selecting previously unselected package krb5-locales.
Preparing to unpack .../02-krb5-locales_1.20.1-6ubuntu2.5_all.deb ...
Unpacking krb5-locales (1.20.1-6ubuntu2.5) ...
Selecting previously unselected package libkrb5support0:amd64.
Preparing to unpack .../03-libkrb5support0_1.20.1-6ubuntu2.5_amd64.deb ...
Unpacking libkrb5support0:amd64 (1.20.1-6ubuntu2.5) ...
Selecting previously unselected package libk5crypto3:amd64.
Preparing to unpack .../04-libk5crypto3_1.20.1-6ubuntu2.5_amd64.deb ...
Unpacking libk5crypto3:amd64 (1.20.1-6ubuntu2.5) ...
Selecting previously unselected package libkeyutils1:amd64.
Preparing to unpack .../05-libkeyutils1_1.6.3-3build1_amd64.deb ...
Unpacking libkeyutils1:amd64 (1.6.3-3build1) ...
Selecting previously unselected package libkrb5-3:amd64.
Preparing to unpack .../06-libkrb5-3_1.20.1-6ubuntu2.5_amd64.deb ...
Unpacking libkrb5-3:amd64 (1.20.1-6ubuntu2.5) ...
Selecting previously unselected package libgssapi-krb5-2:amd64.
Preparing to unpack .../07-libgssapi-krb5-2_1.20.1-6ubuntu2.5_amd64.deb ...
Unpacking libgssapi-krb5-2:amd64 (1.20.1-6ubuntu2.5) ...
Selecting previously unselected package libnghttp2-14:amd64.
Preparing to unpack .../08-libnghttp2-14_1.59.0-1ubuntu0.2_amd64.deb ...
Unpacking libnghttp2-14:amd64 (1.59.0-1ubuntu0.2) ...
Selecting previously unselected package libpsl5t64:amd64.
Preparing to unpack .../09-libpsl5t64_0.21.2-1.1build1_amd64.deb ...
Unpacking libpsl5t64:amd64 (0.21.2-1.1build1) ...
Selecting previously unselected package publicsuffix.
Preparing to unpack .../10-publicsuffix_20231001.0357-0.1_all.deb ...
Unpacking publicsuffix (20231001.0357-0.1) ...
Selecting previously unselected package libbrotli1:amd64.
Preparing to unpack .../11-libbrotli1_1.1.0-2build2_amd64.deb ...
Unpacking libbrotli1:amd64 (1.1.0-2build2) ...
Selecting previously unselected package libsasl2-modules-db:amd64.
Preparing to unpack .../12-libsasl2-modules-db_2.1.28+dfsg1-5ubuntu3.1_amd64.deb ...
Unpacking libsasl2-modules-db:amd64 (2.1.28+dfsg1-5ubuntu3.1) ...
Selecting previously unselected package libsasl2-2:amd64.
Preparing to unpack .../13-libsasl2-2_2.1.28+dfsg1-5ubuntu3.1_amd64.deb ...
Unpacking libsasl2-2:amd64 (2.1.28+dfsg1-5ubuntu3.1) ...
Selecting previously unselected package libldap2:amd64.
Preparing to unpack .../14-libldap2_2.6.7+dfsg-1~exp1ubuntu8.2_amd64.deb ...
Unpacking libldap2:amd64 (2.6.7+dfsg-1~exp1ubuntu8.2) ...
Selecting previously unselected package librtmp1:amd64.
Preparing to unpack .../15-librtmp1_2.4+20151223.gitfa8646d.1-2build7_amd64.deb ...
Unpacking librtmp1:amd64 (2.4+20151223.gitfa8646d.1-2build7) ...
Selecting previously unselected package libssh-4:amd64.
Preparing to unpack .../16-libssh-4_0.10.6-2build2_amd64.deb ...
Unpacking libssh-4:amd64 (0.10.6-2build2) ...
Selecting previously unselected package libcurl4t64:amd64.
Preparing to unpack .../17-libcurl4t64_8.5.0-2ubuntu10.6_amd64.deb ...
Unpacking libcurl4t64:amd64 (8.5.0-2ubuntu10.6) ...
Selecting previously unselected package curl.
Preparing to unpack .../18-curl_8.5.0-2ubuntu10.6_amd64.deb ...
Unpacking curl (8.5.0-2ubuntu10.6) ...
Selecting previously unselected package libldap-common.
Preparing to unpack .../19-libldap-common_2.6.7+dfsg-1~exp1ubuntu8.2_all.deb ...
Unpacking libldap-common (2.6.7+dfsg-1~exp1ubuntu8.2) ...
Selecting previously unselected package libsasl2-modules:amd64.
Preparing to unpack .../20-libsasl2-modules_2.1.28+dfsg1-5ubuntu3.1_amd64.deb ...
Unpacking libsasl2-modules:amd64 (2.1.28+dfsg1-5ubuntu3.1) ...
Setting up libkeyutils1:amd64 (1.6.3-3build1) ...
Setting up libbrotli1:amd64 (1.1.0-2build2) ...
Setting up libsasl2-modules:amd64 (2.1.28+dfsg1-5ubuntu3.1) ...
Setting up libpsl5t64:amd64 (0.21.2-1.1build1) ...
Setting up libnghttp2-14:amd64 (1.59.0-1ubuntu0.2) ...
Setting up krb5-locales (1.20.1-6ubuntu2.5) ...
Setting up libldap-common (2.6.7+dfsg-1~exp1ubuntu8.2) ...
Setting up libkrb5support0:amd64 (1.20.1-6ubuntu2.5) ...
Setting up libsasl2-modules-db:amd64 (2.1.28+dfsg1-5ubuntu3.1) ...
Setting up librtmp1:amd64 (2.4+20151223.gitfa8646d.1-2build7) ...
Setting up libk5crypto3:amd64 (1.20.1-6ubuntu2.5) ...
Setting up libsasl2-2:amd64 (2.1.28+dfsg1-5ubuntu3.1) ...
Setting up libkrb5-3:amd64 (1.20.1-6ubuntu2.5) ...
Setting up openssl (3.0.13-0ubuntu3.5) ...
Setting up publicsuffix (20231001.0357-0.1) ...
Setting up libldap2:amd64 (2.6.7+dfsg-1~exp1ubuntu8.2) ...
Setting up ca-certificates (20240203) ...
debconf: unable to initialize frontend: Dialog
debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 79.)
debconf: falling back to frontend: Readline
debconf: unable to initialize frontend: Readline
debconf: (Can't locate Term/ReadLine.pm in @INC (you may need to install the Term::ReadLine module) (@INC entries checked: /etc/perl /usr/local/lib/x86_64-linux-gnu/perl/5.38.2 /usr/local/share/perl/5.38.2 /usr/lib/x86_64-linux-gnu/perl5/5.38 /usr/share/perl5 /usr/lib/x86_64-linux-gnu/perl-base /usr/lib/x86_64-linux-gnu/perl/5.38 /usr/share/perl/5.38 /usr/local/lib/site_perl) at /usr/share/perl5/Debconf/FrontEnd/Readline.pm line 8.)
debconf: falling back to frontend: Teletype
Updating certificates in /etc/ssl/certs...
146 added, 0 removed; done.
Setting up libgssapi-krb5-2:amd64 (1.20.1-6ubuntu2.5) ...
Setting up libssh-4:amd64 (0.10.6-2build2) ...
Setting up libcurl4t64:amd64 (8.5.0-2ubuntu10.6) ...
Setting up curl (8.5.0-2ubuntu10.6) ...
Processing triggers for libc-bin (2.39-0ubuntu8.4) ...
Processing triggers for ca-certificates (20240203) ...
Updating certificates in /etc/ssl/certs...
0 added, 0 removed; done.
Running hooks in /etc/ca-certificates/update.d...
done.
root@c3bd2d28392c:/#
root@c3bd2d28392c:/#
root@c3bd2d28392c:/#
root@c3bd2d28392c:/#
root@c3bd2d28392c:/#
root@c3bd2d28392c:/# sudo docker run -it --privileged --rm \
>   -e LLM_API_KEY="ollama" \
>   -e OLLAMA_HOST="http://172.21.151.42:11434" \
>   -e LLM_OLLAMA_BASE_URL="http://172.21.151.42:11434" \
>   -e OLLAMA_BASE_URL="http://172.21.151.42:11434" \
>   -e OLLAMA_URL="http://172.21.151.42:11434" \
>   -e SANDBOX_RUNTIME_CONTAINER_IMAGE="docker.all-hands.dev/all-hands-ai/runtime:0.12-nikolaik" \
>   -v /var/run/docker.sock:/var/run/docker.sock \
>   -p 3000:3000 \
>   --name openhands-app \
>   docker.all-hands.dev/all-hands-ai/openhands:0.12
bash: sudo: command not found
root@c3bd2d28392c:/# curl http://172.21.151.42:11434/api/tags
{"models":[{"name":"llama3:latest","model":"llama3:latest","modified_at":"2025-05-26T14:20:43.158646446-07:00","size":4661224676,"digest":"365c0bd3c000a25d28ddbf732fe1c6add414de7275464c4e4d1c3b5fcb5d8ad1","details":{"parent_model":"","format":"gguf","family":"llama","families":["llama"],"parameter_size":"8.0B","quantization_level":"Q4_0"}}]}root@c3bd2d28392c:/# curl http://172.21.151.42:11434/api/generate -X POST -H "Content-Type: application/json" -d '{
>   "model": "llama3:latest",
>   "prompt": "\331\205\330\247 \331\207\331\212 \330\271\330\247\33
0\265\331\205\330\251 \331\201",
>   "stream": false
> }'
{"model":"llama3:latest","created_at":"2025-05-26T21:55:45.741735067Z","response":"I see you're asking about the capital of a country!\n\nCould you please tell me which country you're referring to? I'd be happy to help you with that! 🤔","done":true,"done_reason":"stop","context":[128006,882,128007,271,100653,104380,45082,100905,102281,46677,128009,128006,78191,128007,271,40,1518,499,2351,10371,922,279,6864,315,264,3224,2268,13191,499,4587,3371,757,902,3224,499,2351,22797,311,30,358,4265,387,6380,311,1520,499,449,430,0,11410,97,242],"total_duration":26904492663,"load_duration":20378387226,"prompt_eval_count":16,"prompt_eroot@c3bd2d28392c:/#
root@c3bd2d28392c:/#
root@c3bd2d28392c:/#
root@c3bd2d28392c:/#
root@c3bd2d28392c:/#
root@c3bd2d28392c:/#
root@c3bd2d28392c:/#
root@c3bd2d28392c:/#
root@c3bd2d28392c:/#
root@c3bd2d28392c:/#
root@c3bd2d28392c:/#
root@c3bd2d28392c:/#
root@c3bd2d28392c:/#
root@c3bd2d28392c:/#
root@c3bd2d28392c:/#
root@c3bd2d28392c:/# curl http://172.21.151.42:11434/api/generate -X POST -H "Content-Type: application/json" -d '{
> "model": "llama3:latest",
": "W> "prompt": "What is the capital of France?",
> "stream": false
> }'
{"model":"llama3:latest","created_at":"2025-05-26T22:01:57.931140245Z","response":"The capital of France is Paris.","done":true,"done_reason":"stop","context":[128006,882,128007,271,3923,374,279,6864,315,9822,30,128009,128006,78191,128007,271,791,6864,315,9822,374,12366,13],"total_duration":4874365144,"load_duration":2929100189,"prompt_eval_count":17,"prompt_eval_duration":913710699,"eval_count":8,"eval_duration":1029715398}root@c3bd2d28392c:/#
































m@DESKTOP-MUB16F8:~$ curl http://127.0.0.1:11434/api/tags
url http://<IP الخاص بك>:11434/api/tags{"models":[]}m@DESKTOP-MUB16F8:~$ curl http://<IP الخاص بك>:11434/api/tags
-bash: IP: No such file or directory
m@DESKTOP-MUB16F8:~$ OLLAMA_HOST=0.0.0.0 ollama serve
Error: listen tcp 0.0.0.0:11434: bind: address already in use
m@DESKTOP-MUB16F8:~$ curl http://127.0.0.1:11434/api/tags
://172.21.151.42:11434/api/tags{"models":[]}m@DESKTOP-MUB16F8:~$ curl http://172.21.151.42:11434/api/tags
{"models":[]}m@DESKTOP-MUB16F8:~$ curl http://127.0.0.1:11434/api/tags
{"models":[]}m@DESKTOP-MUB16F8:~$
m@DESKTOP-MUB16F8:~$
m@DESKTOP-MUB16F8:~$
m@DESKTOP-MUB16F8:~$ curl http://127.0.0.1:11434/api/tags
{"models":[]}m@DESKTOP-MUB16F8:~$ curl http://172.21.151.42:11434/api/tags
{"models":[]}m@DESKTOP-MUB16F8:~$
m@DESKTOP-MUB16F8:~$
m@DESKTOP-MUB16F8:~$ curl http://172.21.151.42:11434/api/tags
{"models":[]}m@DESKTOP-MUB16F8:~$ ollama list
NAME    ID    SIZE    MODIFIED
m@DESKTOP-MUB16F8:~$ ollama pull llama3
pulling manifest
pulling 6a0746a1ec1a: 100% ▕██████████████████████████████████████████████████████████▏ 4.7 GB
pulling 4fa551d4f938: 100% ▕██████████████████████████████████████████████████████████▏  12 KB
pulling 8ab4849b038c: 100% ▕██████████████████████████████████████████████████████████▏  254 B
pulling 577073ffcc6c: 100% ▕██████████████████████████████████████████████████████████▏  110 B
pulling 3f8eb4da87fa: 100% ▕██████████████████████████████████████████████████████████▏  485 B
verifying sha256 digest
writing manifest
success
m@DESKTOP-MUB16F8:~$ ollama list
NAME             ID              SIZE      MODIFIED
llama3:latest    365c0bd3c000    4.7 GB    48 seconds ago
m@DESKTOP-MUB16F8:~$ docker run -it --rm \
-e OLLAM>   -e OLLAMA_HOST="http://172.21.151.42:11434" \
>   -e LLM_OLLAMA_BASE_URL="http://172.21.151.42:11434" \
>   -e SANDBOX_RUNTIME_CONTAINER_IMAGE=docker.all-hands.dev/all-hands-ai/runtime:0.12-nikolaik \
 /var/>   -v /var/run/docker.sock:/var/run/docker.sock \
>   -p 3000:3000 \
>   --add-host host.docker.internal:host-gateway \
>   --name openhands-app \
>   docker.all-hands.dev/all-hands-ai/openhands:0.12
Starting OpenHands...
Running OpenHands as root
INFO:     Started server process [10]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:3000 (Press CTRL+C to quit)
INFO:     172.17.0.1:38464 - "GET / HTTP/1.1" 200 OK
INFO:     172.17.0.1:38464 - "GET /locales/en/translation.json HTTP/1.1" 200 OK
INFO:     172.17.0.1:38464 - "GET /config.json HTTP/1.1" 200 OK
INFO:     172.17.0.1:38472 - "GET /config.json HTTP/1.1" 200 OK
INFO:     172.17.0.1:38472 - "GET /config.json HTTP/1.1" 200 OK
21:23:20 - openhands:INFO: github.py:14 - Initializing UserVerifier
21:23:20 - openhands:INFO: github.py:27 - GITHUB_USER_LIST_FILE not configured
21:23:20 - openhands:INFO: github.py:48 - GITHUB_USERS_SHEET_ID not configured
21:23:20 - openhands:INFO: github.py:85 - No user verification sources configured - allowing all users
INFO:     ('172.17.0.1', 38484) - "WebSocket /ws" [accepted]
21:23:20 - openhands:ERROR: auth.py:27 - Invalid token
INFO:     connection open
INFO:     172.17.0.1:38472 - "GET /api/options/models HTTP/1.1" 200 OK
INFO:     172.17.0.1:38464 - "GET /api/options/agents HTTP/1.1" 200 OK
INFO:     172.17.0.1:38488 - "GET /api/options/security-analyzers HTTP/1.1" 200 OK
INFO:     connection closed
INFO:     172.17.0.1:38488 - "GET /config.json HTTP/1.1" 200 OK
INFO:     172.17.0.1:38472 - "GET /config.json HTTP/1.1" 200 OK
INFO:     172.17.0.1:45728 - "GET / HTTP/1.1" 200 OK
INFO:     172.17.0.1:45728 - "GET /favicon.ico HTTP/1.1" 200 OK
INFO:     172.17.0.1:45728 - "GET /locales/en/translation.json HTTP/1.1" 200 OK
INFO:     172.17.0.1:45728 - "GET /config.json HTTP/1.1" 200 OK
INFO:     172.17.0.1:45732 - "GET /config.json HTTP/1.1" 200 OK
INFO:     172.17.0.1:45728 - "GET /api/options/agents HTTP/1.1" 200 OK
INFO:     172.17.0.1:45732 - "GET /api/options/models HTTP/1.1" 200 OK
INFO:     172.17.0.1:45748 - "GET /api/options/security-analyzers HTTP/1.1" 200 OK
INFO:     172.17.0.1:39856 - "GET /assets/settings-B80uBrgv.js HTTP/1.1" 200 OK
INFO:     172.17.0.1:39856 - "GET /config.json HTTP/1.1" 200 OK
INFO:     172.17.0.1:39856 - "GET /config.json HTTP/1.1" 200 OK
INFO:     172.17.0.1:39856 - "GET /config.json HTTP/1.1" 200 OK
INFO:     172.17.0.1:39862 - "GET /config.json HTTP/1.1" 200 OK
INFO:     172.17.0.1:39862 - "GET /config.json HTTP/1.1" 200 OK
INFO:     172.17.0.1:39856 - "GET /config.json HTTP/1.1" 200 OK
INFO:     172.17.0.1:59718 - "GET /assets/_oh.app-BbuKviuw.js HTTP/1.1" 200 OK
INFO:     172.17.0.1:59730 - "GET /config.json HTTP/1.1" 200 OK
INFO:     172.17.0.1:59722 - "GET /assets/route-CCYv0vF5.js HTTP/1.1" 200 OK
INFO:     172.17.0.1:59718 - "GET /assets/_oh.app-o9tOh4U3.js HTTP/1.1" 200 OK
INFO:     172.17.0.1:59730 - "GET /assets/index-BXT04Q8N.js HTTP/1.1" 200 OK
INFO:     172.17.0.1:59744 - "GET /assets/clear-session-Bbh6tTiy.js HTTP/1.1" 200 OK
INFO:     172.17.0.1:59734 - "GET /assets/declaration-DdUOQw3g.js HTTP/1.1" 200 OK
INFO:     172.17.0.1:59740 - "GET /assets/useScrollToBottom-B8_iP14x.js HTTP/1.1" 200 OK
INFO:     172.17.0.1:59722 - "GET /assets/index-C4MRHScb.js HTTP/1.1" 200 OK
INFO:     172.17.0.1:59730 - "GET /assets/index-wBZoZNP4.js HTTP/1.1" 200 OK
INFO:     172.17.0.1:59718 - "GET /assets/Terminal-DIsziyk5.js HTTP/1.1" 200 OK
INFO:     172.17.0.1:59730 - "GET /assets/Terminal-CGrrDQr5.css HTTP/1.1" 200 OK
21:24:36 - openhands:INFO: github.py:14 - Initializing UserVerifier
21:24:36 - openhands:INFO: github.py:27 - GITHUB_USER_LIST_FILE not configured
21:24:36 - openhands:INFO: github.py:48 - GITHUB_USERS_SHEET_ID not configured
21:24:36 - openhands:INFO: github.py:85 - No user verification sources configured - allowing all users
INFO:     ('172.17.0.1', 59758) - "WebSocket /ws" [accepted]
21:24:36 - openhands:INFO: listen.py:336 - New session: b2d909c7-e4d1-4858-9f41-e3be86a78fb6
INFO:     connection open
21:24:36 - openhands:WARNING: codeact_agent.py:101 - Function calling not supported for model ollama/llama3:latest. Disabling function calling.
INFO:     172.17.0.1:59718 - "GET /config.json HTTP/1.1" 200 OK
21:24:36 - openhands:INFO: base.py:98 - [runtime b2d909c7-e4d1-4858-9f41-e3be86a78fb6] Starting runtime with image: docker.all-hands.dev/all-hands-ai/runtime:0.12-nikolaik
21:24:37 - openhands:INFO: base.py:98 - [runtime b2d909c7-e4d1-4858-9f41-e3be86a78fb6] Container started: openhands-runtime-b2d909c7-e4d1-4858-9f41-e3be86a78fb6
21:24:37 - openhands:INFO: base.py:98 - [runtime b2d909c7-e4d1-4858-9f41-e3be86a78fb6] Waiting for client to become ready at http://host.docker.internal:36771...
21:25:29 - openhands:INFO: base.py:98 - [runtime b2d909c7-e4d1-4858-9f41-e3be86a78fb6] Runtime is ready.
21:25:29 - openhands:WARNING: state.py:118 - Failed to restore state from session: sessions/b2d909c7-e4d1-4858-9f41-e3be86a78fb6/agent_state.pkl
21:25:29 - openhands:INFO: agent_controller.py:135 - [Agent Controller b2d909c7-e4d1-4858-9f41-e3be86a78fb6] Starting step loop...
21:25:29 - openhands:INFO: agent_controller.py:135 - [Agent Controller b2d909c7-e4d1-4858-9f41-e3be86a78fb6] Setting agent(CodeActAgent) state from AgentState.LOADING to AgentState.INIT
21:25:29 - openhands:INFO: agent_controller.py:135 - [Agent Controller b2d909c7-e4d1-4858-9f41-e3be86a78fb6] Setting agent(CodeActAgent) state from AgentState.INIT to AgentState.RUNNING
21:25:29 - openhands:INFO: github.py:14 - Initializing UserVerifier
21:25:29 - openhands:INFO: github.py:27 - GITHUB_USER_LIST_FILE not configured
21:25:29 - openhands:INFO: github.py:48 - GITHUB_USERS_SHEET_ID not configured
21:25:29 - openhands:INFO: github.py:85 - No user verification sources configured - allowing all users
INFO:     172.17.0.1:58772 - "GET /config.json HTTP/1.1" 200 OK
INFO:     172.17.0.1:58786 - "GET /config.json HTTP/1.1" 200 OK
INFO:     172.17.0.1:58760 - "GET /api/list-files HTTP/1.1" 200 OK
21:25:29 - openhands:INFO: github.py:14 - Initializing UserVerifier
21:25:29 - openhands:INFO: github.py:27 - GITHUB_USER_LIST_FILE not configured
21:25:29 - openhands:INFO: github.py:48 - GITHUB_USERS_SHEET_ID not configured
21:25:29 - openhands:INFO: github.py:85 - No user verification sources configured - allowing all users
INFO:     172.17.0.1:58786 - "GET /api/list-files HTTP/1.1" 200 OK
21:25:29 - openhands:INFO: github.py:14 - Initializing UserVerifier
21:25:29 - openhands:INFO: github.py:27 - GITHUB_USER_LIST_FILE not configured
21:25:29 - openhands:INFO: github.py:48 - GITHUB_USERS_SHEET_ID not configured
21:25:29 - openhands:INFO: github.py:85 - No user verification sources configured - allowing all users
INFO:     172.17.0.1:58760 - "GET /api/list-files HTTP/1.1" 200 OK


==============
[Agent Controller b2d909c7-e4d1-4858-9f41-e3be86a78fb6] LEVEL 0 LOCAL STEP 0 GLOBAL STEP 0


Provider List: https://docs.litellm.ai/docs/providers


Provider List: https://docs.litellm.ai/docs/providers


Give Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new
LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.


Provider List: https://docs.litellm.ai/docs/providers

21:25:30 - openhands:ERROR: retry_mixin.py:47 - litellm.ServiceUnavailableError: OllamaException: HTTPConnectionPool(host='localhost', port=11434): Max retries exceeded with url: /api/generate (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fd337ac5190>: Failed to establish a new connection: [Errno 111] Connection refused')). Attempt #1 | You can customize retry values in the configuration.

Give Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new
LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.


Provider List: https://docs.litellm.ai/docs/providers

21:25:48 - openhands:ERROR: retry_mixin.py:47 - litellm.ServiceUnavailableError: OllamaException: HTTPConnectionPool(host='localhost', port=11434): Max retries exceeded with url: /api/generate (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fd337ab93d0>: Failed to establish a new connection: [Errno 111] Connection refused')). Attempt #2 | You can customize retry values in the configuration.

Give Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new
LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.


Provider List: https://docs.litellm.ai/docs/providers

21:26:03 - openhands:ERROR: retry_mixin.py:47 - litellm.ServiceUnavailableError: OllamaException: HTTPConnectionPool(host='localhost', port=11434): Max retries exceeded with url: /api/generate (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fd33794f9b0>: Failed to establish a new connection: [Errno 111] Connection refused')). Attempt #3 | You can customize retry values in the configuration.

Give Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new
LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.


Provider List: https://docs.litellm.ai/docs/providers

21:26:20 - openhands:ERROR: retry_mixin.py:47 - litellm.ServiceUnavailableError: OllamaException: HTTPConnectionPool(host='localhost', port=11434): Max retries exceeded with url: /api/generate (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fd337964e00>: Failed to establish a new connection: [Errno 111] Connection refused')). Attempt #4 | You can customize retry values in the configuration.

Give Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new
LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.


Provider List: https://docs.litellm.ai/docs/providers

21:26:36 - openhands:ERROR: retry_mixin.py:47 - litellm.ServiceUnavailableError: OllamaException: HTTPConnectionPool(host='localhost', port=11434): Max retries exceeded with url: /api/generate (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fd33794f680>: Failed to establish a new connection: [Errno 111] Connection refused')). Attempt #5 | You can customize retry values in the configuration.

Give Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new
LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.


Provider List: https://docs.litellm.ai/docs/providers

21:27:11 - openhands:ERROR: retry_mixin.py:47 - litellm.ServiceUnavailableError: OllamaException: HTTPConnectionPool(host='localhost', port=11434): Max retries exceeded with url: /api/generate (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fd337964530>: Failed to establish a new connection: [Errno 111] Connection refused')). Attempt #6 | You can customize retry values in the configuration.

Give Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new
LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.


Provider List: https://docs.litellm.ai/docs/providers

21:28:19 - openhands:ERROR: retry_mixin.py:47 - litellm.ServiceUnavailableError: OllamaException: HTTPConnectionPool(host='localhost', port=11434): Max retries exceeded with url: /api/generate (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fd337ac6c90>: Failed to establish a new connection: [Errno 111] Connection refused')). Attempt #7 | You can customize retry values in the configuration.
^CINFO:     Shutting down
21:30:23 - openhands:INFO: session.py:66 - WebSocket disconnected, sid: b2d909c7-e4d1-4858-9f41-e3be86a78fb6
INFO:     connection closed
INFO:     Waiting for application shutdown.
INFO:     Application shutdown complete.
INFO:     Finished server process [10]
^C^CException ignored in: <module 'threading' from '/usr/local/lib/python3.12/threading.py'>
Traceback (most recent call last):
  File "/usr/local/lib/python3.12/threading.py", line 1592, in _shutdown
    atexit_call()
  File "/usr/local/lib/python3.12/concurrent/futures/thread.py", line 31, in _python_exit
    t.join()
  File "/usr/local/lib/python3.12/threading.py", line 1147, in join
    self._wait_for_tstate_lock()
  File "/usr/local/lib/python3.12/threading.py", line 1167, in _wait_for_tstate_lock
    if lock.acquire(block, timeout):
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt:

Give Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new
LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.


Provider List: https://docs.litellm.ai/docs/providers

Traceback (most recent call last):
  File "/app/.venv/lib/python3.12/site-packages/urllib3/connection.py", line 199, in _new_conn
    sock = connection.create_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/urllib3/util/connection.py", line 85, in create_connection
    raise err
  File "/app/.venv/lib/python3.12/site-packages/urllib3/util/connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/app/.venv/lib/python3.12/site-packages/urllib3/connectionpool.py", line 789, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/urllib3/connectionpool.py", line 495, in _make_request
    conn.request(
  File "/app/.venv/lib/python3.12/site-packages/urllib3/connection.py", line 441, in request
    self.endheaders()
  File "/usr/local/lib/python3.12/http/client.py", line 1331, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/usr/local/lib/python3.12/http/client.py", line 1091, in _send_output
    self.send(msg)
  File "/usr/local/lib/python3.12/http/client.py", line 1035, in send
    self.connect()
  File "/app/.venv/lib/python3.12/site-packages/urllib3/connection.py", line 279, in connect
    self.sock = self._new_conn()
                ^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/urllib3/connection.py", line 214, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7fd3381e37a0>: Failed to establish a new connection: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/app/.venv/lib/python3.12/site-packages/requests/adapters.py", line 667, in send
    resp = conn.urlopen(
           ^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/urllib3/connectionpool.py", line 843, in urlopen
    retries = retries.increment(
              ^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/urllib3/util/retry.py", line 519, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=11434): Max retries exceeded with url: /api/generate (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fd3381e37a0>: Failed to establish a new connection: [Errno 111] Connection refused'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/app/.venv/lib/python3.12/site-packages/litellm/main.py", line 2709, in completion
    generator = ollama.get_ollama_response(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/litellm/llms/ollama.py", line 316, in get_ollama_response
    response = requests.post(
               ^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/requests/api.py", line 115, in post
    return request("post", url, data=data, json=json, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/requests/api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/requests/adapters.py", line 700, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='localhost', port=11434): Max retries exceeded with url: /api/generate (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fd3381e37a0>: Failed to establish a new connection: [Errno 111] Connection refused'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/app/openhands/controller/agent_controller.py", line 168, in start_step_loop
    await self._step()
  File "/app/openhands/controller/agent_controller.py", line 464, in _step
    action = self.agent.step(self.state)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/openhands/agenthub/codeact_agent/codeact_agent.py", line 359, in step
    response = self.llm.completion(**params)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/tenacity/__init__.py", line 336, in wrapped_f
    return copy(f, *args, **kw)
           ^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/tenacity/__init__.py", line 475, in __call__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/tenacity/__init__.py", line 418, in exc_check
    raise retry_exc.reraise()
          ^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/tenacity/__init__.py", line 185, in reraise
    raise self.last_attempt.result()
          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/app/.venv/lib/python3.12/site-packages/tenacity/__init__.py", line 478, in __call__
    result = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/app/openhands/llm/llm.py", line 196, in wrapper
    resp: ModelResponse = completion_unwrapped(*args, **kwargs)
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/litellm/utils.py", line 1013, in wrapper
    raise e
  File "/app/.venv/lib/python3.12/site-packages/litellm/utils.py", line 903, in wrapper
    result = original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/litellm/main.py", line 2999, in completion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2116, in exception_type
    raise e
  File "/app/.venv/lib/python3.12/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1785, in exception_type
    raise ServiceUnavailableError(
litellm.exceptions.ServiceUnavailableError: litellm.ServiceUnavailableError: OllamaException: HTTPConnectionPool(host='localhost', port=11434): Max retries exceeded with url: /api/generate (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fd3381e37a0>: Failed to establish a new connection: [Errno 111] Connection refused'))
21:30:27 - openhands:ERROR: agent_controller.py:135 - [Agent Controller b2d909c7-e4d1-4858-9f41-e3be86a78fb6] Error while running the agent: litellm.ServiceUnavailableError: OllamaException: HTTPConnectionPool(host='localhost', port=11434): Max retries exceeded with url: /api/generate (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fd3381e37a0>: Failed to establish a new connection: [Errno 111] Connection refused'))
21:30:27 - openhands:ERROR: agent_controller.py:135 - [Agent Controller b2d909c7-e4d1-4858-9f41-e3be86a78fb6] Traceback (most recent call last):
  File "/app/.venv/lib/python3.12/site-packages/urllib3/connection.py", line 199, in _new_conn
    sock = connection.create_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/urllib3/util/connection.py", line 85, in create_connection
    raise err
  File "/app/.venv/lib/python3.12/site-packages/urllib3/util/connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/app/.venv/lib/python3.12/site-packages/urllib3/connectionpool.py", line 789, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/urllib3/connectionpool.py", line 495, in _make_request
    conn.request(
  File "/app/.venv/lib/python3.12/site-packages/urllib3/connection.py", line 441, in request
    self.endheaders()
  File "/usr/local/lib/python3.12/http/client.py", line 1331, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/usr/local/lib/python3.12/http/client.py", line 1091, in _send_output
    self.send(msg)
  File "/usr/local/lib/python3.12/http/client.py", line 1035, in send
    self.connect()
  File "/app/.venv/lib/python3.12/site-packages/urllib3/connection.py", line 279, in connect
    self.sock = self._new_conn()
                ^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/urllib3/connection.py", line 214, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7fd3381e37a0>: Failed to establish a new connection: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/app/.venv/lib/python3.12/site-packages/requests/adapters.py", line 667, in send
    resp = conn.urlopen(
           ^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/urllib3/connectionpool.py", line 843, in urlopen
    retries = retries.increment(
              ^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/urllib3/util/retry.py", line 519, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=11434): Max retries exceeded with url: /api/generate (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fd3381e37a0>: Failed to establish a new connection: [Errno 111] Connection refused'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/app/.venv/lib/python3.12/site-packages/litellm/main.py", line 2709, in completion
    generator = ollama.get_ollama_response(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/litellm/llms/ollama.py", line 316, in get_ollama_response
    response = requests.post(
               ^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/requests/api.py", line 115, in post
    return request("post", url, data=data, json=json, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/requests/api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/requests/adapters.py", line 700, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='localhost', port=11434): Max retries exceeded with url: /api/generate (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fd3381e37a0>: Failed to establish a new connection: [Errno 111] Connection refused'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/app/openhands/controller/agent_controller.py", line 168, in start_step_loop
    await self._step()
  File "/app/openhands/controller/agent_controller.py", line 464, in _step
    action = self.agent.step(self.state)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/openhands/agenthub/codeact_agent/codeact_agent.py", line 359, in step
    response = self.llm.completion(**params)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/tenacity/__init__.py", line 336, in wrapped_f
    return copy(f, *args, **kw)
           ^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/tenacity/__init__.py", line 475, in __call__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/tenacity/__init__.py", line 418, in exc_check
    raise retry_exc.reraise()
          ^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/tenacity/__init__.py", line 185, in reraise
    raise self.last_attempt.result()
          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/app/.venv/lib/python3.12/site-packages/tenacity/__init__.py", line 478, in __call__
    result = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/app/openhands/llm/llm.py", line 196, in wrapper
    resp: ModelResponse = completion_unwrapped(*args, **kwargs)
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/litellm/utils.py", line 1013, in wrapper
    raise e
  File "/app/.venv/lib/python3.12/site-packages/litellm/utils.py", line 903, in wrapper
    result = original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/litellm/main.py", line 2999, in completion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2116, in exception_type
    raise e
  File "/app/.venv/lib/python3.12/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1785, in exception_type
    raise ServiceUnavailableError(
litellm.exceptions.ServiceUnavailableError: litellm.ServiceUnavailableError: OllamaException: HTTPConnectionPool(host='localhost', port=11434): Max retries exceeded with url: /api/generate (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fd3381e37a0>: Failed to establish a new connection: [Errno 111] Connection refused'))

21:30:27 - openhands:INFO: agent_controller.py:135 - [Agent Controller b2d909c7-e4d1-4858-9f41-e3be86a78fb6] Setting agent(CodeActAgent) state from AgentState.RUNNING to AgentState.ERROR
m@DESKTOP-MUB16F8:~$ docker run -it --rm \
-e OLL>   -e OLLAMA_HOST="http://172.21.151.42:11434" \
>   -e LLM_OLLAMA_BASE_URL="http://172.21.151.42:11434" \
>   -e OLLAMA_BASE_URL="http://172.21.151.42:11434" \
>   -e OLLAMA_URL="http://172.21.151.42:11434" \
>   -e SANDBOX_RUNTIME_CONTAINER_IMAGE=docker.all-hands.dev/all-hands-ai/runtime:0.12-nikolaik \
>   -v /var/run/docker.sock:/var/run/docker.sock \
>   -p 3000:3000 \
>   --add-host host.docker.internal:host-gateway \
>   --name openhands-app \
>   docker.all-hands.dev/all-hands-ai/openhands:0.12
Starting OpenHands...
Running OpenHands as root
INFO:     Started server process [10]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:3000 (Press CTRL+C to quit)
INFO:     172.17.0.1:46008 - "GET / HTTP/1.1" 200 OK
INFO:     172.17.0.1:46008 - "GET /locales/en/translation.json HTTP/1.1" 200 OK
INFO:     172.17.0.1:46008 - "GET /config.json HTTP/1.1" 200 OK
INFO:     172.17.0.1:46014 - "GET /config.json HTTP/1.1" 200 OK
INFO:     172.17.0.1:46014 - "GET /config.json HTTP/1.1" 200 OK
21:31:18 - openhands:INFO: github.py:14 - Initializing UserVerifier
21:31:18 - openhands:INFO: github.py:27 - GITHUB_USER_LIST_FILE not configured
21:31:18 - openhands:INFO: github.py:48 - GITHUB_USERS_SHEET_ID not configured
21:31:18 - openhands:INFO: github.py:85 - No user verification sources configured - allowing all users
INFO:     ('172.17.0.1', 46024) - "WebSocket /ws" [accepted]
21:31:18 - openhands:ERROR: auth.py:27 - Invalid token
INFO:     172.17.0.1:46014 - "GET /api/options/models HTTP/1.1" 200 OK
INFO:     connection open
INFO:     172.17.0.1:46008 - "GET /api/options/agents HTTP/1.1" 200 OK
INFO:     172.17.0.1:46030 - "GET /api/options/security-analyzers HTTP/1.1" 200 OK
INFO:     connection closed
INFO:     172.17.0.1:46030 - "GET /assets/end-session-CpBsKLW_.js HTTP/1.1" 200 OK
INFO:     172.17.0.1:46030 - "GET /config.json HTTP/1.1" 200 OK
INFO:     172.17.0.1:46008 - "GET /config.json HTTP/1.1" 200 OK
INFO:     172.17.0.1:42668 - "GET /config.json HTTP/1.1" 200 OK
INFO:     172.17.0.1:42674 - "GET /config.json HTTP/1.1" 200 OK
INFO:     172.17.0.1:42686 - "GET /config.json HTTP/1.1" 200 OK
21:32:56 - openhands:INFO: github.py:14 - Initializing UserVerifier
21:32:56 - openhands:INFO: github.py:27 - GITHUB_USER_LIST_FILE not configured
21:32:56 - openhands:INFO: github.py:48 - GITHUB_USERS_SHEET_ID not configured
21:32:56 - openhands:INFO: github.py:85 - No user verification sources configured - allowing all users
INFO:     ('172.17.0.1', 42688) - "WebSocket /ws" [accepted]
21:32:56 - openhands:INFO: listen.py:336 - New session: 844b5dbd-fb1d-4b36-82e1-5b4a6215601c
INFO:     connection open
21:32:56 - openhands:WARNING: codeact_agent.py:101 - Function calling not supported for model ollama/llama3:latest. Disabling function calling.
INFO:     172.17.0.1:42686 - "GET /config.json HTTP/1.1" 200 OK
21:32:56 - openhands:INFO: base.py:98 - [runtime 844b5dbd-fb1d-4b36-82e1-5b4a6215601c] Starting runtime with image: docker.all-hands.dev/all-hands-ai/runtime:0.12-nikolaik
21:32:57 - openhands:INFO: base.py:98 - [runtime 844b5dbd-fb1d-4b36-82e1-5b4a6215601c] Container started: openhands-runtime-844b5dbd-fb1d-4b36-82e1-5b4a6215601c
21:32:57 - openhands:INFO: base.py:98 - [runtime 844b5dbd-fb1d-4b36-82e1-5b4a6215601c] Waiting for client to become ready at http://host.docker.internal:36650...
21:33:50 - openhands:INFO: base.py:98 - [runtime 844b5dbd-fb1d-4b36-82e1-5b4a6215601c] Runtime is ready.
21:33:50 - openhands:WARNING: state.py:118 - Failed to restore state from session: sessions/844b5dbd-fb1d-4b36-82e1-5b4a6215601c/agent_state.pkl
21:33:50 - openhands:INFO: agent_controller.py:135 - [Agent Controller 844b5dbd-fb1d-4b36-82e1-5b4a6215601c] Starting step loop...
21:33:51 - openhands:INFO: agent_controller.py:135 - [Agent Controller 844b5dbd-fb1d-4b36-82e1-5b4a6215601c] Setting agent(CodeActAgent) state from AgentState.LOADING to AgentState.INIT
21:33:51 - openhands:INFO: agent_controller.py:135 - [Agent Controller 844b5dbd-fb1d-4b36-82e1-5b4a6215601c] Setting agent(CodeActAgent) state from AgentState.INIT to AgentState.RUNNING
21:33:51 - openhands:INFO: github.py:14 - Initializing UserVerifier
21:33:51 - openhands:INFO: github.py:27 - GITHUB_USER_LIST_FILE not configured
21:33:51 - openhands:INFO: github.py:48 - GITHUB_USERS_SHEET_ID not configured
21:33:51 - openhands:INFO: github.py:85 - No user verification sources configured - allowing all users
INFO:     172.17.0.1:42910 - "GET /config.json HTTP/1.1" 200 OK
INFO:     172.17.0.1:42918 - "GET /config.json HTTP/1.1" 200 OK
INFO:     172.17.0.1:42894 - "GET /api/list-files HTTP/1.1" 200 OK
21:33:51 - openhands:INFO: github.py:14 - Initializing UserVerifier
21:33:51 - openhands:INFO: github.py:27 - GITHUB_USER_LIST_FILE not configured
21:33:51 - openhands:INFO: github.py:48 - GITHUB_USERS_SHEET_ID not configured
21:33:51 - openhands:INFO: github.py:85 - No user verification sources configured - allowing all users
INFO:     172.17.0.1:42918 - "GET /api/list-files HTTP/1.1" 200 OK
21:33:51 - openhands:INFO: github.py:14 - Initializing UserVerifier
21:33:51 - openhands:INFO: github.py:27 - GITHUB_USER_LIST_FILE not configured
21:33:51 - openhands:INFO: github.py:48 - GITHUB_USERS_SHEET_ID not configured
21:33:51 - openhands:INFO: github.py:85 - No user verification sources configured - allowing all users
INFO:     172.17.0.1:42894 - "GET /api/list-files HTTP/1.1" 200 OK


==============
[Agent Controller 844b5dbd-fb1d-4b36-82e1-5b4a6215601c] LEVEL 0 LOCAL STEP 0 GLOBAL STEP 0


Provider List: https://docs.litellm.ai/docs/providers


Provider List: https://docs.litellm.ai/docs/providers


Give Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new
LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.


Provider List: https://docs.litellm.ai/docs/providers

21:33:52 - openhands:ERROR: retry_mixin.py:47 - litellm.ServiceUnavailableError: OllamaException: HTTPConnectionPool(host='localhost', port=11434): Max retries exceeded with url: /api/generate (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f56e8c739e0>: Failed to establish a new connection: [Errno 111] Connection refused')). Attempt #1 | You can customize retry values in the configuration.

Give Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new
LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.


Provider List: https://docs.litellm.ai/docs/providers

21:34:07 - openhands:ERROR: retry_mixin.py:47 - litellm.ServiceUnavailableError: OllamaException: HTTPConnectionPool(host='localhost', port=11434): Max retries exceeded with url: /api/generate (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f56e8c719d0>: Failed to establish a new connection: [Errno 111] Connection refused')). Attempt #2 | You can customize retry values in the configuration.
^CINFO:     Shutting down
21:34:22 - openhands:INFO: session.py:66 - WebSocket disconnected, sid: 844b5dbd-fb1d-4b36-82e1-5b4a6215601c
INFO:     connection closed
INFO:     Waiting for application shutdown.
INFO:     Application shutdown complete.
INFO:     Finished server process [10]
^C^CException ignored in: <module 'threading' from '/usr/local/lib/python3.12/threading.py'>
Traceback (most recent call last):
  File "/usr/local/lib/python3.12/threading.py", line 1592, in _shutdown
    atexit_call()
  File "/usr/local/lib/python3.12/concurrent/futures/thread.py", line 31, in _python_exit
    t.join()
  File "/usr/local/lib/python3.12/threading.py", line 1147, in join
    self._wait_for_tstate_lock()
  File "/usr/local/lib/python3.12/threading.py", line 1167, in _wait_for_tstate_lock
    if lock.acquire(block, timeout):
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt:

Give Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new
LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.


Provider List: https://docs.litellm.ai/docs/providers

Traceback (most recent call last):
  File "/app/.venv/lib/python3.12/site-packages/urllib3/connection.py", line 199, in _new_conn
    sock = connection.create_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/urllib3/util/connection.py", line 85, in create_connection
    raise err
  File "/app/.venv/lib/python3.12/site-packages/urllib3/util/connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:
Traceback (most recent call last):
  File "/app/.venv/lib/python3.12/site-packages/urllib3/connectionpool.py", line 789, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/urllib3/connectionpool.py", line 495, in _make_request
    conn.request(
  File "/app/.venv/lib/python3.12/site-packages/urllib3/connection.py", line 441, in request
    self.endheaders()
  File "/usr/local/lib/python3.12/http/client.py", line 1331, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/usr/local/lib/python3.12/http/client.py", line 1091, in _send_output
    self.send(msg)
  File "/usr/local/lib/python3.12/http/client.py", line 1035, in send
    self.connect()
  File "/app/.venv/lib/python3.12/site-packages/urllib3/connection.py", line 279, in connect
    self.sock = self._new_conn()
                ^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/urllib3/connection.py", line 214, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7f56e8c607d0>: Failed to establish a new connection: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:
Traceback (most recent call last):
  File "/app/.venv/lib/python3.12/site-packages/requests/adapters.py", line 667, in send
    resp = conn.urlopen(
           ^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/urllib3/connectionpool.py", line 843, in urlopen
    retries = retries.increment(
              ^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/urllib3/util/retry.py", line 519, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=11434): Max retries exceeded with url: /api/generate (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f56e8c607d0>: Failed to establish a new connection: [Errno 111] Connection refused'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/app/.venv/lib/python3.12/site-packages/litellm/main.py", line 2709, in completion
    generator = ollama.get_ollama_response(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/litellm/llms/ollama.py", line 316, in get_ollama_response
    response = requests.post(
               ^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/requests/api.py", line 115, in post
    return request("post", url, data=data, json=json, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/requests/api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/requests/adapters.py", line 700, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='localhost', port=11434): Max retries exceeded with url: /api/generate (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f56e8c607d0>: Failed to establish a new connection: [Errno 111] Connection refused'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/app/openhands/controller/agent_controller.py", line 168, in start_step_loop
    await self._step()
  File "/app/openhands/controller/agent_controller.py", line 464, in _step
    action = self.agent.step(self.state)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/openhands/agenthub/codeact_agent/codeact_agent.py", line 359, in step
    response = self.llm.completion(**params)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/tenacity/__init__.py", line 336, in wrapped_f
    return copy(f, *args, **kw)
           ^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/tenacity/__init__.py", line 475, in __call__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/tenacity/__init__.py", line 418, in exc_check
    raise retry_exc.reraise()
          ^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/tenacity/__init__.py", line 185, in reraise
    raise self.last_attempt.result()
          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/app/.venv/lib/python3.12/site-packages/tenacity/__init__.py", line 478, in __call__
    result = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/app/openhands/llm/llm.py", line 196, in wrapper
    resp: ModelResponse = completion_unwrapped(*args, **kwargs)
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/litellm/utils.py", line 1013, in wrapper
    raise e
  File "/app/.venv/lib/python3.12/site-packages/litellm/utils.py", line 903, in wrapper
    result = original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/litellm/main.py", line 2999, in completion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2116, in exception_type
    raise e
  File "/app/.venv/lib/python3.12/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1785, in exception_type
    raise ServiceUnavailableError(
litellm.exceptions.ServiceUnavailableError: litellm.ServiceUnavailableError: OllamaException: HTTPConnectionPool(host='localhost', port=11434): Max retries exceeded with url: /api/generate (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f56e8c607d0>: Failed to establish a new connection: [Errno 111] Connection refused'))
21:34:24 - openhands:ERROR: agent_controller.py:135 - [Agent Controller 844b5dbd-fb1d-4b36-82e1-5b4a6215601c] Error while running the agent: litellm.ServiceUnavailableError: OllamaException: HTTPConnectionPool(host='localhost', port=11434): Max retries exceeded with url: /api/generate (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f56e8c607d0>: Failed to establish a new connection: [Errno 111] Connection refused'))
21:34:24 - openhands:ERROR: agent_controller.py:135 - [Agent Controller 844b5dbd-fb1d-4b36-82e1-5b4a6215601c] Traceback (most recent call last):
  File "/app/.venv/lib/python3.12/site-packages/urllib3/connection.py", line 199, in _new_conn
    sock = connection.create_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/urllib3/util/connection.py", line 85, in create_connection
    raise err
  File "/app/.venv/lib/python3.12/site-packages/urllib3/util/connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:
Traceback (most recent call last):
  File "/app/.venv/lib/python3.12/site-packages/urllib3/connectionpool.py", line 789, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/urllib3/connectionpool.py", line 495, in _make_request
    conn.request(
  File "/app/.venv/lib/python3.12/site-packages/urllib3/connection.py", line 441, in request
    self.endheaders()
  File "/usr/local/lib/python3.12/http/client.py", line 1331, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/usr/local/lib/python3.12/http/client.py", line 1091, in _send_output
    self.send(msg)
  File "/usr/local/lib/python3.12/http/client.py", line 1035, in send
    self.connect()
  File "/app/.venv/lib/python3.12/site-packages/urllib3/connection.py", line 279, in connect
    self.sock = self._new_conn()
                ^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/urllib3/connection.py", line 214, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7f56e8c607d0>: Failed to establish a new connection: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:
Traceback (most recent call last):
  File "/app/.venv/lib/python3.12/site-packages/requests/adapters.py", line 667, in send
    resp = conn.urlopen(
           ^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/urllib3/connectionpool.py", line 843, in urlopen
    retries = retries.increment(
              ^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/urllib3/util/retry.py", line 519, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=11434): Max retries exceeded with url: /api/generate (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f56e8c607d0>: Failed to establish a new connection: [Errno 111] Connection refused'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/app/.venv/lib/python3.12/site-packages/litellm/main.py", line 2709, in completion
    generator = ollama.get_ollama_response(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/litellm/llms/ollama.py", line 316, in get_ollama_response
    response = requests.post(
               ^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/requests/api.py", line 115, in post
    return request("post", url, data=data, json=json, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/requests/api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/requests/adapters.py", line 700, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='localhost', port=11434): Max retries exceeded with url: /api/generate (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f56e8c607d0>: Failed to establish a new connection: [Errno 111] Connection refused'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/app/openhands/controller/agent_controller.py", line 168, in start_step_loop
    await self._step()
  File "/app/openhands/controller/agent_controller.py", line 464, in _step
    action = self.agent.step(self.state)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/openhands/agenthub/codeact_agent/codeact_agent.py", line 359, in step
    response = self.llm.completion(**params)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/tenacity/__init__.py", line 336, in wrapped_f
    return copy(f, *args, **kw)
           ^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/tenacity/__init__.py", line 475, in __call__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/tenacity/__init__.py", line 418, in exc_check
    raise retry_exc.reraise()
          ^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/tenacity/__init__.py", line 185, in reraise
    raise self.last_attempt.result()
          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/app/.venv/lib/python3.12/site-packages/tenacity/__init__.py", line 478, in __call__
    result = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/app/openhands/llm/llm.py", line 196, in wrapper
    resp: ModelResponse = completion_unwrapped(*args, **kwargs)
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/litellm/utils.py", line 1013, in wrapper
    raise e
  File "/app/.venv/lib/python3.12/site-packages/litellm/utils.py", line 903, in wrapper
    result = original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/litellm/main.py", line 2999, in completion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2116, in exception_type
    raise e
  File "/app/.venv/lib/python3.12/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1785, in exception_type
    raise ServiceUnavailableError(
litellm.exceptions.ServiceUnavailableError: litellm.ServiceUnavailableError: OllamaException: HTTPConnectionPool(host='localhost', port=11434): Max retries exceeded with url: /api/generate (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f56e8c607d0>: Failed to establish a new connection: [Errno 111] Connection refused'))

21:34:24 - openhands:INFO: agent_controller.py:135 - [Agent Controller 844b5dbd-fb1d-4b36-82e1-5b4a6215601c] Setting agent(CodeActAgent) state from AgentState.RUNNING to AgentState.ERROR
m@DESKTOP-MUB16F8:~$
cker runm@DESKTOP-MUB16F8:~$ sudo docker run -it --privileged --rm -ways \al
>   -e LLM_API_KEY="ollama" \
>   -e OLLAMA_HOST="http://host.docker.internal:11434"
 LLM_OLLAMA_BASE_URL="http://host.docker.internal:11434"
  -e OLLAMA_BASE_URL="http://host.docker.internal:11434"
  -e OLLAMA_URL="http://host.docker.internal:11434"
  -e SANDBOX_RUNTIME_CONTAINER_IMAGE=docker.all-hands.dev/all-hands-ai/runtime:0.12-nikolaik \
  -v /var/run/docker.sock:/var/run/docker.sock \
  -p 3000:3000 \
  --add-host host.docker.internal:host-gateway \
  --name openhands-app \
  docker.all-hands.dev/all-hands-ai/openhands:0.12[sudo] password for m:
Sorry, try again.
[sudo] password for m:
docker: 'docker run' requires at least 1 argument

Usage:  docker run [OPTIONS] IMAGE [COMMAND] [ARG...]

See 'docker run --help' for more information
m@DESKTOP-MUB16F8:~$ docker run -it --rm \
>   -e OLLAMA_HOST="http://host.docker.internal:11434" \
>   -e LLM_OLLAMA_BASE_URL="http://host.docker.internal:11434" \
>   -e OLLAMA_BASE_URL="http://host.docker.internal:11434" \
>   -e OLLAMA_URL="http://host.docker.internal:11434" \
>   -e SANDBOX_RUNTIME_CONTAINER_IMAGE=docker.all-hands.dev/all-hands-ai/runtime:0.12-nikolaik \
>   -v /var/run/docker.sock:/var/run/docker.sock \
>   -p 3000:3000 \
>   --add-host host.docker.internal:host-gateway \
>   --name openhands-app \
>   docker.all-hands.dev/all-hands-ai/openhands:0.12
Starting OpenHands...
Running OpenHands as root
INFO:     Started server process [10]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:3000 (Press CTRL+C to quit)
INFO:     172.17.0.1:57364 - "GET / HTTP/1.1" 200 OK
INFO:     172.17.0.1:57364 - "GET /locales/en/translation.json HTTP/1.1" 200 OK
INFO:     172.17.0.1:57364 - "GET /config.json HTTP/1.1" 200 OK
INFO:     172.17.0.1:57376 - "GET /config.json HTTP/1.1" 200 OK
INFO:     172.17.0.1:57376 - "GET /config.json HTTP/1.1" 200 OK
21:37:08 - openhands:ERROR: listen.py:413 - Error getting OLLAMA models: HTTPConnectionPool(host='host.docker.internal', port=11434): Max retries exceeded with url: /api/tags (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f9448158500>: Failed to establish a new connection: [Errno 111] Connection refused'))
Traceback (most recent call last):
  File "/app/.venv/lib/python3.12/site-packages/urllib3/connection.py", line 199, in _new_conn
    sock = connection.create_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/urllib3/util/connection.py", line 85, in create_connection
    raise err
  File "/app/.venv/lib/python3.12/site-packages/urllib3/util/connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:
Traceback (most recent call last):
  File "/app/.venv/lib/python3.12/site-packages/urllib3/connectionpool.py", line 789, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/urllib3/connectionpool.py", line 495, in _make_request
    conn.request(
  File "/app/.venv/lib/python3.12/site-packages/urllib3/connection.py", line 441, in request
    self.endheaders()
  File "/usr/local/lib/python3.12/http/client.py", line 1331, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/usr/local/lib/python3.12/http/client.py", line 1091, in _send_output
    self.send(msg)
  File "/usr/local/lib/python3.12/http/client.py", line 1035, in send
    self.connect()
  File "/app/.venv/lib/python3.12/site-packages/urllib3/connection.py", line 279, in connect
    self.sock = self._new_conn()
                ^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/urllib3/connection.py", line 214, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7f9448158500>: Failed to establish a new connection: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:
Traceback (most recent call last):
  File "/app/.venv/lib/python3.12/site-packages/requests/adapters.py", line 667, in send
    resp = conn.urlopen(
           ^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/urllib3/connectionpool.py", line 843, in urlopen
    retries = retries.increment(
              ^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/urllib3/util/retry.py", line 519, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='host.docker.internal', port=11434): Max retries exceeded with url: /api/tags (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f9448158500>: Failed to establish a new connection: [Errno 111] Connection refused'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/app/openhands/server/listen.py", line 406, in get_litellm_models
    ollama_models_list = requests.get(ollama_url, timeout=3).json()[                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/requests/api.py", line 73, in get
    return request("get", url, params=params, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/requests/api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/requests/adapters.py", line 700, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='host.docker.internal', port=11434): Max retries exceeded with url: /api/tags (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f9448158500>: Failed to establish a new connection: [Errno 111] Connection refused'))
INFO:     172.17.0.1:57376 - "GET /api/options/models HTTP/1.1" 200 OK
21:37:08 - openhands:INFO: github.py:14 - Initializing UserVerifier
21:37:08 - openhands:INFO: github.py:27 - GITHUB_USER_LIST_FILE not configured
21:37:08 - openhands:INFO: github.py:48 - GITHUB_USERS_SHEET_ID not configured
21:37:08 - openhands:INFO: github.py:85 - No user verification sources configured - allowing all users
INFO:     ('172.17.0.1', 57386) - "WebSocket /ws" [accepted]
21:37:08 - openhands:ERROR: auth.py:27 - Invalid token
INFO:     connection open
INFO:     172.17.0.1:57364 - "GET /api/options/agents HTTP/1.1" 200 OK
INFO:     172.17.0.1:57388 - "GET /api/options/security-analyzers HTTP/1.1" 200 OK
INFO:     connection closed
INFO:     172.17.0.1:57388 - "GET /config.json HTTP/1.1" 200 OK
INFO:     172.17.0.1:57364 - "GET /config.json HTTP/1.1" 200 OK
INFO:     172.17.0.1:56212 - "GET /config.json HTTP/1.1" 200 OK
INFO:     172.17.0.1:56214 - "GET /config.json HTTP/1.1" 200 OK
INFO:     172.17.0.1:56214 - "GET /config.json HTTP/1.1" 200 OK
21:37:32 - openhands:INFO: github.py:14 - Initializing UserVerifier
21:37:32 - openhands:INFO: github.py:27 - GITHUB_USER_LIST_FILE not configured
21:37:32 - openhands:INFO: github.py:48 - GITHUB_USERS_SHEET_ID not configured
21:37:32 - openhands:INFO: github.py:85 - No user verification sources configured - allowing all users
INFO:     ('172.17.0.1', 56220) - "WebSocket /ws" [accepted]
21:37:32 - openhands:INFO: listen.py:336 - New session: ec6f817b-3465-47bc-8889-de162172081a
INFO:     connection open
21:37:33 - openhands:WARNING: codeact_agent.py:101 - Function calling not supported for model ollama/llama3:latest. Disabling function calling.
INFO:     172.17.0.1:56214 - "GET /config.json HTTP/1.1" 200 OK
21:37:33 - openhands:INFO: base.py:98 - [runtime ec6f817b-3465-47bc-8889-de162172081a] Starting runtime with image: docker.all-hands.dev/all-hands-ai/runtime:0.12-nikolaik
21:37:33 - openhands:INFO: base.py:98 - [runtime ec6f817b-3465-47bc-8889-de162172081a] Container started: openhands-runtime-ec6f817b-3465-47bc-8889-de162172081a
21:37:33 - openhands:INFO: base.py:98 - [runtime ec6f817b-3465-47bc-8889-de162172081a] Waiting for client to become ready at http://host.docker.internal:39018...
21:38:05 - openhands:INFO: base.py:98 - [runtime ec6f817b-3465-47bc-8889-de162172081a] Runtime is ready.
21:38:05 - openhands:WARNING: state.py:118 - Failed to restore state from session: sessions/ec6f817b-3465-47bc-8889-de162172081a/agent_state.pkl
21:38:05 - openhands:INFO: agent_controller.py:135 - [Agent Controller ec6f817b-3465-47bc-8889-de162172081a] Starting step loop...
21:38:05 - openhands:INFO: agent_controller.py:135 - [Agent Controller ec6f817b-3465-47bc-8889-de162172081a] Setting agent(CodeActAgent) state from AgentState.LOADING to AgentState.INIT
21:38:05 - openhands:INFO: agent_controller.py:135 - [Agent Controller ec6f817b-3465-47bc-8889-de162172081a] Setting agent(CodeActAgent) state from AgentState.INIT to AgentState.RUNNING
21:38:05 - openhands:INFO: github.py:14 - Initializing UserVerifier
21:38:05 - openhands:INFO: github.py:27 - GITHUB_USER_LIST_FILE not configured
21:38:05 - openhands:INFO: github.py:48 - GITHUB_USERS_SHEET_ID not configured
21:38:05 - openhands:INFO: github.py:85 - No user verification sources configured - allowing all users
INFO:     172.17.0.1:41574 - "GET /config.json HTTP/1.1" 200 OK
INFO:     172.17.0.1:41590 - "GET /config.json HTTP/1.1" 200 OK
INFO:     172.17.0.1:41558 - "GET /api/list-files HTTP/1.1" 200 OK
21:38:06 - openhands:INFO: github.py:14 - Initializing UserVerifier
21:38:06 - openhands:INFO: github.py:27 - GITHUB_USER_LIST_FILE not configured
21:38:06 - openhands:INFO: github.py:48 - GITHUB_USERS_SHEET_ID not configured
21:38:06 - openhands:INFO: github.py:85 - No user verification sources configured - allowing all users
INFO:     172.17.0.1:41590 - "GET /api/list-files HTTP/1.1" 200 OK
21:38:06 - openhands:INFO: github.py:14 - Initializing UserVerifier
21:38:06 - openhands:INFO: github.py:27 - GITHUB_USER_LIST_FILE not configured
21:38:06 - openhands:INFO: github.py:48 - GITHUB_USERS_SHEET_ID not configured
21:38:06 - openhands:INFO: github.py:85 - No user verification sources configured - allowing all users
INFO:     172.17.0.1:41558 - "GET /api/list-files HTTP/1.1" 200 OK


==============
[Agent Controller ec6f817b-3465-47bc-8889-de162172081a] LEVEL 0 LOCAL STEP 0 GLOBAL STEP 0


Provider List: https://docs.litellm.ai/docs/providers


Provider List: https://docs.litellm.ai/docs/providers


Give Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new
LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.


Provider List: https://docs.litellm.ai/docs/providers

21:38:07 - openhands:ERROR: retry_mixin.py:47 - litellm.ServiceUnavailableError: OllamaException: HTTPConnectionPool(host='127.0.0.1', port=11434): Max retries exceeded with url: /v1/api/generate (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f944777f6b0>: Failed to establish a new connection: [Errno 111] Connection refused')). Attempt #1 | You can customize retry values in the configuration.

Give Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new
LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.


Provider List: https://docs.litellm.ai/docs/providers

21:38:22 - openhands:ERROR: retry_mixin.py:47 - litellm.ServiceUnavailableError: OllamaException: HTTPConnectionPool(host='127.0.0.1', port=11434): Max retries exceeded with url: /v1/api/generate (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f944761a1b0>: Failed to establish a new connection: [Errno 111] Connection refused')). Attempt #2 | You can customize retry values in the configuration.

Give Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new
LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.


Provider List: https://docs.litellm.ai/docs/providers

21:38:38 - openhands:ERROR: retry_mixin.py:47 - litellm.ServiceUnavailableError: OllamaException: HTTPConnectionPool(host='127.0.0.1', port=11434): Max retries exceeded with url: /v1/api/generate (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f944761aae0>: Failed to establish a new connection: [Errno 111] Connection refused')). Attempt #3 | You can customize retry values in the configuration.

Give Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new
LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.


Provider List: https://docs.litellm.ai/docs/providers

21:38:53 - openhands:ERROR: retry_mixin.py:47 - litellm.ServiceUnavailableError: OllamaException: HTTPConnectionPool(host='127.0.0.1', port=11434): Max retries exceeded with url: /v1/api/generate (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f944761c0b0>: Failed to establish a new connection: [Errno 111] Connection refused')). Attempt #4 | You can customize retry values in the configuration.

Give Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new
LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.


Provider List: https://docs.litellm.ai/docs/providers

21:39:11 - openhands:ERROR: retry_mixin.py:47 - litellm.ServiceUnavailableError: OllamaException: HTTPConnectionPool(host='127.0.0.1', port=11434): Max retries exceeded with url: /v1/api/generate (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f944761abd0>: Failed to establish a new connection: [Errno 111] Connection refused')). Attempt #5 | You can customize retry values in the configuration.

Give Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new
LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.


Provider List: https://docs.litellm.ai/docs/providers

21:39:46 - openhands:ERROR: retry_mixin.py:47 - litellm.ServiceUnavailableError: OllamaException: HTTPConnectionPool(host='127.0.0.1', port=11434): Max retries exceeded with url: /v1/api/generate (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f944761d4f0>: Failed to establish a new connection: [Errno 111] Connection refused')). Attempt #6 | You can customize retry values in the configuration.

Give Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new
LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.


Provider List: https://docs.litellm.ai/docs/providers

21:40:54 - openhands:ERROR: retry_mixin.py:47 - litellm.ServiceUnavailableError: OllamaException: HTTPConnectionPool(host='127.0.0.1', port=11434): Max retries exceeded with url: /v1/api/generate (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f9447e8cd70>: Failed to establish a new connection: [Errno 111] Connection refused')). Attempt #7 | You can customize retry values in the configuration.

Give Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new
LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.


Provider List: https://docs.litellm.ai/docs/providers

Traceback (most recent call last):
  File "/app/.venv/lib/python3.12/site-packages/urllib3/connection.py", line 199, in _new_conn
    sock = connection.create_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/urllib3/util/connection.py", line 85, in create_connection
    raise err
  File "/app/.venv/lib/python3.12/site-packages/urllib3/util/connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/app/.venv/lib/python3.12/site-packages/urllib3/connectionpool.py", line 789, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/urllib3/connectionpool.py", line 495, in _make_request
    conn.request(
  File "/app/.venv/lib/python3.12/site-packages/urllib3/connection.py", line 441, in request
    self.endheaders()
  File "/usr/local/lib/python3.12/http/client.py", line 1331, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/usr/local/lib/python3.12/http/client.py", line 1091, in _send_output
    self.send(msg)
  File "/usr/local/lib/python3.12/http/client.py", line 1035, in send
    self.connect()
  File "/app/.venv/lib/python3.12/site-packages/urllib3/connection.py", line 279, in connect
    self.sock = self._new_conn()
                ^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/urllib3/connection.py", line 214, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7f944761dee0>: Failed to establish a new connection: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/app/.venv/lib/python3.12/site-packages/requests/adapters.py", line 667, in send
    resp = conn.urlopen(
           ^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/urllib3/connectionpool.py", line 843, in urlopen
    retries = retries.increment(
              ^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/urllib3/util/retry.py", line 519, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=11434): Max retries exceeded with url: /v1/api/generate (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f944761dee0>: Failed to establish a new connection: [Errno 111] Connection refused'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/app/.venv/lib/python3.12/site-packages/litellm/main.py", line 2709, in completion
    generator = ollama.get_ollama_response(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/litellm/llms/ollama.py", line 316, in get_ollama_response
    response = requests.post(
               ^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/requests/api.py", line 115, in post
    return request("post", url, data=data, json=json, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/requests/api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/requests/adapters.py", line 700, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=11434): Max retries exceeded with url: /v1/api/generate (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f944761dee0>: Failed to establish a new connection: [Errno 111] Connection refused'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/app/openhands/controller/agent_controller.py", line 168, in start_step_loop
    await self._step()
  File "/app/openhands/controller/agent_controller.py", line 464, in _step
    action = self.agent.step(self.state)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/openhands/agenthub/codeact_agent/codeact_agent.py", line 359, in step
    response = self.llm.completion(**params)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/tenacity/__init__.py", line 336, in wrapped_f
    return copy(f, *args, **kw)
           ^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/tenacity/__init__.py", line 475, in __call__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/tenacity/__init__.py", line 418, in exc_check
    raise retry_exc.reraise()
          ^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/tenacity/__init__.py", line 185, in reraise
    raise self.last_attempt.result()
          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/app/.venv/lib/python3.12/site-packages/tenacity/__init__.py", line 478, in __call__
    result = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/app/openhands/llm/llm.py", line 196, in wrapper
    resp: ModelResponse = completion_unwrapped(*args, **kwargs)
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/litellm/utils.py", line 1013, in wrapper
    raise e
  File "/app/.venv/lib/python3.12/site-packages/litellm/utils.py", line 903, in wrapper
    result = original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/litellm/main.py", line 2999, in completion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2116, in exception_type
    raise e
  File "/app/.venv/lib/python3.12/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1785, in exception_type
    raise ServiceUnavailableError(
litellm.exceptions.ServiceUnavailableError: litellm.ServiceUnavailableError: OllamaException: HTTPConnectionPool(host='127.0.0.1', port=11434): Max retries exceeded with url: /v1/api/generate (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f944761dee0>: Failed to establish a new connection: [Errno 111] Connection refused'))
21:43:01 - openhands:ERROR: agent_controller.py:135 - [Agent Controller ec6f817b-3465-47bc-8889-de162172081a] Error while running the agent: litellm.ServiceUnavailableError: OllamaException: HTTPConnectionPool(host='127.0.0.1', port=11434): Max retries exceeded with url: /v1/api/generate (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f944761dee0>: Failed to establish a new connection: [Errno 111] Connection refused'))
21:43:01 - openhands:ERROR: agent_controller.py:135 - [Agent Controller ec6f817b-3465-47bc-8889-de162172081a] Traceback (most recent call last):
  File "/app/.venv/lib/python3.12/site-packages/urllib3/connection.py", line 199, in _new_conn
    sock = connection.create_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/urllib3/util/connection.py", line 85, in create_connection
    raise err
  File "/app/.venv/lib/python3.12/site-packages/urllib3/util/connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/app/.venv/lib/python3.12/site-packages/urllib3/connectionpool.py", line 789, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/urllib3/connectionpool.py", line 495, in _make_request
    conn.request(
  File "/app/.venv/lib/python3.12/site-packages/urllib3/connection.py", line 441, in request
    self.endheaders()
  File "/usr/local/lib/python3.12/http/client.py", line 1331, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/usr/local/lib/python3.12/http/client.py", line 1091, in _send_output
    self.send(msg)
  File "/usr/local/lib/python3.12/http/client.py", line 1035, in send
    self.connect()
  File "/app/.venv/lib/python3.12/site-packages/urllib3/connection.py", line 279, in connect
    self.sock = self._new_conn()
                ^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/urllib3/connection.py", line 214, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7f944761dee0>: Failed to establish a new connection: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/app/.venv/lib/python3.12/site-packages/requests/adapters.py", line 667, in send
    resp = conn.urlopen(
           ^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/urllib3/connectionpool.py", line 843, in urlopen
    retries = retries.increment(
              ^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/urllib3/util/retry.py", line 519, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=11434): Max retries exceeded with url: /v1/api/generate (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f944761dee0>: Failed to establish a new connection: [Errno 111] Connection refused'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/app/.venv/lib/python3.12/site-packages/litellm/main.py", line 2709, in completion
    generator = ollama.get_ollama_response(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/litellm/llms/ollama.py", line 316, in get_ollama_response
    response = requests.post(
               ^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/requests/api.py", line 115, in post
    return request("post", url, data=data, json=json, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/requests/api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/requests/adapters.py", line 700, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=11434): Max retries exceeded with url: /v1/api/generate (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f944761dee0>: Failed to establish a new connection: [Errno 111] Connection refused'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/app/openhands/controller/agent_controller.py", line 168, in start_step_loop
    await self._step()
  File "/app/openhands/controller/agent_controller.py", line 464, in _step
    action = self.agent.step(self.state)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/openhands/agenthub/codeact_agent/codeact_agent.py", line 359, in step
    response = self.llm.completion(**params)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/tenacity/__init__.py", line 336, in wrapped_f
    return copy(f, *args, **kw)
           ^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/tenacity/__init__.py", line 475, in __call__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/tenacity/__init__.py", line 418, in exc_check
    raise retry_exc.reraise()
          ^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/tenacity/__init__.py", line 185, in reraise
    raise self.last_attempt.result()
          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/app/.venv/lib/python3.12/site-packages/tenacity/__init__.py", line 478, in __call__
    result = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/app/openhands/llm/llm.py", line 196, in wrapper
    resp: ModelResponse = completion_unwrapped(*args, **kwargs)
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/litellm/utils.py", line 1013, in wrapper
    raise e
  File "/app/.venv/lib/python3.12/site-packages/litellm/utils.py", line 903, in wrapper
    result = original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/litellm/main.py", line 2999, in completion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2116, in exception_type
    raise e
  File "/app/.venv/lib/python3.12/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1785, in exception_type
    raise ServiceUnavailableError(
litellm.exceptions.ServiceUnavailableError: litellm.ServiceUnavailableError: OllamaException: HTTPConnectionPool(host='127.0.0.1', port=11434): Max retries exceeded with url: /v1/api/generate (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f944761dee0>: Failed to establish a new connection: [Errno 111] Connection refused'))

21:43:01 - openhands:INFO: agent_controller.py:135 - [Agent Controller ec6f817b-3465-47bc-8889-de162172081a] Setting agent(CodeActAgent) state from AgentState.RUNNING to AgentState.ERROR
^CINFO:     Shutting down
21:45:11 - openhands:INFO: session.py:66 - WebSocket disconnected, sid: ec6f817b-3465-47bc-8889-de162172081a
INFO:     connection closed
INFO:     Waiting for application shutdown.
INFO:     Application shutdown complete.
INFO:     Finished server process [10]
m@DESKTOP-MUB16F8:~$ docker run -it --privileged --rm \
>   -e LLM_API_KEY="ollama" \
>   -e OLLAMA_HOST="http://172.21.151.42:11434" \
e LLM_O>   -e LLM_OLLAMA_BASE_URL="http://172.21.151.42:11434" \
LAMA_BA>   -e OLLAMA_BASE_URL="http://172.21.151.42:11434" \
>   -e OLLAMA_URL="http://172.21.151.42:11434" \
>   -e SANDBOX_RUNTIME_CONTAINER_IMAGE="docker.all-hands.dev/all-hands-ai/runtime:0.12-nikolaik" \
>   -v /var/run/docker.sock:/var/run/docker.sock \
>   -p 3000:3000 \
>   --name openhands-app \
>   docker.all-hands.dev/all-hands-ai/openhands:0.12
Starting OpenHands...
Running OpenHands as root
INFO:     Started server process [10]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:3000 (Press CTRL+C to quit)
INFO:     172.17.0.1:36792 - "GET / HTTP/1.1" 200 OK
INFO:     172.17.0.1:36792 - "GET /locales/en/translation.json HTTP/1.1" 200 OK
INFO:     172.17.0.1:36792 - "GET /config.json HTTP/1.1" 200 OK
INFO:     172.17.0.1:36804 - "GET /config.json HTTP/1.1" 200 OK
INFO:     172.17.0.1:36804 - "GET /config.json HTTP/1.1" 200 OK
21:47:40 - openhands:INFO: github.py:14 - Initializing UserVerifier
21:47:40 - openhands:INFO: github.py:27 - GITHUB_USER_LIST_FILE not configured
21:47:40 - openhands:INFO: github.py:48 - GITHUB_USERS_SHEET_ID not configured
21:47:40 - openhands:INFO: github.py:85 - No user verification sources configured - allowing all users
INFO:     ('172.17.0.1', 36814) - "WebSocket /ws" [accepted]
21:47:40 - openhands:ERROR: auth.py:27 - Invalid token
INFO:     connection open
INFO:     172.17.0.1:36804 - "GET /api/options/models HTTP/1.1" 200 OK
INFO:     172.17.0.1:36792 - "GET /api/options/agents HTTP/1.1" 200 OK
INFO:     172.17.0.1:36824 - "GET /api/options/security-analyzers HTTP/1.1" 200 OK
INFO:     connection closed
INFO:     172.17.0.1:36824 - "GET /config.json HTTP/1.1" 200 OK
INFO:     172.17.0.1:36792 - "GET /config.json HTTP/1.1" 200 OK
INFO:     172.17.0.1:41722 - "GET /config.json HTTP/1.1" 200 OK
INFO:     172.17.0.1:41724 - "GET /config.json HTTP/1.1" 200 OK
INFO:     172.17.0.1:41724 - "GET /config.json HTTP/1.1" 200 OK
INFO:     172.17.0.1:41722 - "GET /config.json HTTP/1.1" 200 OK
INFO:     172.17.0.1:41722 - "GET /config.json HTTP/1.1" 200 OK
21:50:12 - openhands:INFO: github.py:14 - Initializing UserVerifier
21:50:12 - openhands:INFO: github.py:27 - GITHUB_USER_LIST_FILE not configured
21:50:12 - openhands:INFO: github.py:48 - GITHUB_USERS_SHEET_ID not configured
21:50:12 - openhands:INFO: github.py:85 - No user verification sources configured - allowing all users
INFO:     ('172.17.0.1', 36342) - "WebSocket /ws" [accepted]
21:50:12 - openhands:INFO: listen.py:336 - New session: c08adb0a-d9b2-4563-866f-0140cc503d3e
INFO:     connection open
21:50:12 - openhands:WARNING: codeact_agent.py:101 - Function calling not supported for model ollama/llama3:latest. Disabling function calling.
INFO:     172.17.0.1:41722 - "GET /config.json HTTP/1.1" 200 OK
21:50:13 - openhands:INFO: base.py:98 - [runtime c08adb0a-d9b2-4563-866f-0140cc503d3e] Starting runtime with image: docker.all-hands.dev/all-hands-ai/runtime:0.12-nikolaik
21:50:13 - openhands:INFO: base.py:98 - [runtime c08adb0a-d9b2-4563-866f-0140cc503d3e] Container started: openhands-runtime-c08adb0a-d9b2-4563-866f-0140cc503d3e
21:50:13 - openhands:INFO: base.py:98 - [runtime c08adb0a-d9b2-4563-866f-0140cc503d3e] Waiting for client to become ready at http://host.docker.internal:38003...
21:51:05 - openhands:INFO: base.py:98 - [runtime c08adb0a-d9b2-4563-866f-0140cc503d3e] Runtime is ready.
21:51:05 - openhands:WARNING: state.py:118 - Failed to restore state from session: sessions/c08adb0a-d9b2-4563-866f-0140cc503d3e/agent_state.pkl
21:51:05 - openhands:INFO: agent_controller.py:135 - [Agent Controller c08adb0a-d9b2-4563-866f-0140cc503d3e] Starting step loop...
21:51:05 - openhands:INFO: agent_controller.py:135 - [Agent Controller c08adb0a-d9b2-4563-866f-0140cc503d3e] Setting agent(CodeActAgent) state from AgentState.LOADING to AgentState.INIT
21:51:05 - openhands:INFO: agent_controller.py:135 - [Agent Controller c08adb0a-d9b2-4563-866f-0140cc503d3e] Setting agent(CodeActAgent) state from AgentState.INIT to AgentState.RUNNING
21:51:05 - openhands:INFO: github.py:14 - Initializing UserVerifier
21:51:05 - openhands:INFO: github.py:27 - GITHUB_USER_LIST_FILE not configured
21:51:05 - openhands:INFO: github.py:48 - GITHUB_USERS_SHEET_ID not configured
21:51:05 - openhands:INFO: github.py:85 - No user verification sources configured - allowing all users
INFO:     172.17.0.1:43552 - "GET /config.json HTTP/1.1" 200 OK
INFO:     172.17.0.1:43554 - "GET /config.json HTTP/1.1" 200 OK
INFO:     172.17.0.1:43546 - "GET /api/list-files HTTP/1.1" 200 OK
21:51:05 - openhands:INFO: github.py:14 - Initializing UserVerifier
21:51:05 - openhands:INFO: github.py:27 - GITHUB_USER_LIST_FILE not configured
21:51:05 - openhands:INFO: github.py:48 - GITHUB_USERS_SHEET_ID not configured
21:51:05 - openhands:INFO: github.py:85 - No user verification sources configured - allowing all users
INFO:     172.17.0.1:43554 - "GET /api/list-files HTTP/1.1" 200 OK
21:51:06 - openhands:INFO: github.py:14 - Initializing UserVerifier
21:51:06 - openhands:INFO: github.py:27 - GITHUB_USER_LIST_FILE not configured
21:51:06 - openhands:INFO: github.py:48 - GITHUB_USERS_SHEET_ID not configured
21:51:06 - openhands:INFO: github.py:85 - No user verification sources configured - allowing all users
INFO:     172.17.0.1:43546 - "GET /api/list-files HTTP/1.1" 200 OK


==============
[Agent Controller c08adb0a-d9b2-4563-866f-0140cc503d3e] LEVEL 0 LOCAL STEP 0 GLOBAL STEP 0


Provider List: https://docs.litellm.ai/docs/providers


Provider List: https://docs.litellm.ai/docs/providers


Give Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new
LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.


Provider List: https://docs.litellm.ai/docs/providers

21:51:06 - openhands:ERROR: retry_mixin.py:47 - litellm.ServiceUnavailableError: OllamaException: HTTPConnectionPool(host='127.0.0.1', port=11434): Max retries exceeded with url: /v1/api/generate (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f973248b380>: Failed to establish a new connection: [Errno 111] Connection refused')). Attempt #1 | You can customize retry values in the configuration.

Give Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new
LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.


Provider List: https://docs.litellm.ai/docs/providers

21:51:23 - openhands:ERROR: retry_mixin.py:47 - litellm.ServiceUnavailableError: OllamaException: HTTPConnectionPool(host='127.0.0.1', port=11434): Max retries exceeded with url: /v1/api/generate (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f9732b8ba40>: Failed to establish a new connection: [Errno 111] Connection refused')). Attempt #2 | You can customize retry values in the configuration.

Give Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new
LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.


Provider List: https://docs.litellm.ai/docs/providers

21:51:38 - openhands:ERROR: retry_mixin.py:47 - litellm.ServiceUnavailableError: OllamaException: HTTPConnectionPool(host='127.0.0.1', port=11434): Max retries exceeded with url: /v1/api/generate (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f9732328140>: Failed to establish a new connection: [Errno 111] Connection refused')). Attempt #3 | You can customize retry values in the configuration.

Give Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new
LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.


Provider List: https://docs.litellm.ai/docs/providers

21:51:55 - openhands:ERROR: retry_mixin.py:47 - litellm.ServiceUnavailableError: OllamaException: HTTPConnectionPool(host='127.0.0.1', port=11434): Max retries exceeded with url: /v1/api/generate (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f9732329580>: Failed to establish a new connection: [Errno 111] Connection refused')). Attempt #4 | You can customize retry values in the configuration.

Give Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new
LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.


Provider List: https://docs.litellm.ai/docs/providers

21:52:11 - openhands:ERROR: retry_mixin.py:47 - litellm.ServiceUnavailableError: OllamaException: HTTPConnectionPool(host='127.0.0.1', port=11434): Max retries exceeded with url: /v1/api/generate (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f9732513380>: Failed to establish a new connection: [Errno 111] Connection refused')). Attempt #5 | You can customize retry values in the configuration.
INFO:     172.17.0.1:47786 - "GET /config.json HTTP/1.1" 200 OK
INFO:     172.17.0.1:47786 - "GET /config.json HTTP/1.1" 200 OK
INFO:     172.17.0.1:47796 - "GET /config.json HTTP/1.1" 200 OK
21:52:32 - openhands:INFO: session.py:66 - WebSocket disconnected, sid: c08adb0a-d9b2-4563-866f-0140cc503d3e
INFO:     connection closed
INFO:     172.17.0.1:47796 - "GET /config.json HTTP/1.1" 200 OK
INFO:     172.17.0.1:47796 - "GET /config.json HTTP/1.1" 200 OK
21:52:36 - openhands:INFO: github.py:14 - Initializing UserVerifier
21:52:36 - openhands:INFO: github.py:27 - GITHUB_USER_LIST_FILE not configured
21:52:36 - openhands:INFO: github.py:48 - GITHUB_USERS_SHEET_ID not configured
21:52:36 - openhands:INFO: github.py:85 - No user verification sources configured - allowing all users
INFO:     ('172.17.0.1', 47808) - "WebSocket /ws" [accepted]
21:52:36 - openhands:INFO: listen.py:336 - New session: 7efbf261-c0d5-4ed3-82ae-144e1c9bea1b
INFO:     connection open
21:52:36 - openhands:WARNING: codeact_agent.py:101 - Function calling not supported for model ollama/llama3:latest. Disabling function calling.
INFO:     172.17.0.1:47796 - "GET /config.json HTTP/1.1" 200 OK
21:52:36 - openhands:INFO: base.py:98 - [runtime 7efbf261-c0d5-4ed3-82ae-144e1c9bea1b] Starting runtime with image: docker.all-hands.dev/all-hands-ai/runtime:0.12-nikolaik
21:52:37 - openhands:INFO: github.py:14 - Initializing UserVerifier
21:52:37 - openhands:INFO: github.py:27 - GITHUB_USER_LIST_FILE not configured
21:52:37 - openhands:INFO: github.py:48 - GITHUB_USERS_SHEET_ID not configured
21:52:37 - openhands:INFO: github.py:85 - No user verification sources configured - allowing all users
INFO:     172.17.0.1:47796 - "GET /api/list-files HTTP/1.1" 500 Internal Server Error
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/app/.venv/lib/python3.12/site-packages/docker/api/client.py", line 275, in _raise_for_status
    response.raise_for_status()
  File "/app/.venv/lib/python3.12/site-packages/requests/models.py", line 1024, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: http+docker://localhost/v1.49/containers/openhands-runtime-7efbf261-c0d5-4ed3-82ae-144e1c9bea1b/json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/app/.venv/lib/python3.12/site-packages/uvicorn/protocols/http/h11_impl.py", line 406, in run_asgi
    result = await app(  # type: ignore[func-returns-value]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/uvicorn/middleware/proxy_headers.py", line 60, in __call__
    return await self.app(scope, receive, send)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/fastapi/applications.py", line 1054, in __call__
    await super().__call__(scope, receive, send)
  File "/app/.venv/lib/python3.12/site-packages/starlette/applications.py", line 113, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/app/.venv/lib/python3.12/site-packages/starlette/middleware/errors.py", line 187, in __call__
    raise exc
  File "/app/.venv/lib/python3.12/site-packages/starlette/middleware/errors.py", line 165, in __call__
    await self.app(scope, receive, _send)
  File "/app/.venv/lib/python3.12/site-packages/starlette/middleware/base.py", line 185, in __call__
    with collapse_excgroups():
  File "/usr/local/lib/python3.12/contextlib.py", line 158, in __exit__
    self.gen.throw(value)
  File "/app/.venv/lib/python3.12/site-packages/starlette/_utils.py", line 82, in collapse_excgroups
    raise exc
  File "/app/.venv/lib/python3.12/site-packages/starlette/middleware/base.py", line 187, in __call__
    response = await self.dispatch_func(request, call_next)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/openhands/server/listen.py", line 233, in attach_session
    request.state.conversation = await session_manager.attach_to_conversation(
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/openhands/server/session/manager.py", line 53, in attach_to_conversation
    await c.connect()
  File "/app/openhands/server/session/conversation.py", line 42, in connect
    await self.runtime.connect()
  File "/app/openhands/runtime/impl/eventstream/eventstream_runtime.py", line 212, in connect
    self._attach_to_container()
  File "/app/openhands/runtime/impl/eventstream/eventstream_runtime.py", line 350, in _attach_to_container
    container = self.docker_client.containers.get(self.container_name)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/docker/models/containers.py", line 954, in get
    resp = self.client.api.inspect_container(container_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/docker/utils/decorators.py", line 19, in wrapped
    return f(self, resource_id, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/docker/api/container.py", line 793, in inspect_container
    return self._result(
           ^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/docker/api/client.py", line 281, in _result
    self._raise_for_status(response)
  File "/app/.venv/lib/python3.12/site-packages/docker/api/client.py", line 277, in _raise_for_status
    raise create_api_error_from_http_exception(e) from e
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/docker/errors.py", line 39, in create_api_error_from_http_exception
    raise cls(e, response=response, explanation=explanation) from e
docker.errors.NotFound: 404 Client Error for http+docker://localhost/v1.49/containers/openhands-runtime-7efbf261-c0d5-4ed3-82ae-144e1c9bea1b/json: Not Found ("No such container: openhands-runtime-7efbf261-c0d5-4ed3-82ae-144e1c9bea1b")
21:52:37 - openhands:INFO: base.py:98 - [runtime 7efbf261-c0d5-4ed3-82ae-144e1c9bea1b] Container started: openhands-runtime-7efbf261-c0d5-4ed3-82ae-144e1c9bea1b
21:52:37 - openhands:INFO: base.py:98 - [runtime 7efbf261-c0d5-4ed3-82ae-144e1c9bea1b] Waiting for client to become ready at http://host.docker.internal:33243...
INFO:     172.17.0.1:44462 - "GET /app HTTP/1.1" 200 OK
21:52:41 - openhands:INFO: session.py:66 - WebSocket disconnected, sid: 7efbf261-c0d5-4ed3-82ae-144e1c9bea1b
INFO:     connection closed
INFO:     172.17.0.1:44462 - "GET /locales/en/translation.json HTTP/1.1" 200 OK
INFO:     172.17.0.1:44462 - "GET /favicon.ico HTTP/1.1" 200 OK
INFO:     172.17.0.1:44462 - "GET /config.json HTTP/1.1" 200 OK
21:52:41 - openhands:INFO: github.py:14 - Initializing UserVerifier
21:52:41 - openhands:INFO: github.py:27 - GITHUB_USER_LIST_FILE not configured
21:52:41 - openhands:INFO: github.py:48 - GITHUB_USERS_SHEET_ID not configured
21:52:41 - openhands:INFO: github.py:85 - No user verification sources configured - allowing all users
INFO:     172.17.0.1:44462 - "POST /api/authenticate HTTP/1.1" 200 OK
21:52:41 - openhands:INFO: github.py:14 - Initializing UserVerifier
21:52:41 - openhands:INFO: github.py:27 - GITHUB_USER_LIST_FILE not configured
21:52:41 - openhands:INFO: github.py:48 - GITHUB_USERS_SHEET_ID not configured
21:52:41 - openhands:INFO: github.py:85 - No user verification sources configured - allowing all users
INFO:     ('172.17.0.1', 44484) - "WebSocket /ws" [accepted]
21:52:41 - openhands:INFO: listen.py:336 - New session: 7efbf261-c0d5-4ed3-82ae-144e1c9bea1b
INFO:     172.17.0.1:44462 - "GET /api/options/models HTTP/1.1" 200 OK
INFO:     connection open
INFO:     172.17.0.1:44468 - "GET /api/options/agents HTTP/1.1" 200 OK
INFO:     172.17.0.1:44494 - "GET /api/options/security-analyzers HTTP/1.1" 200 OK
21:52:41 - openhands:WARNING: codeact_agent.py:101 - Function calling not supported for model ollama/llama3:latest. Disabling function calling.
INFO:     172.17.0.1:44494 - "GET /config.json HTTP/1.1" 200 OK
21:52:42 - openhands:INFO: base.py:98 - [runtime 7efbf261-c0d5-4ed3-82ae-144e1c9bea1b] Starting runtime with image: docker.all-hands.dev/all-hands-ai/runtime:0.12-nikolaik
21:52:42 - openhands:ERROR: base.py:98 - [runtime 7efbf261-c0d5-4ed3-82ae-144e1c9bea1b] Error: Instance openhands-runtime-7efbf261-c0d5-4ed3-82ae-144e1c9bea1b FAILED to start container!

21:52:42 - openhands:ERROR: base.py:98 - [runtime 7efbf261-c0d5-4ed3-82ae-144e1c9bea1b] 409 Client Error for http+docker://localhost/v1.49/containers/create?name=openhands-runtime-7efbf261-c0d5-4ed3-82ae-144e1c9bea1b: Conflict ("Conflict. The container name "/openhands-runtime-7efbf261-c0d5-4ed3-82ae-144e1c9bea1b" is already in use by container "e84c484233a8d3213f0a9c941e8999dacfa2b83284b44b545b4ebea320882dc0". You have to remove (or rename) that container to be able to reuse that name.")

Give Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new
LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.


Provider List: https://docs.litellm.ai/docs/providers

21:52:47 - openhands:ERROR: retry_mixin.py:47 - litellm.ServiceUnavailableError: OllamaException: HTTPConnectionPool(host='127.0.0.1', port=11434): Max retries exceeded with url: /v1/api/generate (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f97324b6de0>: Failed to establish a new connection: [Errno 111] Connection refused')). Attempt #6 | You can customize retry values in the configuration.
21:52:51 - openhands:INFO: base.py:98 - [runtime 7efbf261-c0d5-4ed3-82ae-144e1c9bea1b] Container started: openhands-runtime-7efbf261-c0d5-4ed3-82ae-144e1c9bea1b
21:52:51 - openhands:INFO: base.py:98 - [runtime 7efbf261-c0d5-4ed3-82ae-144e1c9bea1b] Waiting for client to become ready at http://host.docker.internal:35712...
21:53:23 - openhands:INFO: base.py:98 - [runtime 7efbf261-c0d5-4ed3-82ae-144e1c9bea1b] Runtime is ready.
21:53:23 - openhands:WARNING: state.py:118 - Failed to restore state from session: sessions/7efbf261-c0d5-4ed3-82ae-144e1c9bea1b/agent_state.pkl
21:53:23 - openhands:INFO: agent_controller.py:135 - [Agent Controller 7efbf261-c0d5-4ed3-82ae-144e1c9bea1b] Starting step loop...
21:53:23 - openhands:INFO: agent_controller.py:135 - [Agent Controller 7efbf261-c0d5-4ed3-82ae-144e1c9bea1b] Setting agent(CodeActAgent) state from AgentState.LOADING to AgentState.INIT
21:53:23 - openhands:INFO: github.py:14 - Initializing UserVerifier
21:53:23 - openhands:INFO: github.py:27 - GITHUB_USER_LIST_FILE not configured
21:53:23 - openhands:INFO: github.py:48 - GITHUB_USERS_SHEET_ID not configured
21:53:23 - openhands:INFO: github.py:85 - No user verification sources configured - allowing all users
INFO:     172.17.0.1:35938 - "GET /config.json HTTP/1.1" 200 OK
INFO:     172.17.0.1:35934 - "GET /api/list-files HTTP/1.1" 200 OK
21:53:23 - openhands:INFO: github.py:14 - Initializing UserVerifier
21:53:23 - openhands:INFO: github.py:27 - GITHUB_USER_LIST_FILE not configured
21:53:23 - openhands:INFO: github.py:48 - GITHUB_USERS_SHEET_ID not configured
21:53:23 - openhands:INFO: github.py:85 - No user verification sources configured - allowing all users
INFO:     172.17.0.1:35938 - "GET /api/list-files HTTP/1.1" 200 OK
21:53:31 - openhands:INFO: agent_controller.py:135 - [Agent Controller 7efbf261-c0d5-4ed3-82ae-144e1c9bea1b] Setting agent(CodeActAgent) state from AgentState.INIT to AgentState.RUNNING
21:53:31 - openhands:INFO: github.py:14 - Initializing UserVerifier
21:53:31 - openhands:INFO: github.py:27 - GITHUB_USER_LIST_FILE not configured
21:53:31 - openhands:INFO: github.py:48 - GITHUB_USERS_SHEET_ID not configured
21:53:31 - openhands:INFO: github.py:85 - No user verification sources configured - allowing all users


==============
[Agent Controller 7efbf261-c0d5-4ed3-82ae-144e1c9bea1b] LEVEL 0 LOCAL STEP 0 GLOBAL STEP 0


Provider List: https://docs.litellm.ai/docs/providers


Provider List: https://docs.litellm.ai/docs/providers


Give Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new
LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.


Provider List: https://docs.litellm.ai/docs/providers

21:53:31 - openhands:ERROR: retry_mixin.py:47 - litellm.ServiceUnavailableError: OllamaException: HTTPConnectionPool(host='127.0.0.1', port=11434): Max retries exceeded with url: /api/generate (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f972174f980>: Failed to establish a new connection: [Errno 111] Connection refused')). Attempt #1 | You can customize retry values in the configuration.
INFO:     172.17.0.1:35954 - "GET /config.json HTTP/1.1" 200 OK
INFO:     172.17.0.1:35952 - "GET /api/list-files HTTP/1.1" 200 OK

Give Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new
LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.


Provider List: https://docs.litellm.ai/docs/providers

21:53:46 - openhands:ERROR: retry_mixin.py:47 - litellm.ServiceUnavailableError: OllamaException: HTTPConnectionPool(host='127.0.0.1', port=11434): Max retries exceeded with url: /api/generate (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f9721785dc0>: Failed to establish a new connection: [Errno 111] Connection refused')). Attempt #2 | You can customize retry values in the configuration.

Give Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new
LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.


Provider List: https://docs.litellm.ai/docs/providers

21:53:55 - openhands:ERROR: retry_mixin.py:47 - litellm.ServiceUnavailableError: OllamaException: HTTPConnectionPool(host='127.0.0.1', port=11434): Max retries exceeded with url: /v1/api/generate (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f97217800b0>: Failed to establish a new connection: [Errno 111] Connection refused')). Attempt #7 | You can customize retry values in the configuration.

Give Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new
LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.


Provider List: https://docs.litellm.ai/docs/providers

21:54:04 - openhands:ERROR: retry_mixin.py:47 - litellm.ServiceUnavailableError: OllamaException: HTTPConnectionPool(host='127.0.0.1', port=11434): Max retries exceeded with url: /api/generate (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f9721785340>: Failed to establish a new connection: [Errno 111] Connection refused')). Attempt #3 | You can customize retry values in the configuration.

Give Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new
LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.


Provider List: https://docs.litellm.ai/docs/providers

21:54:19 - openhands:ERROR: retry_mixin.py:47 - litellm.ServiceUnavailableError: OllamaException: HTTPConnectionPool(host='127.0.0.1', port=11434): Max retries exceeded with url: /api/generate (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f9721786e40>: Failed to establish a new connection: [Errno 111] Connection refused')). Attempt #4 | You can customize retry values in the configuration.

Give Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new
LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.


Provider List: https://docs.litellm.ai/docs/providers

21:54:35 - openhands:ERROR: retry_mixin.py:47 - litellm.ServiceUnavailableError: OllamaException: HTTPConnectionPool(host='127.0.0.1', port=11434): Max retries exceeded with url: /api/generate (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f9721785520>: Failed to establish a new connection: [Errno 111] Connection refused')). Attempt #5 | You can customize retry values in the configuration.
21:54:57 - openhands:ERROR: agent_session.py:191 - Runtime initialization failed: HTTPConnectionPool(host='host.docker.internal', port=33243): Max retries exceeded with url: /alive (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f9721780e00>: Failed to establish a new connection: [Errno 101] Network is unreachable'))
Traceback (most recent call last):
  File "/app/.venv/lib/python3.12/site-packages/urllib3/connection.py", line 199, in _new_conn
    sock = connection.create_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/urllib3/util/connection.py", line 85, in create_connection
    raise err
  File "/app/.venv/lib/python3.12/site-packages/urllib3/util/connection.py", line 73, in create_connection
    sock.connect(sa)
OSError: [Errno 101] Network is unreachable

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/app/.venv/lib/python3.12/site-packages/urllib3/connectionpool.py", line 789, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/urllib3/connectionpool.py", line 495, in _make_request
    conn.request(
  File "/app/.venv/lib/python3.12/site-packages/urllib3/connection.py", line 441, in request
    self.endheaders()
  File "/usr/local/lib/python3.12/http/client.py", line 1331, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/usr/local/lib/python3.12/http/client.py", line 1091, in _send_output
    self.send(msg)
  File "/usr/local/lib/python3.12/http/client.py", line 1035, in send
    self.connect()
  File "/app/.venv/lib/python3.12/site-packages/urllib3/connection.py", line 279, in connect
    self.sock = self._new_conn()
                ^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/urllib3/connection.py", line 214, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7f9721780e00>: Failed to establish a new connection: [Errno 101] Network is unreachable

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/app/.venv/lib/python3.12/site-packages/requests/adapters.py", line 667, in send
    resp = conn.urlopen(
           ^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/urllib3/connectionpool.py", line 843, in urlopen
    retries = retries.increment(
              ^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/urllib3/util/retry.py", line 519, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='host.docker.internal', port=33243): Max retries exceeded with url: /alive (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f9721780e00>: Failed to establish a new connection: [Errno 101] Network is unreachable'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/app/openhands/server/session/agent_session.py", line 189, in _create_runtime
    await self.runtime.connect()
  File "/app/openhands/runtime/impl/eventstream/eventstream_runtime.py", line 217, in connect
    self._wait_until_alive()
  File "/app/.venv/lib/python3.12/site-packages/tenacity/__init__.py", line 336, in wrapped_f
    return copy(f, *args, **kw)
           ^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/tenacity/__init__.py", line 475, in __call__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/tenacity/__init__.py", line 418, in exc_check
    raise retry_exc.reraise()
          ^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/tenacity/__init__.py", line 185, in reraise
    raise self.last_attempt.result()
          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/app/.venv/lib/python3.12/site-packages/tenacity/__init__.py", line 478, in __call__
    result = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/app/openhands/runtime/impl/eventstream/eventstream_runtime.py", line 395, in _wait_until_alive
    response = send_request_with_retry(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/openhands/runtime/utils/request.py", line 96, in send_request_with_retry
    return _send_request_with_retry()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/tenacity/__init__.py", line 336, in wrapped_f
    return copy(f, *args, **kw)
           ^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/tenacity/__init__.py", line 475, in __call__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/app/.venv/lib/python3.12/site-packages/tenacity/__init__.py", line 478, in __call__
    result = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/app/openhands/runtime/utils/request.py", line 92, in _send_request_with_retry
    response = session.request(method, url, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/requests/adapters.py", line 700, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='host.docker.internal', port=33243): Max retries exceeded with url: /alive (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f9721780e00>: Failed to establish a new connection: [Errno 101] Network is unreachable'))
ERROR:asyncio:Future exception was never retrieved
future: <Future finished exception=ConnectionError(MaxRetryError("HTTPConnectionPool(host='host.docker.internal', port=33243): Max retries exceeded with url: /alive (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f9721780e00>: Failed to establish a new connection: [Errno 101] Network is unreachable'))"))>
Traceback (most recent call last):
  File "/app/.venv/lib/python3.12/site-packages/urllib3/connection.py", line 199, in _new_conn
    sock = connection.create_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/urllib3/util/connection.py", line 85, in create_connection
    raise err
  File "/app/.venv/lib/python3.12/site-packages/urllib3/util/connection.py", line 73, in create_connection
    sock.connect(sa)
OSError: [Errno 101] Network is unreachable

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/app/.venv/lib/python3.12/site-packages/urllib3/connectionpool.py", line 789, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/urllib3/connectionpool.py", line 495, in _make_request
    conn.request(
  File "/app/.venv/lib/python3.12/site-packages/urllib3/connection.py", line 441, in request
    self.endheaders()
  File "/usr/local/lib/python3.12/http/client.py", line 1331, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/usr/local/lib/python3.12/http/client.py", line 1091, in _send_output
    self.send(msg)
  File "/usr/local/lib/python3.12/http/client.py", line 1035, in send
    self.connect()
  File "/app/.venv/lib/python3.12/site-packages/urllib3/connection.py", line 279, in connect
    self.sock = self._new_conn()
                ^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/urllib3/connection.py", line 214, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7f9721780e00>: Failed to establish a new connection: [Errno 101] Network is unreachable

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/app/.venv/lib/python3.12/site-packages/requests/adapters.py", line 667, in send
    resp = conn.urlopen(
           ^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/urllib3/connectionpool.py", line 843, in urlopen
    retries = retries.increment(
              ^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/urllib3/util/retry.py", line 519, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='host.docker.internal', port=33243): Max retries exceeded with url: /alive (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f9721780e00>: Failed to establish a new connection: [Errno 101] Network is unreachable'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.12/concurrent/futures/thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/openhands/server/session/agent_session.py", line 88, in _start_thread
    asyncio.run(self._start(*args), debug=True)
  File "/usr/local/lib/python3.12/asyncio/runners.py", line 194, in run
    return runner.run(main)
           ^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/asyncio/runners.py", line 118, in run
    return self._loop.run_until_complete(task)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/asyncio/base_events.py", line 687, in run_until_complete
    return future.result()
           ^^^^^^^^^^^^^^^
  File "/app/openhands/server/session/agent_session.py", line 105, in _start
    await self._create_runtime(
  File "/app/openhands/server/session/agent_session.py", line 189, in _create_runtime
    await self.runtime.connect()
  File "/app/openhands/runtime/impl/eventstream/eventstream_runtime.py", line 217, in connect
    self._wait_until_alive()
  File "/app/.venv/lib/python3.12/site-packages/tenacity/__init__.py", line 336, in wrapped_f
    return copy(f, *args, **kw)
           ^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/tenacity/__init__.py", line 475, in __call__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/tenacity/__init__.py", line 418, in exc_check
    raise retry_exc.reraise()
          ^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/tenacity/__init__.py", line 185, in reraise
    raise self.last_attempt.result()
          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/app/.venv/lib/python3.12/site-packages/tenacity/__init__.py", line 478, in __call__
    result = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/app/openhands/runtime/impl/eventstream/eventstream_runtime.py", line 395, in _wait_until_alive
    response = send_request_with_retry(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/openhands/runtime/utils/request.py", line 96, in send_request_with_retry
    return _send_request_with_retry()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/tenacity/__init__.py", line 336, in wrapped_f
    return copy(f, *args, **kw)
           ^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/tenacity/__init__.py", line 475, in __call__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/app/.venv/lib/python3.12/site-packages/tenacity/__init__.py", line 478, in __call__
    result = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/app/openhands/runtime/utils/request.py", line 92, in _send_request_with_retry
    response = session.request(method, url, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/requests/adapters.py", line 700, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='host.docker.internal', port=33243): Max retries exceeded with url: /alive (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f9721780e00>: Failed to establish a new connection: [Errno 101] Network is unreachable'))

Give Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new
LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.


Provider List: https://docs.litellm.ai/docs/providers

21:55:10 - openhands:ERROR: retry_mixin.py:47 - litellm.ServiceUnavailableError: OllamaException: HTTPConnectionPool(host='127.0.0.1', port=11434): Max retries exceeded with url: /api/generate (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f97217872c0>: Failed to establish a new connection: [Errno 111] Connection refused')). Attempt #6 | You can customize retry values in the configuration.

Give Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new
LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.


Provider List: https://docs.litellm.ai/docs/providers

Traceback (most recent call last):
  File "/app/.venv/lib/python3.12/site-packages/urllib3/connection.py", line 199, in _new_conn
    sock = connection.create_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/urllib3/util/connection.py", line 85, in create_connection
    raise err
  File "/app/.venv/lib/python3.12/site-packages/urllib3/util/connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/app/.venv/lib/python3.12/site-packages/urllib3/connectionpool.py", line 789, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/urllib3/connectionpool.py", line 495, in _make_request
    conn.request(
  File "/app/.venv/lib/python3.12/site-packages/urllib3/connection.py", line 441, in request
    self.endheaders()
  File "/usr/local/lib/python3.12/http/client.py", line 1331, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/usr/local/lib/python3.12/http/client.py", line 1091, in _send_output
    self.send(msg)
  File "/usr/local/lib/python3.12/http/client.py", line 1035, in send
    self.connect()
  File "/app/.venv/lib/python3.12/site-packages/urllib3/connection.py", line 279, in connect
    self.sock = self._new_conn()
                ^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/urllib3/connection.py", line 214, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7f9721781760>: Failed to establish a new connection: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/app/.venv/lib/python3.12/site-packages/requests/adapters.py", line 667, in send
    resp = conn.urlopen(
           ^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/urllib3/connectionpool.py", line 843, in urlopen
    retries = retries.increment(
              ^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/urllib3/util/retry.py", line 519, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=11434): Max retries exceeded with url: /v1/api/generate (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f9721781760>: Failed to establish a new connection: [Errno 111] Connection refused'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/app/.venv/lib/python3.12/site-packages/litellm/main.py", line 2709, in completion
    generator = ollama.get_ollama_response(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/litellm/llms/ollama.py", line 316, in get_ollama_response
    response = requests.post(
               ^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/requests/api.py", line 115, in post
    return request("post", url, data=data, json=json, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/requests/api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/requests/adapters.py", line 700, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=11434): Max retries exceeded with url: /v1/api/generate (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f9721781760>: Failed to establish a new connection: [Errno 111] Connection refused'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/app/openhands/controller/agent_controller.py", line 168, in start_step_loop
    await self._step()
  File "/app/openhands/controller/agent_controller.py", line 464, in _step
    action = self.agent.step(self.state)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/openhands/agenthub/codeact_agent/codeact_agent.py", line 359, in step
    response = self.llm.completion(**params)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/tenacity/__init__.py", line 336, in wrapped_f
    return copy(f, *args, **kw)
           ^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/tenacity/__init__.py", line 475, in __call__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/tenacity/__init__.py", line 418, in exc_check
    raise retry_exc.reraise()
          ^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/tenacity/__init__.py", line 185, in reraise
    raise self.last_attempt.result()
          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/app/.venv/lib/python3.12/site-packages/tenacity/__init__.py", line 478, in __call__
    result = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/app/openhands/llm/llm.py", line 196, in wrapper
    resp: ModelResponse = completion_unwrapped(*args, **kwargs)
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/litellm/utils.py", line 1013, in wrapper
    raise e
  File "/app/.venv/lib/python3.12/site-packages/litellm/utils.py", line 903, in wrapper
    result = original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/litellm/main.py", line 2999, in completion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2116, in exception_type
    raise e
  File "/app/.venv/lib/python3.12/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1785, in exception_type
    raise ServiceUnavailableError(
litellm.exceptions.ServiceUnavailableError: litellm.ServiceUnavailableError: OllamaException: HTTPConnectionPool(host='127.0.0.1', port=11434): Max retries exceeded with url: /v1/api/generate (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f9721781760>: Failed to establish a new connection: [Errno 111] Connection refused'))
21:56:02 - openhands:ERROR: agent_controller.py:135 - [Agent Controller c08adb0a-d9b2-4563-866f-0140cc503d3e] Error while running the agent: litellm.ServiceUnavailableError: OllamaException: HTTPConnectionPool(host='127.0.0.1', port=11434): Max retries exceeded with url: /v1/api/generate (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f9721781760>: Failed to establish a new connection: [Errno 111] Connection refused'))
21:56:02 - openhands:ERROR: agent_controller.py:135 - [Agent Controller c08adb0a-d9b2-4563-866f-0140cc503d3e] Traceback (most recent call last):
  File "/app/.venv/lib/python3.12/site-packages/urllib3/connection.py", line 199, in _new_conn
    sock = connection.create_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/urllib3/util/connection.py", line 85, in create_connection
    raise err
  File "/app/.venv/lib/python3.12/site-packages/urllib3/util/connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/app/.venv/lib/python3.12/site-packages/urllib3/connectionpool.py", line 789, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/urllib3/connectionpool.py", line 495, in _make_request
    conn.request(
  File "/app/.venv/lib/python3.12/site-packages/urllib3/connection.py", line 441, in request
    self.endheaders()
  File "/usr/local/lib/python3.12/http/client.py", line 1331, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/usr/local/lib/python3.12/http/client.py", line 1091, in _send_output
    self.send(msg)
  File "/usr/local/lib/python3.12/http/client.py", line 1035, in send
    self.connect()
  File "/app/.venv/lib/python3.12/site-packages/urllib3/connection.py", line 279, in connect
    self.sock = self._new_conn()
                ^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/urllib3/connection.py", line 214, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7f9721781760>: Failed to establish a new connection: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/app/.venv/lib/python3.12/site-packages/requests/adapters.py", line 667, in send
    resp = conn.urlopen(
           ^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/urllib3/connectionpool.py", line 843, in urlopen
    retries = retries.increment(
              ^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/urllib3/util/retry.py", line 519, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=11434): Max retries exceeded with url: /v1/api/generate (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f9721781760>: Failed to establish a new connection: [Errno 111] Connection refused'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/app/.venv/lib/python3.12/site-packages/litellm/main.py", line 2709, in completion
    generator = ollama.get_ollama_response(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/litellm/llms/ollama.py", line 316, in get_ollama_response
    response = requests.post(
               ^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/requests/api.py", line 115, in post
    return request("post", url, data=data, json=json, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/requests/api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/requests/adapters.py", line 700, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=11434): Max retries exceeded with url: /v1/api/generate (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f9721781760>: Failed to establish a new connection: [Errno 111] Connection refused'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/app/openhands/controller/agent_controller.py", line 168, in start_step_loop
    await self._step()
  File "/app/openhands/controller/agent_controller.py", line 464, in _step
    action = self.agent.step(self.state)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/openhands/agenthub/codeact_agent/codeact_agent.py", line 359, in step
    response = self.llm.completion(**params)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/tenacity/__init__.py", line 336, in wrapped_f
    return copy(f, *args, **kw)
           ^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/tenacity/__init__.py", line 475, in __call__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/tenacity/__init__.py", line 418, in exc_check
    raise retry_exc.reraise()
          ^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/tenacity/__init__.py", line 185, in reraise
    raise self.last_attempt.result()
          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/app/.venv/lib/python3.12/site-packages/tenacity/__init__.py", line 478, in __call__
    result = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/app/openhands/llm/llm.py", line 196, in wrapper
    resp: ModelResponse = completion_unwrapped(*args, **kwargs)
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/litellm/utils.py", line 1013, in wrapper
    raise e
  File "/app/.venv/lib/python3.12/site-packages/litellm/utils.py", line 903, in wrapper
    result = original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/litellm/main.py", line 2999, in completion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2116, in exception_type
    raise e
  File "/app/.venv/lib/python3.12/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1785, in exception_type
    raise ServiceUnavailableError(
litellm.exceptions.ServiceUnavailableError: litellm.ServiceUnavailableError: OllamaException: HTTPConnectionPool(host='127.0.0.1', port=11434): Max retries exceeded with url: /v1/api/generate (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f9721781760>: Failed to establish a new connection: [Errno 111] Connection refused'))

21:56:02 - openhands:INFO: agent_controller.py:135 - [Agent Controller c08adb0a-d9b2-4563-866f-0140cc503d3e] Setting agent(CodeActAgent) state from AgentState.RUNNING to AgentState.ERROR

Give Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new
LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.


Provider List: https://docs.litellm.ai/docs/providers

21:56:17 - openhands:ERROR: retry_mixin.py:47 - litellm.ServiceUnavailableError: OllamaException: HTTPConnectionPool(host='127.0.0.1', port=11434): Max retries exceeded with url: /api/generate (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f9721787320>: Failed to establish a new connection: [Errno 111] Connection refused')). Attempt #7 | You can customize retry values in the configuration.
^CINFO:     Shutting down
21:57:58 - openhands:INFO: session.py:66 - WebSocket disconnected, sid: 7efbf261-c0d5-4ed3-82ae-144e1c9bea1b
INFO:     connection closed
INFO:     Waiting for application shutdown.
INFO:     Application shutdown complete.
INFO:     Finished server process [10]

Give Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new
LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.


Provider List: https://docs.litellm.ai/docs/providers

Traceback (most recent call last):
  File "/app/.venv/lib/python3.12/site-packages/urllib3/connection.py", line 199, in _new_conn
    sock = connection.create_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/urllib3/util/connection.py", line 85, in create_connection
    raise err
  File "/app/.venv/lib/python3.12/site-packages/urllib3/util/connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/app/.venv/lib/python3.12/site-packages/urllib3/connectionpool.py", line 789, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/urllib3/connectionpool.py", line 495, in _make_request
    conn.request(
  File "/app/.venv/lib/python3.12/site-packages/urllib3/connection.py", line 441, in request
    self.endheaders()
  File "/usr/local/lib/python3.12/http/client.py", line 1331, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/usr/local/lib/python3.12/http/client.py", line 1091, in _send_output
    self.send(msg)
  File "/usr/local/lib/python3.12/http/client.py", line 1035, in send
    self.connect()
  File "/app/.venv/lib/python3.12/site-packages/urllib3/connection.py", line 279, in connect
    self.sock = self._new_conn()
                ^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/urllib3/connection.py", line 214, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7f97324b7170>: Failed to establish a new connection: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/app/.venv/lib/python3.12/site-packages/requests/adapters.py", line 667, in send
    resp = conn.urlopen(
           ^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/urllib3/connectionpool.py", line 843, in urlopen
    retries = retries.increment(
              ^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/urllib3/util/retry.py", line 519, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=11434): Max retries exceeded with url: /api/generate (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f97324b7170>: Failed to establish a new connection: [Errno 111] Connection refused'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/app/.venv/lib/python3.12/site-packages/litellm/main.py", line 2709, in completion
    generator = ollama.get_ollama_response(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/litellm/llms/ollama.py", line 316, in get_ollama_response
    response = requests.post(
               ^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/requests/api.py", line 115, in post
    return request("post", url, data=data, json=json, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/requests/api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/requests/adapters.py", line 700, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=11434): Max retries exceeded with url: /api/generate (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f97324b7170>: Failed to establish a new connection: [Errno 111] Connection refused'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/app/openhands/controller/agent_controller.py", line 168, in start_step_loop
    await self._step()
  File "/app/openhands/controller/agent_controller.py", line 464, in _step
    action = self.agent.step(self.state)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/openhands/agenthub/codeact_agent/codeact_agent.py", line 359, in step
    response = self.llm.completion(**params)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/tenacity/__init__.py", line 336, in wrapped_f
    return copy(f, *args, **kw)
           ^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/tenacity/__init__.py", line 475, in __call__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/tenacity/__init__.py", line 418, in exc_check
    raise retry_exc.reraise()
          ^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/tenacity/__init__.py", line 185, in reraise
    raise self.last_attempt.result()
          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/app/.venv/lib/python3.12/site-packages/tenacity/__init__.py", line 478, in __call__
    result = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/app/openhands/llm/llm.py", line 196, in wrapper
    resp: ModelResponse = completion_unwrapped(*args, **kwargs)
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/litellm/utils.py", line 1013, in wrapper
    raise e
  File "/app/.venv/lib/python3.12/site-packages/litellm/utils.py", line 903, in wrapper
    result = original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/litellm/main.py", line 2999, in completion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2116, in exception_type
    raise e
  File "/app/.venv/lib/python3.12/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1785, in exception_type
    raise ServiceUnavailableError(
litellm.exceptions.ServiceUnavailableError: litellm.ServiceUnavailableError: OllamaException: HTTPConnectionPool(host='127.0.0.1', port=11434): Max retries exceeded with url: /api/generate (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f97324b7170>: Failed to establish a new connection: [Errno 111] Connection refused'))
21:58:24 - openhands:ERROR: agent_controller.py:135 - [Agent Controller 7efbf261-c0d5-4ed3-82ae-144e1c9bea1b] Error while running the agent: litellm.ServiceUnavailableError: OllamaException: HTTPConnectionPool(host='127.0.0.1', port=11434): Max retries exceeded with url: /api/generate (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f97324b7170>: Failed to establish a new connection: [Errno 111] Connection refused'))
21:58:24 - openhands:ERROR: agent_controller.py:135 - [Agent Controller 7efbf261-c0d5-4ed3-82ae-144e1c9bea1b] Traceback (most recent call last):
  File "/app/.venv/lib/python3.12/site-packages/urllib3/connection.py", line 199, in _new_conn
    sock = connection.create_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/urllib3/util/connection.py", line 85, in create_connection
    raise err
  File "/app/.venv/lib/python3.12/site-packages/urllib3/util/connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/app/.venv/lib/python3.12/site-packages/urllib3/connectionpool.py", line 789, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/urllib3/connectionpool.py", line 495, in _make_request
    conn.request(
  File "/app/.venv/lib/python3.12/site-packages/urllib3/connection.py", line 441, in request
    self.endheaders()
  File "/usr/local/lib/python3.12/http/client.py", line 1331, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/usr/local/lib/python3.12/http/client.py", line 1091, in _send_output
    self.send(msg)
  File "/usr/local/lib/python3.12/http/client.py", line 1035, in send
    self.connect()
  File "/app/.venv/lib/python3.12/site-packages/urllib3/connection.py", line 279, in connect
    self.sock = self._new_conn()
                ^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/urllib3/connection.py", line 214, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7f97324b7170>: Failed to establish a new connection: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/app/.venv/lib/python3.12/site-packages/requests/adapters.py", line 667, in send
    resp = conn.urlopen(
           ^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/urllib3/connectionpool.py", line 843, in urlopen
    retries = retries.increment(
              ^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/urllib3/util/retry.py", line 519, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=11434): Max retries exceeded with url: /api/generate (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f97324b7170>: Failed to establish a new connection: [Errno 111] Connection refused'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/app/.venv/lib/python3.12/site-packages/litellm/main.py", line 2709, in completion
    generator = ollama.get_ollama_response(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/litellm/llms/ollama.py", line 316, in get_ollama_response
    response = requests.post(
               ^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/requests/api.py", line 115, in post
    return request("post", url, data=data, json=json, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/requests/api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/requests/adapters.py", line 700, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=11434): Max retries exceeded with url: /api/generate (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f97324b7170>: Failed to establish a new connection: [Errno 111] Connection refused'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/app/openhands/controller/agent_controller.py", line 168, in start_step_loop
    await self._step()
  File "/app/openhands/controller/agent_controller.py", line 464, in _step
    action = self.agent.step(self.state)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/openhands/agenthub/codeact_agent/codeact_agent.py", line 359, in step
    response = self.llm.completion(**params)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/tenacity/__init__.py", line 336, in wrapped_f
    return copy(f, *args, **kw)
           ^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/tenacity/__init__.py", line 475, in __call__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/tenacity/__init__.py", line 418, in exc_check
    raise retry_exc.reraise()
          ^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/tenacity/__init__.py", line 185, in reraise
    raise self.last_attempt.result()
          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/app/.venv/lib/python3.12/site-packages/tenacity/__init__.py", line 478, in __call__
    result = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/app/openhands/llm/llm.py", line 196, in wrapper
    resp: ModelResponse = completion_unwrapped(*args, **kwargs)
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/litellm/utils.py", line 1013, in wrapper
    raise e
  File "/app/.venv/lib/python3.12/site-packages/litellm/utils.py", line 903, in wrapper
    result = original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/litellm/main.py", line 2999, in completion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2116, in exception_type
    raise e
  File "/app/.venv/lib/python3.12/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1785, in exception_type
    raise ServiceUnavailableError(
litellm.exceptions.ServiceUnavailableError: litellm.ServiceUnavailableError: OllamaException: HTTPConnectionPool(host='127.0.0.1', port=11434): Max retries exceeded with url: /api/generate (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f97324b7170>: Failed to establish a new connection: [Errno 111] Connection refused'))

21:58:24 - openhands:INFO: agent_controller.py:135 - [Agent Controller 7efbf261-c0d5-4ed3-82ae-144e1c9bea1b] Setting agent(CodeActAgent) state from AgentState.RUNNING to AgentState.ERROR
m@DESKTOP-MUB16F8:~$ docker run -it --privileged --rm \
LLM_API>   -e LLM_API_KEY="ollama" \
>   -e OLLAMA_HOST="http://172.21.151.42:11434" \
>   -e LLM_OLLAMA_BASE_URL="http://172.21.151.42:11434" \
>   -e OLLAMA_BASE_URL="http://172.21.151.42:11434" \
>   -e OLLAMA_URL="http://172.21.151.42:11434" \
>   -e SANDBOX_RUNTIME_CONTAINER_IMAGE="docker.all-hands.dev/all-hands-ai/runtime:0.12-nikolaik" \
>   -v /var/run/docker.sock:/var/run/docker.sock \
>   -p 3000:3000 \
>   --name openhands-app \
>   docker.all-hands.dev/all-hands-ai/openhands:0.12
Starting OpenHands...
Running OpenHands as root
INFO:     Started server process [10]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:3000 (Press CTRL+C to quit)
INFO:     172.17.0.1:48974 - "GET / HTTP/1.1" 200 OK
INFO:     172.17.0.1:48974 - "GET /locales/en/translation.json HTTP/1.1" 200 OK
INFO:     172.17.0.1:48974 - "GET /config.json HTTP/1.1" 200 OK
INFO:     172.17.0.1:48984 - "GET /config.json HTTP/1.1" 200 OK
INFO:     172.17.0.1:48984 - "GET /config.json HTTP/1.1" 200 OK
21:59:35 - openhands:INFO: github.py:14 - Initializing UserVerifier
21:59:35 - openhands:INFO: github.py:27 - GITHUB_USER_LIST_FILE not configured
21:59:35 - openhands:INFO: github.py:48 - GITHUB_USERS_SHEET_ID not configured
21:59:35 - openhands:INFO: github.py:85 - No user verification sources configured - allowing all users
INFO:     ('172.17.0.1', 48990) - "WebSocket /ws" [accepted]
21:59:35 - openhands:ERROR: auth.py:27 - Invalid token
INFO:     connection open
INFO:     172.17.0.1:48984 - "GET /api/options/models HTTP/1.1" 200 OK
INFO:     172.17.0.1:48974 - "GET /api/options/agents HTTP/1.1" 200 OK
INFO:     172.17.0.1:49004 - "GET /api/options/security-analyzers HTTP/1.1" 200 OK
INFO:     connection closed
INFO:     172.17.0.1:49004 - "GET /config.json HTTP/1.1" 200 OK
INFO:     172.17.0.1:48974 - "GET /config.json HTTP/1.1" 200 OK
INFO:     172.17.0.1:49010 - "GET /config.json HTTP/1.1" 200 OK
INFO:     172.17.0.1:49012 - "GET /config.json HTTP/1.1" 200 OK
INFO:     172.17.0.1:49012 - "GET /config.json HTTP/1.1" 200 OK
INFO:     172.17.0.1:49010 - "GET /config.json HTTP/1.1" 200 OK
INFO:     172.17.0.1:49010 - "GET /config.json HTTP/1.1" 200 OK
21:59:46 - openhands:INFO: github.py:14 - Initializing UserVerifier
21:59:46 - openhands:INFO: github.py:27 - GITHUB_USER_LIST_FILE not configured
21:59:46 - openhands:INFO: github.py:48 - GITHUB_USERS_SHEET_ID not configured
21:59:46 - openhands:INFO: github.py:85 - No user verification sources configured - allowing all users
INFO:     ('172.17.0.1', 54666) - "WebSocket /ws" [accepted]
21:59:46 - openhands:INFO: listen.py:336 - New session: 5bd2485c-984e-4453-b636-3de44ced3087
INFO:     connection open
21:59:46 - openhands:WARNING: codeact_agent.py:101 - Function calling not supported for model ollama/llama3:latest. Disabling function calling.
INFO:     172.17.0.1:49010 - "GET /config.json HTTP/1.1" 200 OK
21:59:46 - openhands:INFO: base.py:98 - [runtime 5bd2485c-984e-4453-b636-3de44ced3087] Starting runtime with image: docker.all-hands.dev/all-hands-ai/runtime:0.12-nikolaik
21:59:47 - openhands:INFO: base.py:98 - [runtime 5bd2485c-984e-4453-b636-3de44ced3087] Container started: openhands-runtime-5bd2485c-984e-4453-b636-3de44ced3087
21:59:47 - openhands:INFO: base.py:98 - [runtime 5bd2485c-984e-4453-b636-3de44ced3087] Waiting for client to become ready at http://host.docker.internal:37702...
22:00:19 - openhands:INFO: base.py:98 - [runtime 5bd2485c-984e-4453-b636-3de44ced3087] Runtime is ready.
22:00:19 - openhands:WARNING: state.py:118 - Failed to restore state from session: sessions/5bd2485c-984e-4453-b636-3de44ced3087/agent_state.pkl
22:00:19 - openhands:INFO: agent_controller.py:135 - [Agent Controller 5bd2485c-984e-4453-b636-3de44ced3087] Starting step loop...
22:00:19 - openhands:INFO: agent_controller.py:135 - [Agent Controller 5bd2485c-984e-4453-b636-3de44ced3087] Setting agent(CodeActAgent) state from AgentState.LOADING to AgentState.INIT
22:00:19 - openhands:INFO: agent_controller.py:135 - [Agent Controller 5bd2485c-984e-4453-b636-3de44ced3087] Setting agent(CodeActAgent) state from AgentState.INIT to AgentState.RUNNING
22:00:19 - openhands:INFO: github.py:14 - Initializing UserVerifier
22:00:19 - openhands:INFO: github.py:27 - GITHUB_USER_LIST_FILE not configured
22:00:19 - openhands:INFO: github.py:48 - GITHUB_USERS_SHEET_ID not configured
22:00:19 - openhands:INFO: github.py:85 - No user verification sources configured - allowing all users
INFO:     172.17.0.1:37572 - "GET /config.json HTTP/1.1" 200 OK
INFO:     172.17.0.1:37584 - "GET /config.json HTTP/1.1" 200 OK
INFO:     172.17.0.1:37562 - "GET /api/list-files HTTP/1.1" 200 OK
22:00:19 - openhands:INFO: github.py:14 - Initializing UserVerifier
22:00:19 - openhands:INFO: github.py:27 - GITHUB_USER_LIST_FILE not configured
22:00:19 - openhands:INFO: github.py:48 - GITHUB_USERS_SHEET_ID not configured
22:00:19 - openhands:INFO: github.py:85 - No user verification sources configured - allowing all users
INFO:     172.17.0.1:37584 - "GET /api/list-files HTTP/1.1" 200 OK
22:00:20 - openhands:INFO: github.py:14 - Initializing UserVerifier
22:00:20 - openhands:INFO: github.py:27 - GITHUB_USER_LIST_FILE not configured
22:00:20 - openhands:INFO: github.py:48 - GITHUB_USERS_SHEET_ID not configured
22:00:20 - openhands:INFO: github.py:85 - No user verification sources configured - allowing all users
INFO:     172.17.0.1:37562 - "GET /api/list-files HTTP/1.1" 200 OK


==============
[Agent Controller 5bd2485c-984e-4453-b636-3de44ced3087] LEVEL 0 LOCAL STEP 0 GLOBAL STEP 0


Provider List: https://docs.litellm.ai/docs/providers


Provider List: https://docs.litellm.ai/docs/providers


Give Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new
LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.


Provider List: https://docs.litellm.ai/docs/providers

22:00:20 - openhands:ERROR: retry_mixin.py:47 - litellm.ServiceUnavailableError: OllamaException: HTTPConnectionPool(host='127.0.0.1', port=11434): Max retries exceeded with url: /api/generate (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fa1b7683ec0>: Failed to establish a new connection: [Errno 111] Connection refused')). Attempt #1 | You can customize retry values in the configuration.

Give Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new
LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.


Provider List: https://docs.litellm.ai/docs/providers

22:00:35 - openhands:ERROR: retry_mixin.py:47 - litellm.ServiceUnavailableError: OllamaException: HTTPConnectionPool(host='127.0.0.1', port=11434): Max retries exceeded with url: /api/generate (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fa1b7675ca0>: Failed to establish a new connection: [Errno 111] Connection refused')). Attempt #2 | You can customize retry values in the configuration.

Give Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new
LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.


Provider List: https://docs.litellm.ai/docs/providers

22:00:52 - openhands:ERROR: retry_mixin.py:47 - litellm.ServiceUnavailableError: OllamaException: HTTPConnectionPool(host='127.0.0.1', port=11434): Max retries exceeded with url: /api/generate (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fa1b750bf50>: Failed to establish a new connection: [Errno 111] Connection refused')). Attempt #3 | You can customize retry values in the configuration.

Give Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new
LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.


Provider List: https://docs.litellm.ai/docs/providers

22:01:07 - openhands:ERROR: retry_mixin.py:47 - litellm.ServiceUnavailableError: OllamaException: HTTPConnectionPool(host='127.0.0.1', port=11434): Max retries exceeded with url: /api/generate (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fa1b75216d0>: Failed to establish a new connection: [Errno 111] Connection refused')). Attempt #4 | You can customize retry values in the configuration.

Give Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new
LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.


Provider List: https://docs.litellm.ai/docs/providers

22:01:25 - openhands:ERROR: retry_mixin.py:47 - litellm.ServiceUnavailableError: OllamaException: HTTPConnectionPool(host='127.0.0.1', port=11434): Max retries exceeded with url: /api/generate (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fa1b750b7a0>: Failed to establish a new connection: [Errno 111] Connection refused')). Attempt #5 | You can customize retry values in the configuration.

Give Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new
LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.


Provider List: https://docs.litellm.ai/docs/providers

22:01:59 - openhands:ERROR: retry_mixin.py:47 - litellm.ServiceUnavailableError: OllamaException: HTTPConnectionPool(host='127.0.0.1', port=11434): Max retries exceeded with url: /api/generate (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fa1b75208c0>: Failed to establish a new connection: [Errno 111] Connection refused')). Attempt #6 | You can customize retry values in the configuration.
22:02:37 - openhands:INFO: agent_controller.py:135 - [Agent Controller 5bd2485c-984e-4453-b636-3de44ced3087] Setting agent(CodeActAgent) state from AgentState.RUNNING to paused
22:02:37 - openhands:INFO: github.py:14 - Initializing UserVerifier
22:02:37 - openhands:INFO: github.py:27 - GITHUB_USER_LIST_FILE not configured
22:02:37 - openhands:INFO: github.py:48 - GITHUB_USERS_SHEET_ID not configured
22:02:37 - openhands:INFO: github.py:85 - No user verification sources configured - allowing all users
INFO:     172.17.0.1:47052 - "GET /config.json HTTP/1.1" 200 OK
INFO:     172.17.0.1:47038 - "GET /api/list-files HTTP/1.1" 200 OK
22:02:38 - openhands:INFO: agent_controller.py:135 - [Agent Controller 5bd2485c-984e-4453-b636-3de44ced3087] Setting agent(CodeActAgent) state from paused to running
22:02:38 - openhands:INFO: github.py:14 - Initializing UserVerifier
22:02:38 - openhands:INFO: github.py:27 - GITHUB_USER_LIST_FILE not configured
22:02:38 - openhands:INFO: github.py:48 - GITHUB_USERS_SHEET_ID not configured
22:02:38 - openhands:INFO: github.py:85 - No user verification sources configured - allowing all users
INFO:     172.17.0.1:47052 - "GET /config.json HTTP/1.1" 200 OK
INFO:     172.17.0.1:47038 - "GET /api/list-files HTTP/1.1" 200 OK

Give Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new
LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.


Provider List: https://docs.litellm.ai/docs/providers

22:03:06 - openhands:ERROR: retry_mixin.py:47 - litellm.ServiceUnavailableError: OllamaException: HTTPConnectionPool(host='127.0.0.1', port=11434): Max retries exceeded with url: /api/generate (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fa1b7532ea0>: Failed to establish a new connection: [Errno 111] Connection refused')). Attempt #7 | You can customize retry values in the configuration.

Give Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new
LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.


Provider List: https://docs.litellm.ai/docs/providers

Traceback (most recent call last):
  File "/app/.venv/lib/python3.12/site-packages/urllib3/connection.py", line 199, in _new_conn
    sock = connection.create_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/urllib3/util/connection.py", line 85, in create_connection
    raise err
  File "/app/.venv/lib/python3.12/site-packages/urllib3/util/connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/app/.venv/lib/python3.12/site-packages/urllib3/connectionpool.py", line 789, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/urllib3/connectionpool.py", line 495, in _make_request
    conn.request(
  File "/app/.venv/lib/python3.12/site-packages/urllib3/connection.py", line 441, in request
    self.endheaders()
  File "/usr/local/lib/python3.12/http/client.py", line 1331, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/usr/local/lib/python3.12/http/client.py", line 1091, in _send_output
    self.send(msg)
  File "/usr/local/lib/python3.12/http/client.py", line 1035, in send
    self.connect()
  File "/app/.venv/lib/python3.12/site-packages/urllib3/connection.py", line 279, in connect
    self.sock = self._new_conn()
                ^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/urllib3/connection.py", line 214, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7fa1b76411c0>: Failed to establish a new connection: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/app/.venv/lib/python3.12/site-packages/requests/adapters.py", line 667, in send
    resp = conn.urlopen(
           ^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/urllib3/connectionpool.py", line 843, in urlopen
    retries = retries.increment(
              ^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/urllib3/util/retry.py", line 519, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=11434): Max retries exceeded with url: /api/generate (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fa1b76411c0>: Failed to establish a new connection: [Errno 111] Connection refused'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/app/.venv/lib/python3.12/site-packages/litellm/main.py", line 2709, in completion
    generator = ollama.get_ollama_response(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/litellm/llms/ollama.py", line 316, in get_ollama_response
    response = requests.post(
               ^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/requests/api.py", line 115, in post
    return request("post", url, data=data, json=json, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/requests/api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/requests/adapters.py", line 700, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=11434): Max retries exceeded with url: /api/generate (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fa1b76411c0>: Failed to establish a new connection: [Errno 111] Connection refused'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/app/openhands/controller/agent_controller.py", line 168, in start_step_loop
    await self._step()
  File "/app/openhands/controller/agent_controller.py", line 464, in _step
    action = self.agent.step(self.state)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/openhands/agenthub/codeact_agent/codeact_agent.py", line 359, in step
    response = self.llm.completion(**params)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/tenacity/__init__.py", line 336, in wrapped_f
    return copy(f, *args, **kw)
           ^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/tenacity/__init__.py", line 475, in __call__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/tenacity/__init__.py", line 418, in exc_check
    raise retry_exc.reraise()
          ^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/tenacity/__init__.py", line 185, in reraise
    raise self.last_attempt.result()
          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/app/.venv/lib/python3.12/site-packages/tenacity/__init__.py", line 478, in __call__
    result = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/app/openhands/llm/llm.py", line 196, in wrapper
    resp: ModelResponse = completion_unwrapped(*args, **kwargs)
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/litellm/utils.py", line 1013, in wrapper
    raise e
  File "/app/.venv/lib/python3.12/site-packages/litellm/utils.py", line 903, in wrapper
    result = original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/litellm/main.py", line 2999, in completion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2116, in exception_type
    raise e
  File "/app/.venv/lib/python3.12/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1785, in exception_type
    raise ServiceUnavailableError(
litellm.exceptions.ServiceUnavailableError: litellm.ServiceUnavailableError: OllamaException: HTTPConnectionPool(host='127.0.0.1', port=11434): Max retries exceeded with url: /api/generate (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fa1b76411c0>: Failed to establish a new connection: [Errno 111] Connection refused'))
22:05:14 - openhands:ERROR: agent_controller.py:135 - [Agent Controller 5bd2485c-984e-4453-b636-3de44ced3087] Error while running the agent: litellm.ServiceUnavailableError: OllamaException: HTTPConnectionPool(host='127.0.0.1', port=11434): Max retries exceeded with url: /api/generate (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fa1b76411c0>: Failed to establish a new connection: [Errno 111] Connection refused'))
22:05:14 - openhands:ERROR: agent_controller.py:135 - [Agent Controller 5bd2485c-984e-4453-b636-3de44ced3087] Traceback (most recent call last):
  File "/app/.venv/lib/python3.12/site-packages/urllib3/connection.py", line 199, in _new_conn
    sock = connection.create_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/urllib3/util/connection.py", line 85, in create_connection
    raise err
  File "/app/.venv/lib/python3.12/site-packages/urllib3/util/connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/app/.venv/lib/python3.12/site-packages/urllib3/connectionpool.py", line 789, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/urllib3/connectionpool.py", line 495, in _make_request
    conn.request(
  File "/app/.venv/lib/python3.12/site-packages/urllib3/connection.py", line 441, in request
    self.endheaders()
  File "/usr/local/lib/python3.12/http/client.py", line 1331, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/usr/local/lib/python3.12/http/client.py", line 1091, in _send_output
    self.send(msg)
  File "/usr/local/lib/python3.12/http/client.py", line 1035, in send
    self.connect()
  File "/app/.venv/lib/python3.12/site-packages/urllib3/connection.py", line 279, in connect
    self.sock = self._new_conn()
                ^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/urllib3/connection.py", line 214, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7fa1b76411c0>: Failed to establish a new connection: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/app/.venv/lib/python3.12/site-packages/requests/adapters.py", line 667, in send
    resp = conn.urlopen(
           ^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/urllib3/connectionpool.py", line 843, in urlopen
    retries = retries.increment(
              ^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/urllib3/util/retry.py", line 519, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=11434): Max retries exceeded with url: /api/generate (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fa1b76411c0>: Failed to establish a new connection: [Errno 111] Connection refused'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/app/.venv/lib/python3.12/site-packages/litellm/main.py", line 2709, in completion
    generator = ollama.get_ollama_response(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/litellm/llms/ollama.py", line 316, in get_ollama_response
    response = requests.post(
               ^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/requests/api.py", line 115, in post
    return request("post", url, data=data, json=json, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/requests/api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/requests/adapters.py", line 700, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=11434): Max retries exceeded with url: /api/generate (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fa1b76411c0>: Failed to establish a new connection: [Errno 111] Connection refused'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/app/openhands/controller/agent_controller.py", line 168, in start_step_loop
    await self._step()
  File "/app/openhands/controller/agent_controller.py", line 464, in _step
    action = self.agent.step(self.state)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/openhands/agenthub/codeact_agent/codeact_agent.py", line 359, in step
    response = self.llm.completion(**params)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/tenacity/__init__.py", line 336, in wrapped_f
    return copy(f, *args, **kw)
           ^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/tenacity/__init__.py", line 475, in __call__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/tenacity/__init__.py", line 418, in exc_check
    raise retry_exc.reraise()
          ^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/tenacity/__init__.py", line 185, in reraise
    raise self.last_attempt.result()
          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/app/.venv/lib/python3.12/site-packages/tenacity/__init__.py", line 478, in __call__
    result = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/app/openhands/llm/llm.py", line 196, in wrapper
    resp: ModelResponse = completion_unwrapped(*args, **kwargs)
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/litellm/utils.py", line 1013, in wrapper
    raise e
  File "/app/.venv/lib/python3.12/site-packages/litellm/utils.py", line 903, in wrapper
    result = original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/litellm/main.py", line 2999, in completion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "/app/.venv/lib/python3.12/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 2116, in exception_type
    raise e
  File "/app/.venv/lib/python3.12/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py", line 1785, in exception_type
    raise ServiceUnavailableError(
litellm.exceptions.ServiceUnavailableError: litellm.ServiceUnavailableError: OllamaException: HTTPConnectionPool(host='127.0.0.1', port=11434): Max retries exceeded with url: /api/generate (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fa1b76411c0>: Failed to establish a new connection: [Errno 111] Connection refused'))

22:05:14 - openhands:INFO: agent_controller.py:135 - [Agent Controller 5bd2485c-984e-4453-b636-3de44ced3087] Setting agent(CodeActAgent) state from running to AgentState.ERROR
^CINFO:     Shutting down
22:06:55 - openhands:INFO: session.py:66 - WebSocket disconnected, sid: 5bd2485c-984e-4453-b636-3de44ced3087
INFO:     connection closed
INFO:     Waiting for application shutdown.
INFO:     Application shutdown complete.
INFO:     Finished server process [10]
^CException ignored in atexit callback: <bound method EventStreamRuntime.close of <openhands.runtime.impl.eventstream.eventstream_runtime.EventStreamRuntime object at 0x7fa1b75237d0>>
Traceback (most recent call last):
  File "/app/openhands/runtime/impl/eventstream/eventstream_runtime.py", line 417, in close
    self.log_buffer.close()
  File "/app/openhands/runtime/impl/eventstream/eventstream_runtime.py", line 100, in close
    self.log_stream_thread.join(timeout)
  File "/usr/local/lib/python3.12/threading.py", line 1151, in join
    self._wait_for_tstate_lock(timeout=max(timeout, 0))
  File "/usr/local/lib/python3.12/threading.py", line 1167, in _wait_for_tstate_lock
    if lock.acquire(block, timeout):
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt:
^CException ignored in atexit callback: <bound method EventStreamRuntime.close of <openhands.runtime.impl.eventstream.eventstream_runtime.EventStreamRuntime object at 0x7fa1b7bac2f0>>
Traceback (most recent call last):
  File "/app/openhands/runtime/impl/eventstream/eventstream_runtime.py", line 417, in close
    self.log_buffer.close()
  File "/app/openhands/runtime/impl/eventstream/eventstream_runtime.py", line 100, in close
    self.log_stream_thread.join(timeout)
  File "/usr/local/lib/python3.12/threading.py", line 1151, in join
    self._wait_for_tstate_lock(timeout=max(timeout, 0))
  File "/usr/local/lib/python3.12/threading.py", line 1167, in _wait_for_tstate_lock
    if lock.acquire(block, timeout):
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt:
m@DESKTOP-MUB16F8:~$ docker run -it --privileged --rm \
LLM_API>   -e LLM_API_KEY="ollama" \
>   -e OLLAMA_HOST="http://172.21.151.42:11434" \
>   -e LLM_OLLAMA_BASE_URL="http://172.21.151.42:11434" \
>   -e OLLAMA_BASE_URL="http://172.21.151.42:11434" \
>   -e OLLAMA_URL="http://172.21.151.42:11434" \
>   -e SANDBOX_RUNTIME_CONTAINER_IMAGE="docker.all-hands.dev/all-hands-ai/runtime:0.12-nikolaik" \
>   -v /var/run/docker.sock:/var/run/docker.sock \
>   -p 3000:3000 \
>   --name openhands-app \
>   docker.all-hands.dev/all-hands-ai/openhands:0.12
Starting OpenHands...
Running OpenHands as root
INFO:     Started server process [10]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:3000 (Press CTRL+C to quit)
INFO:     172.17.0.1:34962 - "GET / HTTP/1.1" 200 OK
INFO:     172.17.0.1:34962 - "GET /locales/en/translation.json HTTP/1.1" 200 OK
INFO:     172.17.0.1:34962 - "GET /favicon.ico HTTP/1.1" 200 OK
INFO:     172.17.0.1:34962 - "GET /config.json HTTP/1.1" 200 OK
INFO:     172.17.0.1:34974 - "GET /config.json HTTP/1.1" 200 OK
INFO:     172.17.0.1:34974 - "GET /config.json HTTP/1.1" 200 OK
22:08:17 - openhands:INFO: github.py:14 - Initializing UserVerifier
22:08:17 - openhands:INFO: github.py:27 - GITHUB_USER_LIST_FILE not configured
22:08:17 - openhands:INFO: github.py:48 - GITHUB_USERS_SHEET_ID not configured
22:08:17 - openhands:INFO: github.py:85 - No user verification sources configured - allowing all users
INFO:     ('172.17.0.1', 34980) - "WebSocket /ws" [accepted]
22:08:17 - openhands:ERROR: auth.py:27 - Invalid token
INFO:     connection open
INFO:     172.17.0.1:34974 - "GET /api/options/models HTTP/1.1" 200 OK
INFO:     172.17.0.1:34962 - "GET /api/options/agents HTTP/1.1" 200 OK
INFO:     172.17.0.1:34982 - "GET /api/options/security-analyzers HTTP/1.1" 200 OK
INFO:     connection closed
INFO:     172.17.0.1:34982 - "GET /config.json HTTP/1.1" 200 OK
INFO:     172.17.0.1:34962 - "GET /config.json HTTP/1.1" 200 OK
INFO:     172.17.0.1:34962 - "GET / HTTP/1.1" 200 OK
INFO:     172.17.0.1:34962 - "GET /locales/en/translation.json HTTP/1.1" 200 OK
INFO:     172.17.0.1:34962 - "GET /config.json HTTP/1.1" 200 OK
INFO:     172.17.0.1:34982 - "GET /config.json HTTP/1.1" 200 OK
INFO:     172.17.0.1:34982 - "GET /api/options/models HTTP/1.1" 200 OK
INFO:     172.17.0.1:34962 - "GET /api/options/agents HTTP/1.1" 200 OK
INFO:     172.17.0.1:34974 - "GET /api/options/security-analyzers HTTP/1.1" 200 OK
INFO:     172.17.0.1:51484 - "GET /config.json HTTP/1.1" 200 OK
INFO:     172.17.0.1:51484 - "GET /config.json HTTP/1.1" 200 OK
INFO:     172.17.0.1:51484 - "GET /config.json HTTP/1.1" 200 OK
INFO:     172.17.0.1:51492 - "GET /config.json HTTP/1.1" 200 OK
INFO:     172.17.0.1:34872 - "GET /config.json HTTP/1.1" 200 OK
22:09:02 - openhands:INFO: github.py:14 - Initializing UserVerifier
22:09:02 - openhands:INFO: github.py:27 - GITHUB_USER_LIST_FILE not configured
22:09:02 - openhands:INFO: github.py:48 - GITHUB_USERS_SHEET_ID not configured
22:09:02 - openhands:INFO: github.py:85 - No user verification sources configured - allowing all users
INFO:     ('172.17.0.1', 34874) - "WebSocket /ws" [accepted]
22:09:02 - openhands:INFO: listen.py:336 - New session: 04d83367-dcb8-40bd-a5fb-d29a404ce676
INFO:     connection open
22:09:02 - openhands:WARNING: codeact_agent.py:101 - Function calling not supported for model ollama/llama3:latest. Disabling function calling.
INFO:     172.17.0.1:34872 - "GET /config.json HTTP/1.1" 200 OK
22:09:02 - openhands:INFO: base.py:98 - [runtime 04d83367-dcb8-40bd-a5fb-d29a404ce676] Starting runtime with image: docker.all-hands.dev/all-hands-ai/runtime:0.12-nikolaik
22:09:02 - openhands:INFO: base.py:98 - [runtime 04d83367-dcb8-40bd-a5fb-d29a404ce676] Container started: openhands-runtime-04d83367-dcb8-40bd-a5fb-d29a404ce676
22:09:02 - openhands:INFO: base.py:98 - [runtime 04d83367-dcb8-40bd-a5fb-d29a404ce676] Waiting for client to become ready at http://host.docker.internal:31789...
22:09:33 - openhands:INFO: base.py:98 - [runtime 04d83367-dcb8-40bd-a5fb-d29a404ce676] Runtime is ready.
22:09:33 - openhands:WARNING: state.py:118 - Failed to restore state from session: sessions/04d83367-dcb8-40bd-a5fb-d29a404ce676/agent_state.pkl
22:09:33 - openhands:INFO: agent_controller.py:135 - [Agent Controller 04d83367-dcb8-40bd-a5fb-d29a404ce676] Starting step loop...
22:09:33 - openhands:INFO: agent_controller.py:135 - [Agent Controller 04d83367-dcb8-40bd-a5fb-d29a404ce676] Setting agent(CodeActAgent) state from AgentState.LOADING to AgentState.INIT
22:09:33 - openhands:INFO: agent_controller.py:135 - [Agent Controller 04d83367-dcb8-40bd-a5fb-d29a404ce676] Setting agent(CodeActAgent) state from AgentState.INIT to AgentState.RUNNING
22:09:33 - openhands:INFO: github.py:14 - Initializing UserVerifier
22:09:33 - openhands:INFO: github.py:27 - GITHUB_USER_LIST_FILE not configured
22:09:33 - openhands:INFO: github.py:48 - GITHUB_USERS_SHEET_ID not configured
22:09:33 - openhands:INFO: github.py:85 - No user verification sources configured - allowing all users
INFO:     172.17.0.1:40502 - "GET /config.json HTTP/1.1" 200 OK
INFO:     172.17.0.1:40510 - "GET /config.json HTTP/1.1" 200 OK
INFO:     172.17.0.1:40500 - "GET /api/list-files HTTP/1.1" 200 OK
22:09:33 - openhands:INFO: github.py:14 - Initializing UserVerifier
22:09:33 - openhands:INFO: github.py:27 - GITHUB_USER_LIST_FILE not configured
22:09:33 - openhands:INFO: github.py:48 - GITHUB_USERS_SHEET_ID not configured
22:09:33 - openhands:INFO: github.py:85 - No user verification sources configured - allowing all users
INFO:     172.17.0.1:40510 - "GET /api/list-files HTTP/1.1" 200 OK
22:09:34 - openhands:INFO: github.py:14 - Initializing UserVerifier
22:09:34 - openhands:INFO: github.py:27 - GITHUB_USER_LIST_FILE not configured
22:09:34 - openhands:INFO: github.py:48 - GITHUB_USERS_SHEET_ID not configured
22:09:34 - openhands:INFO: github.py:85 - No user verification sources configured - allowing all users
INFO:     172.17.0.1:40500 - "GET /api/list-files HTTP/1.1" 200 OK


==============
[Agent Controller 04d83367-dcb8-40bd-a5fb-d29a404ce676] LEVEL 0 LOCAL STEP 0 GLOBAL STEP 0


Provider List: https://docs.litellm.ai/docs/providers


Provider List: https://docs.litellm.ai/docs/providers


